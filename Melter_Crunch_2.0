#### Melter_Crunch_1.0.py 
crunchversion = "Melter_Crunch_2.0.py"
# Run all raw_data_dict in folder
# Verbose off, ei =0
# This Crunch is for Use with Continuous melting for data files after June 1, 2015 *** Need to test for earlier data!!!
# Commented out drift standards section
# Using 104 to 175 as end of am nea

# Changed calibration scheme for SPIceCore to only include kgw, kpw, vw1f, And VW, vw1f is run as known-unknown

# Modified from SPC14_Crunch_1_2 which was take from WAIS06A_Crunch_2_8.py for batch mode
# This can data process any core as long as the data file structure is a replicate of SPIce or WAIS06A on GoogleDrive, and corename is set
# GoogleDrive must be renamed to take space out of the middle
# New to this version: flagging instead of pruning, more conservative autotrim as flag, so less subjective manual prunning to be done
# also changing the input of final flag option by typing in indices to flag anomolus feature, not explained by recorded issues
# new to last version: meltrate and diffusion lengths added into all data files
# memory correction NOT applied to ice cores, to allow system diffusion length to be applied to full data set.
# 

##### TABLE OF CONTENTS ########################################################
# SECTION..........................................LINE#
# ------------------------------------------------------
# REFERENCES..........................................57
# IMPORT PYTHON FUNCTIONS.............................91
# VERBOSE FLAG AND Core ID...........................129 
# CONSTANTS..........................................136
# DEFINE FUNCTIONS...................................172
#       ALLAN CLASS..................................174
#       ALLAN FUNCTION...............................213
#       TRANSFER FUNCTION............................314
#       SMOOTHING FUNCTION...........................762
# BEGIN OF FULL PROGRAM..............................809
# READ IN DATA.......................................830 instrument flag
#       FILTER FOR LOW WATER CONCENTRATION...........928 water flag
#       PLOT RAW DATA................................956
# ALLAN VARIANCE....................................1001
# FIRST DERIVATIVES.................................1077
# VALCO IDENTIFICATION FOR MEMORY AND CALIBRATION...1114 method flag
#       FOR WAIS06A, 1102, 5min.....................1249
#       FOR WAIS06A, 2130, 5min.....................1496
#       FOR WAIS06A, 2130, 20min....................1741
#       FOR SPIceCore,2130,20min....................1993 
#       APPLY MEMORY TO ALL VALCO TRANSITIONS.......2250 memory flag
# NEAPOLITAN IDENTIFICATION FOR MEMORY..............2333 memory flag
# ISOTOPE CALIBRATION...............................2638
# ICE CORES.........................................2918
#       MEMORY CORRECTION...........................3274 memory flag
#       DEPTH FILTER................................3288 depth flag
#       PARSE AND SAVE ALL ICE CORE DATA............3429 1st position prune flag
# OUTPUTS...........................................3546
# PLOT FOR QA/QC AND FLAGGING.......................3559 all second position flags
# READ IN ALL DATA AND PLOT FOR QA/QC...............3605 1st and 3rd position analytical flags
# END...............................................3874
#
#

##### REFERENCES USED THROUGHOUT THE CODE ######################################
# COMMENT FIELD CODES
# renumbered on 10/27/10 to ensure that the permuations of averages do not equal another comment value
# 0  = nothing
# 28 = other, look at written notes
# 101 = high isotope ice of neapolitan
# 103 = mid isotope ice of neapolitan (not being used 8/30/11)
# 104 = low isotope ice of neapolitan
# 106 (spare)
#       momentary flags:
#       113 = filter changed
#       114 = P2 stopped
#       117 = P2 restarted
#       119 = add constriction
#       126 = remove constriction
#       129 = gilson stuck
# 142 = beginning standard vials - Valco
# 153 = beginning of first neapolitan - AM
# 159 = end of first neapolitan - AM
# 161 = beginning of second neapolitan - PM
# 162 = end of second neapolitan - PM
# 172 = end of day standard vials - Valco
# 173 = push ice
# 175 = ice core stick
#
# VALCO STREAM SELECT VALVE POSITION MAP
# 1 = Waste
# 2 = Sample line from melter 
# 3 = kaw Std from vial
# 4 = kgw Std from vial
# 5 = kpw Std from vial
# 6 = vw1f Std from vial


##### IMPORT PYTHON FUNCTIONS ##################################################
import numpy as np
import scipy as sp
import time
import numpy.random
import os.path
import sys
import string
import copy
import datetime
import os
import pickle 
from copy import deepcopy
from numpy import fft
from scipy import interpolate
from scipy.interpolate import interp1d
from scipy.interpolate import UnivariateSpline
from scipy import stats
from scipy import special
from scipy.special import erf
from scipy import stats
from scipy import signal
from scipy import io
from scipy import optimize
from scipy import linalg
from scipy import integrate
from scipy.integrate import quad
from matplotlib import pyplot as plt
from math import sqrt, copysign, pi
import numpy.random as random
from numpy import where, zeros, ones, float64, array
from numpy import inner, kron
from numpy import exp as np_exp
from numpy import arctan as np_arctan
from scipy.stats import norm
from scipy.special import gamma as sp_gamma
from Tkinter import *
import tkMessageBox

# VERBOSE FLAG, 1=ON, 0=OFF, for batch mode after corrections made
verbose = 0

# Core Name for data directory - please comment out the other cores
corename = 'WAIS06AData'
#corename = 'SPIceCoreData'

##### CONSTANTS ################################################################

watertoolow = 10000 # in ppm

## Standard Values, calibrated March 2010 
kbwd18o = -14.19
kbwdD = -111.81
kawd18o = -30.35
kawdD = -239.3
kgwd18o = -38.09 #trap standard for WAIS06A
kgwdD = -298.7
kpwd18o = -45.43 #trap standard for SPIceCore
kpwdD = -355.6 
vw1fd18o = -56
vw1fdD = -438

if corename == 'WAIS06AData': 
    knownd18o = [kbwd18o, kawd18o, kpwd18o]       
    knowndD   = [kbwdD, kawdD, kpwdD]         

if corename == 'SPIceCoreData': 
    knownd18o = [kawd18o, kgwd18o, vw1fd18o]       
    knowndD   = [kawdD, kgwdD, vw1fdD] 


## Transfer function shape constatants
valcoshape1d18o = 1.8
valcoshape2d18o = 0.3
valcoshape1dD = 3.1
valcoshape2dD = 0.35
neashape1d18o = 1.6
neashape2d18o = 0.3
neashape1dD = 3.1
neashape2dD = 0.4


##### DEFINE FUNCTIONS USED THROUGHOUT THE CODE ################################

##### ALLAN VARIANCE MATHMATICS ################################################
## written by Vasileios Gkinis
class Allan():
    
    def __init__(self):
        return

    def allan(self, t, y, plot = True):
        
        t1 = time.time()
        dt = t[1] - t[0]
        N = np.size(y)
        m = np.arange(2,np.floor(N/2)+1)# Number of subgroups
        allans = np.zeros(np.size(m))   # Array where Allan variances are stored
        tau = np.zeros(np.size(m))
        allan_i = 0                     # Initiates index for allans

        for mi in m:
            k = np.floor(N/mi)          # Size of subgroup
            tau[allan_i] = k*dt
            if tau[allan_i] == tau[allan_i-1]:
                tau[allan_i] = 0
                continue
            means_mi = np.zeros(mi)     # Means of subgroups array
             
            for s in np.arange(mi):
                means_mi[s] = np.mean(y[s*k:(s+1)*k])
            diffs_squares = (means_mi[1:] - means_mi[:-1])**2
            allans[allan_i] = 0.5*np.mean(diffs_squares)
            allan_i = allan_i+1

        allans = np.trim_zeros(allans)[::-1]
        tau = np.trim_zeros(tau)[::-1]
        
        if verbose ==1:
            print "Allan variance plot processing time: %0.3e" %(time.time() - t1)
        
        return np.array((tau, allans))

##### PERFORM ALLAN VARIANCE FUNCTION DEFINED ##################################
## written by Vasileios Gkinis, editted by Valerie Morris to automate

def perform_allan(AllanIndex1, AllanIndex2):
    Allansecs = secs[AllanIndex1:AllanIndex2]
    Allanwater_ppm = data_dict["water_ppm"][AllanIndex1:AllanIndex2]
    Alland18o = data_dict["d18o"][AllanIndex1:AllanIndex2]
    AllandD = data_dict["dD"][AllanIndex1:AllanIndex2]
    Allanflag = data_dict["flag"][AllanIndex1:AllanIndex2]
    Allanindex = np.arange(len(Allanflag))

    time_step = np.ceil(mean_time_delay) ## really with all of the data, this equals 1.0 except when it is negative, then it is 0.0... would this be more appropriate to leave as just the mean_time_delay
    print Allansecs[0], Allansecs[-1], time_step
    equal_secs = np.arange(Allansecs[0], Allansecs[-1], time_step)
    equal_Alland18o = np.interp(equal_secs, Allansecs, Alland18o)
    equal_AllandD = np.interp(equal_secs, Allansecs, AllandD)

    mean_water_ppm = np.mean(Allanwater_ppm)

    t_allan = equal_secs
    Alland18o_allan = equal_Alland18o
    AllandD_allan = equal_AllandD
    tau, allans_Alland18o = Allan().allan(t_allan, Alland18o_allan, plot = False)
    tau, allans_AllandD = Allan().allan(t_allan, AllandD_allan,  plot = False)

    ## PLOTS OF ALLAN ##################################################
    fig_allan = plt.figure(3)
    fig_allan_ax1 = fig_allan.add_subplot(111)
    fig_allan_ax1.loglog(tau, allans_Alland18o, "b-o")
    fig_allan_ax1.loglog(tau, allans_AllandD, "r-o")
    fig_allan_ax1.set_ylabel("Allan variance")
    fig_allan_ax1.set_xlabel("Integration time [sec]")
    fig_allan_ax1.set_title("%s - %0.0f ppm" %(os.path.splitext(filepath)[0], mean_water_ppm))
    fig_allan_ax1.grid(True)

    fig_series1 = plt.figure(4)
    fig_series1_ax1 = fig_series1.add_subplot(111)
    fig_series1_ax1.plot(t_allan, Alland18o_allan, "b-")
    fig_series1_ax1.set_title("d18o time series")
    fig_series1_ax1.set_ylabel("d18o")
    fig_series1_ax1.set_xlabel("Time [sec]")

    fig_series2 = plt.figure(5)
    fig_series2_ax1 = fig_series2.add_subplot(111)
    fig_series2_ax1.plot(t_allan, AllandD_allan, "r-")
    fig_series2_ax1.set_title("dD time series")
    fig_series2_ax1.set_ylabel("dD")
    fig_series2_ax1.set_xlabel("Time [sec]")
            
    ## OUTPUT TO SCREEN OF ALLAN AND TO FUNCTION OUTPUT ########################            
    allanout = np.zeros (13)
    allanindex = np.arange(len(tau))
    date = data_dict["j_days"][0]
    ave_d18o = np.mean(Alland18o)
    allanout[0] = ave_d18o
    if verbose ==1:
        print("d18o average value for section: %0.3f" %(ave_d18o))
    stdev_d18o = np.std(Alland18o)
    allanout[1] = stdev_d18o
    if verbose ==1:
        print("Std d18o raw of section: %0.3f" %(stdev_d18o))
        print("Std d18o of fixed spacing: %0.3f" %(np.std(Alland18o_allan)))
    lin = sp.interpolate.interp1d(tau, allans_Alland18o)
    xpoints = [10, 60, 600, 3600]
    if len(tau) <= 3600:
        xpoints = [10, 60, 600]
    ypoints = lin (xpoints)
    allanout[2] = ypoints[0] #10 sec d18o
    allanout[3] = ypoints[1] #60 sec d18o
    allanout[4] = ypoints[2] #600 sec d18o
    if len(tau) >= 3600:
        allanout[11] = ypoints[3] #3600 sec dD (40 min)
    ave_dD = np.mean(AllandD)
    allanout[6] = ave_dD
    if verbose ==1:
        print("dD average value for section: %0.3f" %(ave_dD))
    stdev_dD = np.std(AllandD)
    allanout[7] = stdev_dD
    if verbose ==1:
        print("Std dD raw of section: %0.3f" %(stdev_dD))
        print("Std dD of fixed spacing: %0.3f" %(np.std(AllandD_allan)))
    ave_time_delay = np.mean(data_dict["time_delay"])
    if verbose ==1:
        print("average time_delay: %0.3f"  %(ave_time_delay))
    lin = sp.interpolate.interp1d(tau, allans_AllandD)
    xpoints = [10, 60, 600, 3600]
    if len(tau) <= 3600:
        xpoints = [10, 60, 600]
    ypoints = lin (xpoints)  
    allanout[8] = ypoints[0] #10 sec dD
    allanout[9] = ypoints[1] #60 sec dD
    allanout[10] = ypoints[2] #600 sec dD
    if len(tau) >= 3600:
        allanout[11] = ypoints[3] #3600 sec dD (40 min)
    if verbose ==1:
        print("water conc of this section: %0.3f" %(mean_water_ppm))
    allanout[12] =  mean_water_ppm 
    if verbose ==1:
        print allanout   
    return allanout

##### TRANSFER FUNCTION DEFINED ################################################
## written by Vasileios Gkinis, modified by Valerie Morris

def lognorm_cdf(x, s, mu, sigma):
    return stats.lognorm.cdf(x, s, loc = mu, scale = sigma)

def lognorm_pdf(x, s, mu, sigma):
    return stats.lognorm.pdf(x, s, loc = mu, scale = sigma)

def log_product(x, a, b, shape1, mu, r1, shape2, r2):
    f1 = lognorm_cdf(x, shape1, mu, r1)
    f2 = lognorm_cdf(x, shape2, mu, r2)
    return a*(f1*f2)+b

def lsq_log_product(p, x, a, b, c, d):
    f1 = lognorm_cdf(x, c, p[0], p[1])
    f2 = lognorm_cdf(x, d, p[0], p[2])
    return a*(f1*f2)+b

def err_lsq_log_product(p, x, y, a, b, c, d):
    return lsq_log_product(p, x, a, b, c, d)-y

def skew(p,x):                                                                  #skew pdf
    #t = (x-e)/w
    # 2/w * lognorm_pdf(t,s,mu,sigma) * lognorm_cdf(a*t,s,mu,sigma)
    #p[0]=e, p[1]=w, p[2]=a, p[3]=s, p[4]=mu, p[5]=sigma, p_i = [-0.5,1,5,3,0,10]
    t = x                      #t = (x-e) / w, e=0, w=1, a=1.06
    return 2* lognorm_pdf(t,0.34,p[0],p[1]) * lognorm_cdf(1.06*t,0.34,p[0],p[1])

def err_lsq_skew(p,x,y):
    return skew(p,x)-y

def skew_cdf1(p,x):                                                            #skew cdf take 1, with special case listed on wolfram
    return lognorm_cdf(1.06*x,0.34,p[0],p[1])-2*(1/8*erf(-x/np.sqrt(2))*erf(x/np.sqrt(2)))

def err_lsq_skew_cdf1(p,x,y):
    return skew_cdf1(p,x)-y

#####################################################################################
"""
Created on Sat Jan 26 16:19:12 2013

@author: Janwillem van Dijk
@email: jwe.van.dijk@xs4all.nl

Module for generating skew normal random numbers (Adelchi Azzalini)
===================================================================
http://azzalini.stat.unipd.it/SN/

Licensing:
This code is distributed under the GNU LGPL license.

-   rnd_skewnormal: returns random valuse for sn distribution with given
        location scale and shape
-   random_skewnormal: returns random valuse for sn distribution with given
        mean, stdev and skewness
-   skewnormal_parms: returns location, scale and shape given
        mean, stdev and skewnessof the sn distribution
-   skewnormal_stats: returns mean, stdev and skewness given
        location scale and shape
-   pdf_skewnormal: returns values for the pdf of a skew normal distribution
-   cdf_skewnormal: returns values for the cdf of a skew normal distribution
-   T_owen returns: values for Owens T as used by cdf_skewnormal
-   skew_max: returns the maximum skewness of a sn distribution
"""
try:
    """
    Try to use owen.f90 compiled into python module with
    f2py -c -m owens owens.f90
    ginving owens.so
    http://people.sc.fsu.edu/~jburkardt/f_src/owens/owens.f90
    """
    owens = None
    #import owens
except:
    print 'owens not found'

def T_Owen_int(h, a, jmax=50, cut_point=6):
    """
    Return Owens T
    ==============
    @param: h   the h parameter of Owen's T
    @param: a   the a parameter of Owen's T (-1 <= a <= 1)
    Python-numpy-scipy version for Owen's T translated from matlab version
        T_owen.m of R module sn.T_int
    """
    if type(h) in (float, float64):
        h = array([h])
    low = where(h <= cut_point)[0]
    high = where(h > cut_point)[0]
    n_low = low.size
    n_high = high.size
    irange = np.arange(0, jmax)
    series = zeros(h.size)
    if n_low > 0:
        h_low = h[low].reshape(n_low, 1)
        b = fui(h_low, irange)
        cumb = b.cumsum(axis=1)
        b1 = np_exp(-0.5 * h_low ** 2) * cumb
        matr = ones((jmax, n_low)) - b1.transpose()  # matlab ' means transpose
        jk = kron(ones(jmax), [1.0, -1.0])
        jk = jk[0: jmax] / (2 * irange + 1)
        matr = inner((jk.reshape(jmax, 1) * matr).transpose(),
                     a ** (2 * irange + 1))
        series[low] = (np_arctan(a) - matr.flatten(1)) / (2 * pi)
    if n_high > 0:
        h_high = h[high]
        atana = np_arctan(a)
        series[high] = (atana * np_exp(-0.5 * (h_high ** 2) * a / atana) *
                    (1.0 + 0.00868 * (h_high ** 4) * a ** 4) / (2.0 * pi))
    return series

def fui(h, i):
    return (h ** (2 * i)) / ((2 ** i) * sp_gamma(i + 1))

def T_Owen_series(h, a, jmax=50, cut_point=6):
    """
    Return Owens T
    ==============
    @param: h   the h parameter of Owen's T
    @param: a   the a parameter of Owen's T
    Python-numpy-scipy version for Owen's T
    Python-numpy-scipy version for Owen's T translated from matlab version
        T_owen.m of R module sn.T_Owen
    """
    if abs(a) <= 1.0:
        return T_Owen_int(h, a, jmax=jmax, cut_point=cut_point)
    else:
        """D.B. Owen Ann. Math. Stat. Vol 27, #4 (1956), 1075-1090
         eqn 2.3, 2.4 and 2.5
         Available at: http://projecteuclid.org/DPubS/Repository/1.0/
            Disseminate?view=body&id=pdf_1&handle=euclid.aoms/1177728074"""
        signt = copysign(1.0, a)
        a = abs(a)
        h = abs(h)
        ha = a * h
        gh = norm.cdf(h)
        gha = norm.cdf(ha)
        t = 0.5 * gh + 0.5 * gha - gh * gha - \
                T_Owen_int(ha, 1.0 / a, jmax=jmax, cut_point=cut_point)
        return signt * t

def T_Owen(h, a):
    """
    Return Owens T
    ==============
    @param: h   the h parameter of Owens T
    @param: a   the a parameter of Owens T
    Try to use owens.f90 version else python version
    owens.f90 is approximately a factor 100 faster
    """
    if owens:
        """Owen's T using owens.f90 by Patefield and Brown
            http://www.jstatsoft.org/v05/a05/paper
            Fortran source by Burkhard
            http://people.sc.fsu.edu/~jburkardt/f_src/owens/owens.f90"""
        if type(h) in [float, float64]:
            return owens.t(h, a)
        else:
            t = zeros(h.size)
            for i in range(h.size):
                t[i] = owens.t(h[i], a)
            return t
    else:
        """
        Owens T after sn.T_Owen(H, a) D.B. Owen (1956)
        """
        return T_Owen_series(h, a)

def cdf_skewnormal(p, x):
    """
    Return skew normal cdf
    ======================
    p[0] = @param location:    location of sn distribution(e)
    p[1] = @param scale:       scale of sn distribution(w)
    p[2] = @param shape:       shape of sn distribution(a)
    http://azzalini.stat.unipd.it/SN/
    """
    xi = (x - p[0]) / p[1]
    return norm.cdf(xi) - 2.0 * T_Owen(xi, p[2])
def err_lsq_cdf_skewnormal(p, x, y):
    return cdf_skewnormal(p, x)-y

def pdf_skewnormal(p, x):
    """
    Return skew normal pdf
    ======================
    p[0] = @param location:    location of sn distribution(e)
    p[1] = @param scale:       scale of sn distribution(w)
    p[2] = @param shape:       shape of sn distribution(a)
    http://azzalini.stat.unipd.it/SN/
    """
    t = (x - p[0]) / p[1]
    return 2.0 / p[1] * norm.pdf(t) * norm.cdf(p[2] * t)
def err_lsq_pdf_skewnormal(p, x, y):
    return pdf_skewnormal(p, x)-y

def impulse(sig,time):                                                          #normal distribution pdf with sig =1, (1/(np.sqrt(2*np.pi))*np.exp(-1*(np.square(time)/(2)))
    return (1/(sig*(np.sqrt(2*np.pi))))*np.exp(-1*(np.square(time)/(2*np.square(sig))))

def err_lsq_impulse(sig,time,y):
    return impulse(sig,time)-y

def PerformTransfer(type, int, TransferIndex1, TransferIndex2, StepIndex):
    ## INPUT INDICES FOR TRANSFRER FUNCTION ############################
    TransferIndex1 = np.float(TransferIndex1)
    TransferIndex2 = np.float(TransferIndex2)
    StepIndex = secs[np.float(StepIndex)]
    
    Transsecs = secs[TransferIndex1:TransferIndex2]
    Transwater_ppm = data_dict["water_ppm"][TransferIndex1:TransferIndex2]
    Transd18o = data_dict["d18o"][TransferIndex1:TransferIndex2]
    TransdD = data_dict["dD"][TransferIndex1:TransferIndex2]
    startvalued18o = np.mean(Transd18o[0:40])
    startvaluedD = np.mean(TransdD[0:40])
    endvalued18o = np.mean(Transd18o[-41:-1])
    endvaluedD = np.mean(TransdD[-41:-1])
    if len(Transd18o)<=800:
        stepd18o = (endvalued18o - startvalued18o)/0.9957314
        stepdD = (endvaluedD - startvaluedD)/0.9879513
    if len (Transd18o)>=800:
        stepd18o = endvalued18o - startvalued18o
        stepdD = endvaluedD - startvaluedD
    newd18oend = startvalued18o+stepd18o
    newdDend = startvaluedD+stepdD
            
    if verbose ==1:
        print startvalued18o, startvaluedD, newd18oend, newdDend, stepd18o, stepdD

    time_step = np.ceil(mean_time_delay)
    total_time = Transsecs[-1]-Transsecs[0]
    equal_secs = np.arange(Transsecs[0], Transsecs[-1], time_step)
    equal_Transd18o = np.interp(equal_secs, Transsecs, Transd18o)
    equal_TransdD = np.interp(equal_secs, Transsecs, TransdD)
    mean_water_ppm = np.mean(Transwater_ppm)
    norm_Transd18o = (startvalued18o-equal_Transd18o)/(startvalued18o-newd18oend)
    norm_TransdD = (startvaluedD-equal_TransdD)/(startvaluedD-newdDend)
    
    ## Fit log*log cdf on d18o data  ################################################
    p_i = [StepIndex, 2.0, 35]  #[mu, sigma1, sigma2]
    s1_Transd18o = valcoshape1d18o
    s2_Transd18o = valcoshape2d18o
    if type == "AMNea" or type == "PMNea":
        p_i = [StepIndex, 2.0, 50]
        s1_Transd18o = neashape1d18o
        s2_Transd18o = neashape2d18o
    p_opt = sp.optimize.leastsq(err_lsq_log_product, p_i, args=(equal_secs, equal_Transd18o, stepd18o, startvalued18o, s1_Transd18o, s2_Transd18o), maxfev=10000)[0]
    if verbose ==1:
        print("\n\n\n" + 80*"-" + "\nFitting O18 step with model a*(f1*f2)+b with lsq and shapes fixed")
        print "**** p_opt *****", p_opt
    mu_Transd18o = p_opt[0]
    sigma1_Transd18o = p_opt[1]
    sigma2_Transd18o = p_opt[2]
    d18o_Diff_Len = p_opt[-1]
    extrapolated18o = log_product(4000, stepd18o, startvalued18o, s1_Transd18o, 0, sigma1_Transd18o, s2_Transd18o, sigma2_Transd18o)
    if verbose ==1:
        print extrapolated18o
    cdf_Transd18o = lsq_log_product(p_opt, equal_secs, stepd18o, startvalued18o, s1_Transd18o, s2_Transd18o)
    cdf_Transd18o_norm = (cdf_Transd18o - startvalued18o)/stepd18o
    cdf_residuald18o = err_lsq_log_product(p_opt, equal_secs, equal_Transd18o, stepd18o, startvalued18o, s1_Transd18o, s2_Transd18o)
    time_n_Transd18o = equal_secs-equal_secs[cdf_Transd18o_norm>=0.5][0]

    #### Fit skew_cdf on d18o data #################################################
    y_i_d18o = [-15.0,25.0,4.0] # [location(e), scale (w), shape(a)] not necessarily mu, scale and sigma
    y_opt_d18o = sp.optimize.leastsq(err_lsq_cdf_skewnormal, y_i_d18o, args=(time_n_Transd18o, norm_Transd18o))[0]
    print "cdf_skewnormal variables", y_opt_d18o
    skew_cdf_Transd18o = cdf_skewnormal(y_opt_d18o, time_n_Transd18o)
    skew_cdf_residuald18o = err_lsq_cdf_skewnormal(y_opt_d18o, time_n_Transd18o, norm_Transd18o)*stepd18o
    skew_alpha_d18o = y_opt_d18o[2]
    skew_omega_d18o = y_opt_d18o[1]
    skew_delta_d18o = skew_alpha_d18o/(np.sqrt(1+np.square(skew_alpha_d18o)))
    skew_var_d18o = np.sqrt(np.square(skew_omega_d18o)*(1-(2*np.square(skew_delta_d18o)/np.pi)))
    print "skewnormal cdf variance for ", type, skew_var_d18o

    ## Fit log*log cdf on dD data  ################################################
    p_i = [StepIndex, 0.4, 32]  #[mu, sigma1, sigma2)
    s1_TransdD = valcoshape1dD
    s2_TransdD = valcoshape2dD
    if type == "AMNea" or type == "PMNea":
        p_i = [StepIndex, 2.0, 50]
        s1_TransdD = neashape1dD
        s2_TransdD = neashape2dD
    p_opt = sp.optimize.leastsq(err_lsq_log_product, p_i, args=(equal_secs, equal_TransdD, stepdD, startvaluedD, s1_TransdD, s2_TransdD), maxfev=10000)[0]
    if verbose ==1:
        print("\n\n\n" + 80*"-" + "\nFitting delD step with model a*(f1*f2)+b with lsq and shapes fixed")
        print "**** p_opt *****", p_opt
    mu_TransdD = p_opt[0]
    sigma1_TransdD = p_opt[1]
    sigma2_TransdD = p_opt[2]
    dD_Diff_Len = p_opt[-1]
    extrapolatedD = log_product(4000, stepdD, startvaluedD, s1_TransdD, 0, sigma1_TransdD, s2_TransdD, sigma2_TransdD)
    if verbose ==1:
        print extrapolatedD
    cdf_TransdD = lsq_log_product(p_opt, equal_secs, stepdD, startvaluedD, s1_TransdD, s2_TransdD)
    cdf_TransdD_norm = (cdf_TransdD - startvaluedD)/stepdD
    cdf_residualdD = err_lsq_log_product(p_opt, equal_secs, equal_TransdD, stepdD, startvaluedD, s1_TransdD, s2_TransdD)
    time_n_TransdD = equal_secs - equal_secs[cdf_TransdD_norm>=0.5][0]
    
    #### Fit skew_cdf on dD data #################################################
    y_i_dD = [-15.0,25.0,4.0] # [location, scale, shape] not necessarily mu, scale and sigma
    y_opt_dD = sp.optimize.leastsq(err_lsq_cdf_skewnormal, y_i_dD, args=(time_n_TransdD, norm_TransdD))[0]
    print "cdf_skewnormal variables", y_opt_dD
    skew_cdf_TransdD = cdf_skewnormal(y_opt_dD, time_n_TransdD)
    skew_cdf_residualdD = err_lsq_cdf_skewnormal(y_opt_dD, time_n_TransdD, norm_TransdD)*stepdD
    skew_alpha_dD = y_opt_dD[2]
    skew_omega_dD = y_opt_dD[1]
    skew_delta_dD = skew_alpha_dD/(np.sqrt(1+np.square(skew_alpha_dD)))
    skew_var_dD = np.sqrt(np.square(skew_omega_dD)*(1-(2*np.square(skew_delta_dD)/np.pi)))
    print "skewnormal cdf variance for ", type, skew_var_dD

    ## Plot CDF's  #####################################################
    fig4 = plt.figure(int+6)
    fig4_ax1 = fig4.add_subplot(321)
    fig4_ax1.plot(equal_secs, equal_Transd18o, "bx")
    fig4_ax1.plot(equal_secs, cdf_Transd18o, "k", linewidth = 2)
    fig4_ax1.set_ylabel("d18o")
    fig4_ax1.set_xlabel("Time [sec]")
    
    fig4_ax3 = fig4.add_subplot(323)
    fig4_ax3.plot(time_n_Transd18o, norm_Transd18o, "bx")
    fig4_ax3.plot(time_n_Transd18o, cdf_Transd18o_norm, "k-", linewidth = 2)    #log*log
    fig4_ax3.plot(time_n_Transd18o, skew_cdf_Transd18o, "g-", linewidth = 1)    #skew normal
    fig4_ax3.set_ylabel("d18o")
    fig4_ax3.set_xlabel("Time [sec]")
    
    fig4_ax5 = fig4.add_subplot(325)
    fig4_ax5.plot(equal_secs, cdf_residuald18o, "k-", linewidth = 2)            #log*log
    fig4_ax5.plot(equal_secs, skew_cdf_residuald18o, "g-", linewidth = 1)       #skew normal
    fig4_ax5.set_ylabel("d18o")
    fig4_ax5.set_xlabel("Time [sec]")
    
    fig4_ax2 = fig4.add_subplot(322)
    fig4_ax2.plot(equal_secs, equal_TransdD, "rx")   
    fig4_ax2.plot(equal_secs, cdf_TransdD, "k", linewidth = 2)
    fig4_ax2.set_ylabel("dD")
    fig4_ax2.set_xlabel("Time [sec]")
    
    fig4_ax4 = fig4.add_subplot(324)
    fig4_ax4.plot(time_n_Transd18o, norm_TransdD, "rx")
    fig4_ax4.plot(time_n_TransdD, cdf_TransdD_norm, "k-", linewidth = 2)        #log*log
    fig4_ax4.plot(time_n_TransdD, skew_cdf_TransdD, "m-", linewidth = 1)        #skew normal
    fig4_ax4.set_ylabel("dD")
    fig4_ax4.set_xlabel("Time [sec]")
    
    fig4_ax6 = fig4.add_subplot(326)
    fig4_ax6.plot(equal_secs, cdf_residualdD, "k-", linewidth = 2)              #log*log
    fig4_ax6.plot(equal_secs, skew_cdf_residualdD, "m-", linewidth = 1)         #skew normal
    fig4_ax6.set_ylabel("dD")
    fig4_ax6.set_xlabel("Time [sec]")
            
    fig4_ax1.set_title("%s - %0.0f - %0.0f" %(os.path.splitext(filepath)[0], TransferIndex1, TransferIndex2))
    
    ## Frequencies  #################################################### ?
    dt = equal_secs[1] - equal_secs[0]
    N = np.size(equal_secs)
    pad = 2048-N
    Nf = np.size(equal_secs) + pad
    freq = fft.fftfreq(Nf, dt)
    f_nyq = 1./(2*dt)
    if verbose ==1:
        print "\ndt: %0.2f    N: %i    fnyq: %.3f Hz\n" %(dt, Nf, f_nyq)
    
    ## Transd18o transfer function   ################################### ?
    diff_Transd18o = np.gradient(equal_Transd18o, dt)/stepd18o                  #first derivative of equally spaced d18o data normaized to step size
    fft_diff_Transd18o = fft.fft(diff_Transd18o, Nf)*dt                         #fourierre transform of data
    absolute_Transd18o = np.abs(fft_diff_Transd18o)                             #absolute value of fourierre transform of data
    diff_cdf_Transd18o = np.gradient(cdf_Transd18o_norm, dt)                    #first derivate of normalized fit cdf function
    fft_diff_cdf_Transd18o = fft.fft(diff_cdf_Transd18o, Nf)*dt                 #fourierre transform of fit
    absolute_cdf_Transd18o = np.abs(fft_diff_cdf_Transd18o)                     #absolute value of fourierre transform of fit
    
    ## TransdD transfer function   ##################################### ?
    diff_TransdD = np.gradient(equal_TransdD, dt)/stepdD                        #first derivative of equally spaced dD data normaized to step size
    fft_diff_TransdD = fft.fft(diff_TransdD, Nf)*dt                             #fourierre transform of data
    absolute_TransdD = np.abs(fft_diff_TransdD)                                 #absolute value of fourierre transform of data
    diff_cdf_TransdD= np.gradient(cdf_TransdD_norm, dt)                         #first derivate of normalized fit cdf function
    fft_diff_cdf_TransdD = fft.fft(diff_cdf_TransdD, Nf)*dt                     #fourierre transform of fit
    absolute_cdf_TransdD = np.abs(fft_diff_cdf_TransdD)                         #absolute value of fourierre transform of fit
    
    # Get diffusion length in time ####################################
    ## Normal distribution
    sigi_d18o = 10                                                              # apriori sigma
    sig_opt_d18o = sp.optimize.leastsq(err_lsq_impulse, sigi_d18o, args=(time_n_Transd18o, diff_Transd18o))[0] #(was being fitted to diff of cdf, not data, does that really equal pdf?)
    print "d18O sigma", type, sig_opt_d18o
    impulse_d18o = impulse(sig_opt_d18o,time_n_TransdD)
    sigi_dD = 10                                                                # apriori sigma
    sig_opt_dD = sp.optimize.leastsq(err_lsq_impulse, sigi_dD, args=(time_n_TransdD, diff_TransdD))[0] #(was being fitted to diff of cdf, not data, does that really equal pdf?)
    print "dD sigma", type, sig_opt_dD
    impulse_dD = impulse(sig_opt_dD,time_n_TransdD)
    
    # Get diffusion length in time ####################################
    w_i_d18o = [-15.0,25.0,4.0]
    w_opt_d18o = sp.optimize.leastsq(err_lsq_pdf_skewnormal, w_i_d18o, args=(time_n_Transd18o, diff_Transd18o))[0]
    print "d18o pdf_skewnormal variables ", type, w_opt_d18o
    skewnormalimpulse_d18o = pdf_skewnormal(w_opt_d18o, time_n_Transd18o)
    resisdualimpulse_d18o = err_lsq_pdf_skewnormal(w_opt_d18o, time_n_Transd18o,diff_Transd18o)
    skew_cdf_Transd18o = cdf_skewnormal(w_opt_d18o, time_n_Transd18o)
    skew_cdf_residuald18o = err_lsq_cdf_skewnormal(w_opt_d18o, time_n_Transd18o, norm_Transd18o)*stepd18o
    skew_alpha_d18o = w_opt_d18o[2]
    skew_omega_d18o = w_opt_d18o[1]
    skew_delta_d18o = skew_alpha_d18o/(np.sqrt(1+np.square(skew_alpha_d18o)))
    skew_var_d18o = np.sqrt(np.square(skew_omega_d18o)*(1-(2*np.square(skew_delta_d18o)/np.pi)))
    print "skewnormal pdf variance for ", type, skew_var_d18o
    
    w_i_dD = [-15.0,25.0,4.0]
    w_opt_dD = sp.optimize.leastsq(err_lsq_pdf_skewnormal, w_i_dD, args=(time_n_TransdD, diff_TransdD))[0]
    print "dD pdf_skewnormal variables ", type, w_opt_dD
    skewnormalimpulse_dD = pdf_skewnormal(w_opt_dD, time_n_TransdD)
    resisdualimpulse_dD = err_lsq_pdf_skewnormal(w_opt_dD, time_n_TransdD,diff_TransdD)
    skew_cdf_TransdD = cdf_skewnormal(w_opt_dD, time_n_TransdD)
    skew_cdf_residualdD = err_lsq_cdf_skewnormal(w_opt_dD, time_n_TransdD, norm_TransdD)*stepdD
    skew_alpha_dD = w_opt_dD[2]
    skew_omega_dD = w_opt_dD[1]
    skew_delta_dD = skew_alpha_dD/(np.sqrt(1+np.square(skew_alpha_dD)))
    skew_var_dD = np.sqrt(np.square(skew_omega_dD)*(1-(2*np.square(skew_delta_dD)/np.pi)))
    print "skewnormal pdf variance for ", type, skew_var_dD
    
    ## PLOT IMPULSE RESPONSE ###########################################
    fig5 = plt.figure(int+7)
    fig5_ax1 = fig5.add_subplot(311)
    fig5_ax1.plot(time_n_Transd18o, diff_Transd18o, 'bx')                       #diff of data
    fig5_ax1.plot(time_n_Transd18o, impulse_d18o, 'k', linewidth = 1)           #normal pdf
    fig5_ax1.plot(time_n_Transd18o, skewnormalimpulse_d18o, 'b', linewidth = 1) #skew normal pdf
    fig5_ax1.grid(True)
    fig5_ax1.set_xlabel("Time [sec]")
    fig5_ax1.set_ylabel("d[d18o]/dt")
    fig5_ax2 = fig5.add_subplot(312)
    fig5_ax2.plot(time_n_TransdD, diff_TransdD, 'rx')                           #diff of data
    fig5_ax2.plot(time_n_TransdD, impulse_dD, 'k', linewidth = 1)               #normal pdf
    fig5_ax2.plot(time_n_TransdD, skewnormalimpulse_dD, 'r', linewidth = 1)     #skew normal pdf
    fig5_ax2.grid(True)
    fig5_ax2.set_xlabel("Time [sec]")
    fig5_ax2.set_ylabel("d[dD]/dt")
    fig5_ax3 = fig5.add_subplot(313)
    fig5_ax3.grid(True)
    fig5_ax3.plot(time_n_Transd18o, resisdualimpulse_d18o, 'b-')
    fig5_ax3.plot(time_n_TransdD, resisdualimpulse_dD, 'r-')
    fig5_ax1.set_title("%s - %0.0f - %0.0f" %(os.path.splitext(filepath)[0], TransferIndex1, TransferIndex2))

    fig4_ax3.plot(time_n_Transd18o, skew_cdf_Transd18o, "y-", linewidth = 1)    #pdf transform to cdf
    fig4_ax5.plot(equal_secs, skew_cdf_residuald18o, "y-", linewidth = 1)       #pdf transform to cdf
    fig4_ax4.plot(time_n_TransdD, skew_cdf_TransdD, "y-", linewidth = 1)        #pdf transform to cdf
    fig4_ax6.plot(equal_secs, skew_cdf_residualdD, "y-", linewidth = 1)         #pdf transform to cdf
    
    ##### First two are VALCO OUTPUT VARIABLES TO ARRAY TO BE USED LATER IN Calibriation if 5 min valco
    ##### Three onwards are curve fit variables to be used in performance file, memory correction, and deconvolution
    ##### IF NEAPOLITAN, WRITE TO COMMON FILE TO BE USED IN DECONVOLUTION... INDICATORS AM = FIRST BEG DEPTH, PM = LAST END DEPTH  
    return extrapolated18o, extrapolatedD, sigma1_Transd18o, sigma2_Transd18o, sigma1_TransdD, sigma2_TransdD, time_n_Transd18o, cdf_Transd18o_norm, time_n_TransdD, cdf_TransdD_norm, mu_Transd18o, skew_var_d18o, sig_opt_d18o, skew_var_dD, sig_opt_dD

##### SMOOTHING FUNCTION #######################################################
## written by Vasileios Gkinis
def smooth(x, window_len=21, window='hamming'): # window length was 11 in previous versions
    """
    smooth the data using a window with requested size.
    
    This method is based on the convolution of a scaled window with the signal.
    The signal is prepared by introducing reflected copies of the signal 
    (with the window size) in both ends so that transient parts are minimized
    in the begining and end part of the output signal.
    
    input:
        x: the input signal 
        window_len: the dimension of the smoothing window; should be an odd integer
        window: the type of window from 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'
            flat window will produce a moving average smoothing.

    output:
        the smoothed signal
    """
    
    if x.ndim != 1:
        raise ValueError, "smooth only accepts 1 dimension arrays."

    if x.size < window_len:
        raise ValueError, "Input vector needs to be bigger than window size."

    if window_len<3:
        return x

    if not window in ['flat', 'hanning', 'hamming', 'bartlett', 'blackman']:
        raise ValueError, "Window is on of 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'"

    s=np.r_[2*x[0]-x[window_len:1:-1],x,2*x[-1]-x[-1:-window_len:-1]]

    if window == 'flat': #moving average
        w=np.ones(window_len,'d')
    else:
        w=eval('np.'+window+'(window_len)')

    y=np.convolve(w/w.sum(),s,mode='same')
    y = y[window_len-1:-window_len+1]

    return y


##########################################################################################################################################
##### BEGIN FULL PROGRAM #################################################################################################################
##########################################################################################################################################
plt.ion()
    
#### Batch running raw_dictionaries
for root, dirs, files in os.walk('/Users/frio/GoogleDrive/'+corename+'/raw_dictionaries'):
    if verbose ==1:
        print files
    plt.ion()
    
if files[0] == '.DS_Store':
    files = files[1:]
if files[0] == 'Icon\r':
    files = files[1:]

for file in files[:]:   
    filepath = "/Users/frio/GoogleDrive/"+corename+"/raw_dictionaries/" + file
    splitfilepath = filepath.rpartition("/")
    filename = splitfilepath[-1]
    print filepath

    ##### READ IN RAW DATA FILE FROM MELTER ########################################
    if verbose ==1:
        filepath = raw_input("Give filepath: ")
        splitfilepath = filepath.rpartition("/")
        filename = splitfilepath[-1]

    ## If already processed, and reading from binary dictionary file
    filetype = [i for i in range(len(filepath)) if filepath.startswith('/Users/frio/GoogleDrive/'+corename+'/raw_dictionaries/raw')] 
    if len(filetype) >= 1:
        data = open(filepath, "r")                                   # open bininary file to read
        data_dict = pickle.load(data)  
        data_dict["flag"] = data_dict["flag"][:].astype("string")
        data_dict["flag1"] = deepcopy(data_dict["flag"])
        data_dict["flag1"][:] = '.'                                              #rewrites flag as soon as it is read in... Will need to change after first round of reprocessing
        data_dict["flag2"] = deepcopy(data_dict["flag"])
        data_dict["flag2"][:] = '.'                                              #rewrites flag as soon as it is read in... Will need to change after first round of reprocessing
        data_dict["flag3"] = deepcopy(data_dict["flag"])
        data_dict["flag3"][:] = '.'                                              #rewrites flag as soon as it is read in... Will need to change after first round of reprocessing
        data_dict["flag4"] = deepcopy(data_dict["flag"])
        data_dict["flag4"][:] = '.'                                              #rewrites flag as soon as it is read in... Will need to change after first round of reprocessing
        data_dict["flag5"] = deepcopy(data_dict["flag"])
        data_dict["flag5"][:] = '.'                                              #rewrites flag as soon as it is read in... Will need to change after first round of reprocessing
        data_dict["flag6"] = deepcopy(data_dict["flag"])
        if filepath.startswith('/Users/frio/GoogleDrive/'+corename+'/raw_dictionaries/rawHBDS'):
            data_dict["flag6"][:] = '1102'                      
        if filepath.startswith('/Users/frio/GoogleDrive/'+corename+'/raw_dictionaries/rawHIDS'):
            data_dict["flag6"][:] = '2130'                        
    else:
        data = np.loadtxt(filepath, skiprows = 1, dtype = "S")
        data_dict = {}
        
        ## If run on Picarro 1102, ODO read in with this formatting ####################
        filetype = [i for i in range(len(filepath)) if filepath.startswith('/Users/frio/GoogleDrive/'+corename+'/raw/HBDS')]
        if len(filetype) >= 1:
            data_dict["j_days"] = data[:,2].astype("float")
            data_dict["j_days"] = data_dict["j_days"] * 60 * 60 * 24    # convert into seconds
            data_dict["time_delay"] = np.diff(data_dict["j_days"])
            data_dict["epoch"] = data[:,5].astype("float")[:-1]
            data_dict["water_ppm"] = data[:,14].astype("float") [:-1]
            data_dict["d18o"] = data[:,16].astype("float")[:-1] # 17=D_1816_AVE1
            data_dict["dD"] = data[:,19].astype("float")[:-1]   # 20=D_DH_AVE1
            data_dict["carousel_pos"] = data[:,59].astype("float")[:-1]
            data_dict["vial_num"] = data[:,61].astype("float")[:-1]
            data_dict["start_depth"] = data[:,62].astype("float")[:-1]
            data_dict["end_depth"] = data[:,63].astype("float")[:-1]
            data_dict["true_depth"] = data[:,65].astype("float")[:-1]
            data_dict["ec_value"] = data[:,66].astype("float")[:-1]
            data_dict["ec_value"] = data_dict["ec_value"] * 10
            data_dict["valco_pos"] = data[:,68].astype("float")[:-1]
            data_dict["comments"] = data[:,69].astype("float")[:-1]
            data_dict["flag"] = np.arange(len(data_dict["time_delay"]))
            data_dict["flag1"] = deepcopy(data_dict["flag"])
            data_dict["flag1"][:] = '.' 
            data_dict["flag2"] = deepcopy(data_dict["flag"])
            data_dict["flag2"][:] = '.' 
            data_dict["flag3"] = deepcopy(data_dict["flag"])
            data_dict["flag3"][:] = '.'  
            data_dict["flag4"] = deepcopy(data_dict["flag"])
            data_dict["flag4"][:] = '.' 
            data_dict["flag5"] = deepcopy(data_dict["flag"])
            data_dict["flag5"][:] = '.' 
            data_dict["flag6"] = deepcopy(data_dict["flag"])
            data_dict["flag6"][:] = '1102'
        
        ## If run on Picarro 2130, KES read in with this formatting ####################
        filetype = [i for i in range(len(filepath)) if filepath.startswith('/Users/frio/GoogleDrive/'+corename+'/raw/HIDS')] 

        if len(filetype) >= 1:
            data_dict["j_days"] = data[:,2].astype("float")
            data_dict["j_days"] = data_dict["j_days"] * 60 * 60 * 24         # convert into seconds
            data_dict["time_delay"] = np.diff(data_dict["j_days"])
            data_dict["epoch"] = data[:,5].astype("float")[:-1]
            data_dict["water_ppm"] = data[:,16].astype("float")[:-1]
            data_dict["d18o"] = data[:,17].astype("float")[:-1] 
            data_dict["dD"] = data[:,18].astype("float")[:-1] 
            data_dict["carousel_pos"] = data[:,24].astype("float")[:-1]
            data_dict["vial_num"] = data[:,26].astype("float")[:-1]
            data_dict["start_depth"] = data[:,27].astype("float")[:-1]
            data_dict["end_depth"] = data[:,28].astype("float")[:-1]
            data_dict["true_depth"] = data[:,30].astype("float")[:-1]
            data_dict["ec_value"] = data[:,31].astype("float")[:-1]
            data_dict["ec_value"] = data_dict["ec_value"] * 10
            data_dict["valco_pos"] = data[:,32].astype("float")[:-1]
            data_dict["comments"] = data[:,33].astype("float")[:-1]
            data_dict["flag"] = np.arange(len(data_dict["time_delay"]))
            data_dict["flag1"] = deepcopy(data_dict["flag"])
            data_dict["flag1"][:] = '.' 
            data_dict["flag2"] = deepcopy(data_dict["flag"])
            data_dict["flag2"][:] = '.' 
            data_dict["flag3"] = deepcopy(data_dict["flag"])
            data_dict["flag3"][:] = '.'  
            data_dict["flag4"] = deepcopy(data_dict["flag"])
            data_dict["flag4"][:] = '.' 
            data_dict["flag5"] = deepcopy(data_dict["flag"])
            data_dict["flag5"][:] = '.' 
            data_dict["flag6"] = deepcopy(data_dict["flag"])
            data_dict["flag6"][:] = '2130'

        # If run on Picarro 2130 and a test, KES read in with this formatting #########
        filetype = [i for i in range(len(filepath)) if filepath.startswith('/Users/frio/GoogleDrive/'+corename+'/test/HIDS')] 

        if len(filetype) >= 1:
            data_dict["j_days"] = data[:,2].astype("float")
            data_dict["j_days"] = data_dict["j_days"] * 60 * 60 * 24         # convert into seconds
            data_dict["time_delay"] = np.diff(data_dict["j_days"])
            data_dict["epoch"] = data[:,5].astype("float")[:-1]
            data_dict["water_ppm"] = data[:,16].astype("float")[:-1]
            data_dict["d18o"] = data[:,17].astype("float")[:-1]
            data_dict["dD"] = data[:,18].astype("float")[:-1]
            data_dict["carousel_pos"] = data[:,24].astype("float")[:-1]
            data_dict["vial_num"] = data[:,26].astype("float")[:-1]
            data_dict["start_depth"] = data[:,27].astype("float")[:-1]
            data_dict["end_depth"] = data[:,28].astype("float")[:-1]
            data_dict["true_depth"] = data[:,30].astype("float")[:-1]
            data_dict["ec_value"] = data[:,31].astype("float")[:-1]
            data_dict["ec_value"] = data_dict["ec_value"] * 10
            data_dict["valco_pos"] = data[:,32].astype("float")[:-1]
            data_dict["comments"] = data[:,33].astype("float")[:-1]
            data_dict["flag"] = np.arange(len(data_dict["time_delay"]))
            data_dict["flag1"] = deepcopy(data_dict["flag"])
            data_dict["flag1"][:] = '.' 
            data_dict["flag2"] = deepcopy(data_dict["flag"])
            data_dict["flag2"][:] = '.' 
            data_dict["flag3"] = deepcopy(data_dict["flag"])
            data_dict["flag3"][:] = '.'  
            data_dict["flag4"] = deepcopy(ata_dict["flag"])
            data_dict["flag4"][:] = '.' 
            data_dict["flag5"] = deepcopy(data_dict["flag"])
            data_dict["flag5"][:] = '.' 
            data_dict["flag6"] = deepcopy(data_dict["flag"])
            data_dict["flag6"][:] = '2130'
            
        data_dict["dexcess"] = data_dict["dD"]-8*data_dict["d18o"]
        data_dict["index"] = np.arange(len(data_dict["time_delay"]))

    allpositive = np.where(data_dict["time_delay"]>= 0)[0]
    data_dict["time_delay"] = data_dict["time_delay"][allpositive]
    mean_time_delay = np.mean(data_dict["time_delay"])
    secs = np.cumsum(data_dict["time_delay"])

    ##### H20 CONCENTRATION FILTER PRIOR TO PLOTTING AND CALCULATIONS ##############
    ## flag set at "." for all good
    ## change first character to W if water concentration low
    h2obad = np.where(data_dict["water_ppm"]<= watertoolow)[0]
    for f in h2obad:
        data_dict["flag1"][f] = 'W'
    
    ##### PLOT RAW DATA ############################################################
    plt.close("all")

    ## EXCLUDE ZEROS AND DETERMINE RANGE FOR PLOTS #################################
    nonzero = np.where(data_dict["vial_num"]!=0)[0]
    nonzero_index_vial_num = data_dict["index"] #[nonzero]
    if len(nonzero_index_vial_num)>=1:
        nonzero_vial_num = data_dict["vial_num"]#[nonzero]
        maxvial = nonzero_vial_num[-1] + 10
        minvial = nonzero_vial_num[0] - 10    
     
    nonzero = np.where(data_dict["true_depth"]!=0)[0]                       
    nonzero_index_true_depth = data_dict["index"]#[nonzero]
    nonzero_true_depth = data_dict["true_depth"]#[nonzero]
    if len(nonzero)>=1:
        nonzero_true_depth = data_dict["true_depth"]#[nonzero]
        nonzero_index_true_depth = data_dict["index"]#[nonzero]
        maxdepth = nonzero_true_depth[-1] + 10
        mindepth = nonzero_true_depth[0] - 10     

    ## PLOT DATA ###################################################################
    fig21 = plt.figure(21)
    fig21_ax1 = fig21.add_subplot(411)
    fig21_ax1.plot(data_dict["index"], data_dict["d18o"], "b-")
    fig21_ax1.set_ylabel("d18o")
    fig21_ax1.axis([0,data_dict["index"][-1],-50,0])
    fig21_ax2 = fig21.add_subplot(412)
    fig21_ax2.plot(data_dict["index"], data_dict["dD"], "r-")
    fig21_ax2.set_ylabel("dD")
    fig21_ax2.axis([0,data_dict["index"][-1],-500,0])
    fig21_ax3 = fig21.add_subplot(413)
    fig21_ax3.plot(data_dict["index"], data_dict["water_ppm"], "k-")
    fig21_ax3.set_ylabel("water ppm")
    fig21_ax3 = fig21.add_subplot(414)
    fig21_ax3.plot(data_dict["index"], data_dict["dexcess"], "g-")
    fig21_ax3.set_ylabel("d-excess")
    fig21_ax3.set_xlabel("Index")
    fig21_ax1.set_title("%s" %(os.path.splitext(filepath)[0]))

    fig22 = plt.figure(22)                                                                         
    fig22_ax1 = fig22.add_subplot(311)
    fig22_ax1.plot(nonzero_index_vial_num, nonzero_vial_num, "b-")
    fig22_ax1.set_ylabel("vial number")
    fig22_ax2 = fig22.add_subplot(312)
    fig22_ax2.plot(nonzero_index_true_depth, nonzero_true_depth, "r-")
    fig22_ax2.set_ylabel("true depth")
    fig22_ax3 = fig22.add_subplot(313)
    fig22_ax3.plot(data_dict["index"], data_dict["ec_value"], "k-")
    fig22_ax3.set_ylabel("EC Value")
    fig22_ax3.set_xlabel("Index")
    fig22_ax1.set_title("%s" %(os.path.splitext(filepath)[0]))

    fig23 = plt.figure(23)
    fig23_ax1 = fig23.add_subplot(311)
    fig23_ax1.plot(data_dict["index"], data_dict["valco_pos"], "b-")
    fig23_ax1.set_ylabel("valco position")
    fig23_ax2 = fig23.add_subplot(312)
    fig23_ax2.plot(data_dict["index"], data_dict["comments"], "r-")
    fig23_ax2.set_ylabel("comments")
    fig23_ax3 = fig23.add_subplot(313)
    fig23_ax3.plot(data_dict["index"], data_dict["carousel_pos"], "g-")
    fig23_ax3.set_ylabel("carousel position")
    fig23_ax3.set_xlabel("Index")
    fig23_ax1.set_title("%s" %(os.path.splitext(filepath)[0]))

    ##### BEGINING OF ALLAN FUNCTION ###############################################

    ## AM ALLAN VARIANCE FROM MIDNIGHT TO 1 HOUR BEFORE AM VALCO TO AVOID H20 DROP OUT IN INITIATION
    amallanbegin = 100
    amvalco = np.where(data_dict["comments"]==142)[0]  
    amallanaved18o = 0
    amallanstdevd18o = 0
    amallan10secd18o = 0
    amallan60secd18o = 0
    amallan600secd18o = 0
    amallan3600secd18o = 0
    amallanavedD = 0
    amallanstdevdD = 0
    amallan10secdD = 0
    amallan60secdD = 0
    amallan600secdD = 0
    amallan3600secdD = 0
    amallanh2o = 0
    if len(amvalco)!=0 and amvalco[0]>4200:
        amallanend = amvalco[0]-4000
        if len(h2obad)!=0:
            if h2obad[0] <= amallanend:
                amallanend = h2obad[0]-100
        amrun_allan = perform_allan(amallanbegin, amallanend)
        amallanaved18o = amrun_allan[0]
        amallanstdevd18o = amrun_allan[1]
        amallan10secd18o = amrun_allan[2]
        amallan60secd18o = amrun_allan[3]
        amallan600secd18o = amrun_allan[4]
        amallan3600secd18o = amrun_allan[5]
        amallanavedD = amrun_allan[6]
        amallanstdevdD = amrun_allan[7]
        amallan10secdD = amrun_allan[8]
        amallan60secdD = amrun_allan[9]
        amallan600secdD = amrun_allan[10]
        amallan3600secdD = amrun_allan[11]
        amallanh2o = amrun_allan[12]

    ## PM ALLAN VARIANCE FROM 10 MIN AFTER END OF PM VALCO (VALCO_POS==3), TO END OF FILE
    pmvalcoend = np.where(data_dict["comments"]==172)[0] 
    pmallanaved18o = 0
    pmallanstdevd18o = 0
    pmallan10secd18o = 0
    pmallan60secd18o = 0
    pmallan600secd18o = 0
    pmallan3600secd18o = 0
    pmallanavedD = 0
    pmallanstdevdD = 0
    pmallan10secdD = 0
    pmallan60secdD = 0
    pmallan600secdD = 0
    pmallan36000secdD = 0
    pmallanh2o = 0
    if len(pmvalcoend)!=0:
        pmallanbegin = pmvalcoend[-1]+2000 #was 1000
        pmallanend = data_dict["index"][-1]
        if len(h2obad)!=0:
            if h2obad[-1] >= pmallanbegin:
                pmallanbegin = h2obad[-1]+100
        if pmallanbegin <= (pmallanend-3000):
            pmrun_allan = perform_allan(pmallanbegin, pmallanend)
            pmallanaved18o = pmrun_allan[0]
            pmallanstdevd18o = pmrun_allan[1]
            pmallan10secd18o = pmrun_allan[2]
            pmallan60secd18o = pmrun_allan[3]
            pmallan600secd18o = pmrun_allan[4]
            pmallan3600secd18o = pmrun_allan[5]
            pmallanavedD = pmrun_allan[6]
            pmallanstdevdD = pmrun_allan[7]
            pmallan10secdD = pmrun_allan[8]
            pmallan60secdD = pmrun_allan[9]
            pmallan600secdD = pmrun_allan[10]
            pmallan36000secdD = pmrun_allan[11]
            pmallanh2o = pmrun_allan[12]
    ##### END ALLAN FUNCTION########################################################

    ##### PERFORM DIFF FUNCTION (first derivative approximation) ON ISOTOPES AND EC 
    ## PRECEEDED BY SMOOTHING
    smoothd18o = smooth(data_dict["d18o"])
    smoothdD = smooth(data_dict["dD"])
    smooth_ec = smooth(data_dict["ec_value"])
    depth_cm = data_dict["true_depth"]*100  # true_depth in meters*100 = depth in cm
    smooth_depth = smooth(depth_cm)
    minutes = data_dict["j_days"]/60  # j_days in sec/60 = time in minutes
    smooth_time =smooth(minutes[:-1])

    diffindex = data_dict["index"][:-1] 
    diffd18o = np.diff(smoothd18o)
    diffdD = np.diff(smoothdD)
    diff_ec = np.diff(smooth_ec)
    diff_depth = np.diff(smooth_depth)
    diff_time = np.diff(smooth_time)
    meltrate = diff_depth/diff_time
    smooth_meltrate = smooth(meltrate)
    diffdepthindex = nonzero_index_true_depth[:-1]                                                        

    fig31 = plt.figure(31)
    fig31_ax1 = fig31.add_subplot(411)
    fig31_ax1.plot(diffindex, diffd18o, "b-")
    fig31_ax1.set_ylabel("diffd18o")
    fig31_ax2 = fig31.add_subplot(412)
    fig31_ax2.plot(diffindex, diffdD, "r-")
    fig31_ax2.set_ylabel("diffdD")
    fig31_ax3 = fig31.add_subplot(413)
    fig31_ax3.plot(diffindex, diff_ec, "k-")
    fig31_ax3.set_ylabel("diff_ec")
    fig31_ax4 = fig31.add_subplot(414)
    fig31_ax4.plot(diffindex, meltrate, "k-", diffindex, smooth_meltrate, "b-")
    fig31_ax4.axis([0,diffindex[-1],-5,15])
    fig31_ax4.set_ylabel("meltrate")
    fig31_ax4.set_xlabel("Index")
    fig31_ax1.set_title("%s" %(os.path.splitext(filepath)[0]))

    ##### VALCO IDENTIFICATION #####################################################
    ##### Look at comments to locate amvalco and pmvalco
    amvalcobegin = [x for x in data_dict["index"][1:] if data_dict["comments"][x-1]!=142 and data_dict["comments"][x]==142]
    pmvalcobegin = [x for x in data_dict["index"][1:] if data_dict["comments"][x-1]!=172 and data_dict["comments"][x]==172]

    if len(amvalcobegin) > 1:
        amvalcobegin = [amvalcobegin[-1]]
    if len(amvalcobegin) < 1:
        amvalcobegin = [pmvalcobegin[-1]]
    if len(pmvalcobegin) > 1:
        pmvalcobegin = [pmvalcobegin[-1]]
    if len(pmvalcobegin) < 1:
        pmvalcobegin = [amvalcobegin[-1]]
        
    starttime = data_dict["epoch"][amvalcobegin]
    endtime = data_dict["epoch"][pmvalcobegin]
    fullmelttime = ((endtime-starttime)/60)/60
    
    if verbose ==1:
        print "AM valco begin " ,amvalcobegin
        print "PM valco begin ", pmvalcobegin
        print "Full melt time (hours)", fullmelttime

    #### Stop and ask if need to edit?
    if verbose ==1:
        checkbegin = raw_input("Do you want to edit the beginning am valco indices?")
        if checkbegin in ('y', 'ye', 'yes'):
            amvalcobegin = input("Please type new indices list in [ ]...")
            print "New AM valco begin ", amvalcobegin
        checkbegin = raw_input("Do you want to edit the beginning pm valco indices?")
        if checkbegin in ('y', 'ye', 'yes'):
            pmvalcobegin = input("Please type new indices list in [ ]...")
            print "New PM valco begin ", pmvalcobegin
        
    ##### Identify each standard from valco array 
    # AM valco in 0 position PM valco in 1 position   
    trans0 = [x for x in data_dict["index"][amvalcobegin[0]:] if data_dict["valco_pos"][x]==3 and data_dict["valco_pos"][x-2]==1 and data_dict["valco_pos"][x+100]==3]   
    if len(trans0)==0:
        trans0 = [x for x in data_dict["index"][amvalcobegin[0]:] if data_dict["valco_pos"][x]==3 and data_dict["valco_pos"][x-2]==0 and data_dict["valco_pos"][x+100]==3]
    if len(trans0)==0:
        trans0 = amvalcobegin[0]
    trans1 = [x for x in data_dict["index"][amvalcobegin[0]:] if data_dict["valco_pos"][x-2]==3 and data_dict["valco_pos"][x]==4 and data_dict["valco_pos"][x+100]==4]
    trans2 = [x for x in data_dict["index"][amvalcobegin[0]:] if data_dict["valco_pos"][x-2]==4 and data_dict["valco_pos"][x]==5 and data_dict["valco_pos"][x+100]==5]
    trans3 = [x for x in data_dict["index"][amvalcobegin[0]:] if data_dict["valco_pos"][x-2]==5 and data_dict["valco_pos"][x]==6 and data_dict["valco_pos"][x+100]==6]
    trans4 = [x for x in data_dict["index"][amvalcobegin[0]:] if data_dict["valco_pos"][x-2]==6 and data_dict["valco_pos"][x]==5 and data_dict["valco_pos"][x+100]==5]
    trans5 = [x for x in data_dict["index"][amvalcobegin[0]:] if data_dict["valco_pos"][x-2]==5 and data_dict["valco_pos"][x]==4 and data_dict["valco_pos"][x+100]==4]
    trans6 = [x for x in data_dict["index"][amvalcobegin[0]:] if data_dict["valco_pos"][x-2]==4 and data_dict["valco_pos"][x]==3 and data_dict["valco_pos"][x+100]==3]
    trans7 = [x for x in data_dict["index"][amvalcobegin[0]:] if data_dict["valco_pos"][x-2]==3 and data_dict["valco_pos"][x]==1 and data_dict["valco_pos"][x-100]==3]
    if len(trans7)==0:
        trans7 = [x for x in data_dict["index"][amvalcobegin[0]:] if data_dict["valco_pos"][x-2]==3 and data_dict["valco_pos"][x]==0 and data_dict["valco_pos"][x-100]==3]
        
    if verbose ==1:
        print "valco pos changes"
        print trans0
        print trans1
        print trans2
        print trans3
        print trans4
        print trans5
        print trans6
        print trans7

    amtransbegin = np.arange(7)
    amtransbegin[0] = amvalcobegin[0]
    amtransbegin[1] = trans1[0]
    amtransbegin[2] = trans2[0]
    amtransbegin[3] = trans3[0]
    amtransbegin[4] = trans4[0]
    amtransbegin[5] = trans5[0]
    amtransbegin[6] = trans6[0]

    pmtransbegin = np.arange(7)
    pmtransbegin[0] = pmvalcobegin[0]
    pmtransbegin[1] = trans1[-1]
    pmtransbegin[2] = trans2[-1]
    pmtransbegin[3] = trans3[-1]
    pmtransbegin[4] = trans4[-1]
    pmtransbegin[5] = trans5[-1]
    pmtransbegin[6] = trans6[-1]

    ##### Then Identify each standard from isotope transition array (can then be fed to trasfer function)
    ##### FIRST FOR AM VALCO
    amtransindexd18o = []
    amtransindexdD = []
    for i in amtransbegin:
        tranbegin = i
        tranend = tranbegin+150
        d18otransition = np.max(abs(diffd18o[tranbegin:tranend]))
        transd18o = [x for x in data_dict["index"][tranbegin:tranend] if abs(diffd18o[x])==d18otransition]
        amtransindexd18o.append(transd18o[0])
        dDtransition = np.max(abs(diffdD[tranbegin:tranend]))
        transdD = [x for x in data_dict["index"][tranbegin:tranend] if abs(diffdD[x])==dDtransition]
        amtransindexdD.append(transdD[0])

    ##### REPEAT FOR PM VALCO                                                        ### Need to put in error check, if no pm valco, don't read in values
    pmtransindexd18o = []
    pmtransindexdD = []
    for i in pmtransbegin:
        tranbegin = i
        tranend = tranbegin+150
        d18otransition = np.max(abs(diffd18o[tranbegin:tranend]))
        transd18o = [x for x in data_dict["index"][tranbegin:tranend] if abs(diffd18o[x])==d18otransition]
        pmtransindexd18o.append(transd18o[0])
        dDtransition = np.max(abs(diffdD[tranbegin:tranend]))
        transdD = [x for x in data_dict["index"][tranbegin:tranend] if abs(diffdD[x])==dDtransition]
        pmtransindexdD.append(transdD[0])

    if verbose ==1:
        print "index for am valco isotope transitions, and delays"
        print amtransindexd18o
        print amtransindexdD

        print "index for pm valco isotope transitions"                                   ### Need to put in error check, if no pm valco, don't read in values
        print pmtransindexd18o
        print pmtransindexdD


    ##### PUT IN TRANSFER FUNCTION CALL FOR EACH OF THE VALCO TRANSITIONS LISTED ABOVE, then Apply Memory correction to all valco transitions ##########################
    ## Start by replicating full isotope arrays
    valcomemd18o = data_dict["d18o"].copy()
    valcomemdD = data_dict["dD"].copy()
    ## CREATE ARRAY FOR ALL VARIABLES TO BE PUT IN
    extrapolatedd18o = []
    extrapolatedD = []
    sigma1_Transd18o = []
    sigma2_Transd18o = []
    sigma1_TransdD = []
    sigma2_TransdD = []
    valco_skewsigma_d18o = []
    valco_normsigma_d18o = []
    valco_skewsigma_dD = []
    valco_normsigma_dD = []
    count = 1
    counter = 1
    
    #### BEGIN VALCO PROCESSING FOR 1102
    if data_dict["epoch"][0] < 1325376000:  # before 20120101, WAIS06A, 1102 with longer sampling time in between each data point, 5 minute valco
        for m in data_dict["index"]:
            data_dict["flag5"][m] = 'A'
        print "Data processing 1102 data"
        ## Create spline and RUN THE TRANSFER FUNCTION IN LOOP THROUGH ALL AM VALCO TRANSITIONS ##########
        for i in amtransindexd18o:
            Index1 = i - 50
            Index2 = i + 100
            previousbegin = i-75
            previousend = i-50
            currentbegin = i+75
            currentend = i+100
            valcosegindex = data_dict["index"][Index1:Index2]
            valcosegindexnorm = valcosegindex - Index1
            valcosegd18o = data_dict["d18o"][Index1:Index2]
            previousvalued18o = np.mean(data_dict["d18o"][previousbegin:previousend])
            currentvalued18o = np.mean(data_dict["d18o"][currentbegin:currentend])
            stepsized18o = (currentvalued18o-previousvalued18o) 
            valcosegnormd18o = (valcosegd18o-previousvalued18o)/stepsized18o
            valcosegdD = data_dict["dD"][Index1:Index2]
            previousvaluedD = np.mean(data_dict["dD"][previousbegin:previousend])
            currentvaluedD = np.mean(data_dict["dD"][currentbegin:currentend])
            stepsizedD = (currentvaluedD-previousvaluedD) 
            valcosegnormdD = (valcosegdD-previousvaluedD)/stepsizedD
            
            badtransh2o = [x for x in data_dict["index"][Index1:Index2] if data_dict["flag1"][x]=="W"]
            if len(badtransh2o)<=50:
                if counter == 1:
                    valcoindex = valcosegindexnorm
                    valcod18o = valcosegnormd18o
                    valcodD = valcosegnormdD
                    counter = 2
#                #### only for when first transitions buggered - start
#                if counter == 2:
#                    valcoindex = valcosegindexnorm
#                    valcod18o = valcosegnormd18o
#                    valcodD = valcosegnormdD
#                    counter = 3
#                #### only for when first transitions buggered - end
                if counter == 2:
                    valcoindex = np.append(valcoindex,valcosegindexnorm)
                    valcod18o = np.append(valcod18o,valcosegnormd18o)
                    valcodD = np.append(valcodD,valcosegnormdD)
                
                run_am_valco_transfer = PerformTransfer(type = 'AMValco', int = 1, TransferIndex1 = Index1, TransferIndex2 = Index2, StepIndex = i)
                # output is: extrapolated18o, extrapolatedD, sigma1_Transd18o, sigma2_Transd18o, sigma1_TransdD, sigma2_TransdD, time_n_Transd18o, cdf_Transd18o_norm, time_n_TransdD, cdf_TransdD_norm, sig_opt_d18o, sig_opt_dD
                extrapolatedd18o.append(run_am_valco_transfer[0])
                extrapolatedD.append(run_am_valco_transfer[1])
                sigma1_Transd18o.append(run_am_valco_transfer[2])
                sigma2_Transd18o.append(run_am_valco_transfer[3])
                sigma1_TransdD.append(run_am_valco_transfer[4])
                sigma2_TransdD.append(run_am_valco_transfer[5])
                valco_skewsigma_d18o.append(run_am_valco_transfer[11])
                valco_normsigma_d18o.append(run_am_valco_transfer[12])
                valco_skewsigma_dD.append(run_am_valco_transfer[13])
                valco_normsigma_dD.append(run_am_valco_transfer[14])

                if count == 2:
                    amtimed18o = run_am_valco_transfer[6]
                    amcdfd18o = run_am_valco_transfer[7]
                    amtimedD = run_am_valco_transfer[8]
                    amcdfdD = run_am_valco_transfer[9]
            count = count + 1
        ## RUN THE TRANSFER FUNCTION  IN LOOP THROUGH ALL PM VALCO TRANSITIONS #########
        count = 1
        if filepath == '/Users/frio/GoogleDrive/WAIS06AData/raw_dictionaries/rawHBDS92-20111209-0940-Data.dat':
            pmtransindexd18o = pmtransindexd18o[1:]
            extrapolatedd18o.append(extrapolatedd18o[-1])
            extrapolatedD.append(extrapolatedD[-1])
        for i in pmtransindexd18o:
            Index1 = i - 50
            Index2 = i + 100
            previousbegin = i-75
            previousend = i-50
            currentbegin = i+75
            currentend = i+100
            valcosegindex = data_dict["index"][Index1:Index2]
            valcosegindexnorm = valcosegindex - Index1
            valcosegd18o = data_dict["d18o"][Index1:Index2]
            previousvalued18o = np.mean(data_dict["d18o"][previousbegin:previousend])
            currentvalued18o = np.mean(data_dict["d18o"][currentbegin:currentend])
            stepsized18o = (currentvalued18o-previousvalued18o) 
            valcosegnormd18o = (valcosegd18o-previousvalued18o)/stepsized18o
            valcosegdD = data_dict["dD"][Index1:Index2]
            previousvaluedD = np.mean(data_dict["dD"][previousbegin:previousend])
            currentvaluedD = np.mean(data_dict["dD"][currentbegin:currentend])
            stepsizedD = (currentvaluedD-previousvaluedD) 
            valcosegnormdD = (valcosegdD-previousvaluedD)/stepsizedD
            
            badtransh2o = [x for x in data_dict["index"][Index1:Index2] if data_dict["flag1"][x]=="W"]
            counter  = 1 #### only for when first transitions buggered
            if len(badtransh2o)<=50:
                if counter == 1:
                    valcoindex = valcosegindexnorm
                    valcod18o = valcosegnormd18o
                    valcodD = valcosegnormdD
                    counter = 2
#                #### only for when first transitions buggered - start
#                if counter == 2:
#                    valcoindex = valcosegindexnorm
#                    valcod18o = valcosegnormd18o
#                    valcodD = valcosegnormdD
#                    counter = 3
#                #### only for when first transitions buggered - end
                if counter == 2:
                    valcoindex = np.append(valcoindex,valcosegindexnorm)
                    valcod18o = np.append(valcod18o,valcosegnormd18o)
                    valcodD = np.append(valcodD,valcosegnormdD)
                
                run_pm_valco_transfer = PerformTransfer(type='PMValco', int = 3, TransferIndex1 = Index1, TransferIndex2 = Index2, StepIndex = i)   
                # output is: extrapolated18o, extrapolatedD, sigma1_Transd18o, sigma2_Transd18o, sigma1_TransdD, sigma2_TransdD, time_n_Transd18o, cdf_Transd18o_norm, time_n_TransdD, cdf_TransdD_norm
                extrapolatedd18o.append(run_pm_valco_transfer[0])
                extrapolatedD.append(run_pm_valco_transfer[1])
                sigma1_Transd18o.append(run_pm_valco_transfer[2])
                sigma2_Transd18o.append(run_pm_valco_transfer[3])
                sigma1_TransdD.append(run_pm_valco_transfer[4])
                sigma2_TransdD.append(run_pm_valco_transfer[5])
                valco_skewsigma_d18o.append(run_am_valco_transfer[11])
                valco_normsigma_d18o.append(run_am_valco_transfer[12])
                valco_skewsigma_dD.append(run_am_valco_transfer[13])
                valco_normsigma_dD.append(run_am_valco_transfer[14])
                if count == 2:
                    pmtimed18o = run_pm_valco_transfer[6]
                    pmcdfd18o = run_pm_valco_transfer[7]
                    pmtimedD = run_pm_valco_transfer[8]
                    pmcdfdD = run_pm_valco_transfer[9]
            count = count + 1
        ave_valco_skewsigma_d18o = np.mean(valco_skewsigma_d18o)
        ave_valco_normsigma_d18o = np.mean(valco_normsigma_d18o)
        ave_valco_skewsigma_dD = np.mean(valco_skewsigma_dD) 
        ave_valco_normsigma_dD = np.mean(valco_normsigma_dD)    
        sortindex = np.argsort(valcoindex)
        sortedvalcoindex = valcoindex[sortindex]
        sortedvalcod18o = valcod18o[sortindex]
        sortedvalcodD = valcodD[sortindex]   
        avevalcod18o = valcosegnormd18o.copy()
        avevalcodD = valcosegnormdD.copy()
        for p in valcosegindexnorm:
            aveindex = np.where(sortedvalcoindex==p)[0]
            avevalcod18o[p] = np.mean(sortedvalcod18o[aveindex])
            avevalcodD[p] = np.mean(sortedvalcodD[aveindex])
        smavevalcod18o = smooth(avevalcod18o)
        smavevalcodD = smooth(avevalcodD)
        valcosplined18o = UnivariateSpline(sortedvalcoindex,sortedvalcod18o,k=4, s=10.5)
        valcomomemcod18o = valcosplined18o(valcosegindexnorm)
        normvalcomemcod18o = (valcomomemcod18o-np.min(valcomomemcod18o))/(np.max(valcomomemcod18o)-np.min(valcomomemcod18o))
        valcoresd18o = valcomomemcod18o-avevalcod18o
        valcosplinedD = UnivariateSpline(sortedvalcoindex,sortedvalcodD,k=4, s=4.5)
        valcomomemcodD = valcosplinedD(valcosegindexnorm)
        normvalcomemcodD = (valcomomemcodD-np.min(valcomomemcodD))/(np.max(valcomomemcodD)-np.min(valcomomemcodD))
        valcoresdD = valcomomemcodD-avevalcodD
        
        fig420 = plt.figure(420)
        clear = plt.clf()
        fig420_ax1 = fig420.add_subplot(211)
        fig420_ax1.plot(sortedvalcoindex, sortedvalcod18o, "g-", valcosegindexnorm, avevalcod18o, "b-", valcosegindexnorm, smavevalcod18o, "k-") #valcosegindexnorm, valcosegnormd18o, "b-", valcosegindexnorm, valcosegnormneamemcod18o, "g-", 
        fig420_ax1.set_ylabel("d18o")
        fig420_ax2 = fig420.add_subplot(212)
        fig420_ax2.plot(sortedvalcoindex, sortedvalcodD, "m-", valcosegindexnorm, avevalcodD, "r-", valcosegindexnorm, smavevalcodD, "k-") #valcosegindexnorm, valcosegnormdD, "r-", valcosegindexnorm, valcosegnormneamemcodD, "m-", 
        fig420_ax2.set_ylabel("dD")
        fig420_ax2.set_xlabel("Index")
        fig420_ax1.set_title("%s" %(os.path.splitext(filepath)[0]))
        
        if verbose ==1:
            print extrapolatedd18o
            print extrapolatedD
            print sigma1_Transd18o
            print sigma2_Transd18o
            print sigma1_TransdD
            print sigma2_TransdD

        avesigma1_Transd18o = np.mean(sigma1_Transd18o)
        avesigma2_Transd18o = np.mean(sigma2_Transd18o)
        avesigma1_TransdD = np.mean(sigma1_TransdD)
        avesigma2_TransdD = np.mean(sigma2_TransdD)

        ##### CALCULATE RAW VALUES FOR STANDARDS IN VALCO
        rawd18o = []
        stdevrawd18o = []
        rawdD = []
        stdevrawdD = []

        for i in amtransbegin:
            begin = i-70
            end = i
            rawd18o.append(np.mean(data_dict["d18o"][begin:end]))
            stdevrawd18o.append(np.std(data_dict["d18o"][begin:end]))
            rawdD.append(np.mean(data_dict["dD"][begin:end]))
            stdevrawdD.append(np.std(data_dict["dD"][begin:end]))

        begin = trans7[0]-70
        end = trans7[0]
        rawd18o.append(np.mean(data_dict["d18o"][begin:end]))
        stdevrawd18o.append(np.std(data_dict["d18o"][begin:end]))
        rawdD.append(np.mean(data_dict["dD"][begin:end]))
        stdevrawdD.append(np.std(data_dict["dD"][begin:end]))

        for i in pmtransbegin:
            begin = i-70
            end = i
            rawd18o.append(np.mean(data_dict["d18o"][begin:end]))
            stdevrawd18o.append(np.std(data_dict["d18o"][begin:end]))
            rawdD.append(np.mean(data_dict["dD"][begin:end]))
            stdevrawdD.append(np.std(data_dict["dD"][begin:end]))

        begin = trans7[-1]-70
        end = trans7[-1]
        rawd18o.append(np.mean(data_dict["d18o"][begin:end]))
        stdevrawd18o.append(np.std(data_dict["d18o"][begin:end]))
        rawdD.append(np.mean(data_dict["dD"][begin:end]))
        stdevrawdD.append(np.std(data_dict["dD"][begin:end]))

        ## ASSIGN EXTRAPOLATED VALUES ############################################
        # Assign KBW measured/raw isotope values from extrapolation ###################                                     ### Need to put in error check, if no pm valco, don't create 4 positions, only 2, OR NO AM VALCO IF DAY WAS RESTARTED OR SPLIT DUE TO SHIFT
        rawkbwd18o = [extrapolatedd18o[0],extrapolatedd18o[6],extrapolatedd18o[7],extrapolatedd18o[13]]
        rawkbwdD = [extrapolatedD[0],extrapolatedD[6],extrapolatedD[7],extrapolatedD[13]]
        
        if verbose ==1:
            print "KBW extrapolated d18o valco values ", rawkbwd18o
            print "KBW extrapolated dD valco values ", rawkbwdD

        ## Assign KAW measured isotope values #######################################                                         ### Need to put in error check, if no pm valco, don't create 4 positions, only 2
        rawkawd18o = [extrapolatedd18o[1],extrapolatedd18o[5],extrapolatedd18o[8],extrapolatedd18o[12]]
        rawkawdD = [extrapolatedD[1],extrapolatedD[5],extrapolatedD[8],extrapolatedD[12]]
        if verbose ==1:
            print "KAW extrapolated d18o valco values ", rawkawd18o
            print "KAW extrapolated dD valco values ", rawkawdD 

        ## Assign KGW measured isotope values ##########################################                                         ### Need to put in error check, if no pm valco, don't create 4 positions, only 2
        rawkgwd18o = [extrapolatedd18o[2],extrapolatedd18o[4],extrapolatedd18o[9],extrapolatedd18o[11]]
        rawkgwdD = [extrapolatedD[2],extrapolatedD[4],extrapolatedD[9],extrapolatedD[11]]
        if verbose ==1:
            print "KGW extrapolated d18o valco values ", rawkgwd18o
            print "KGW extrapolated dD valco values ", rawkgwdD

        ## Assign KPW measured isotope values #######################################                                         ### Need to put in error check, if no pm valco, don't create 2 positions, only 2
        rawkpwd18o = [extrapolatedd18o[3],extrapolatedd18o[10]]
        rawkpwdD = [extrapolatedD[3],extrapolatedD[10]]
        if verbose ==1:
            print "KPW extrapolated d18o valco values ", rawkpwd18o
            print "KPW extrapolated dD valco values ", rawkpwdD
            
        #### END VALCO PROCESSING FOR 1102
            
            
    #### BEGING VALCO PROCESSING FOR 2130 BUT 5 MINUTE VALCOS   ### first KBW removed to see if that gets rid of sigma outliers and standard issues
    if data_dict["epoch"][0] < 1354320001 and data_dict["epoch"][0] > 1325376000:  # before 20121201, WAIS06A, 2130, 5 minute valco and 1,5,1 for drift, but after switch to 2130
        for m in data_dict["index"]:
            data_dict["flag5"][m] = 'B'
        print "Data processing 2130 and 5 min valco data"
        ## Create spline and RUN THE TRANSFER FUNCTION IN LOOP THROUGH ALL AM VALCO TRANSITIONS ##########
        for i in amtransindexd18o[1:]:
            Index1 = i - 250
            Index2 = i + 250
            previousbegin = i-250
            previousend = i-150
            currentbegin = i+150
            currentend = i+250
            valcosegindex = data_dict["index"][Index1:Index2]
            valcosegindexnorm = valcosegindex - Index1
            valcosegd18o = data_dict["d18o"][Index1:Index2]
            previousvalued18o = np.mean(data_dict["d18o"][previousbegin:previousend])
            currentvalued18o = np.mean(data_dict["d18o"][currentbegin:currentend])
            stepsized18o = (currentvalued18o-previousvalued18o) 
            valcosegnormd18o = (valcosegd18o-previousvalued18o)/stepsized18o
            valcosegdD = data_dict["dD"][Index1:Index2]
            previousvaluedD = np.mean(data_dict["dD"][previousbegin:previousend])
            currentvaluedD = np.mean(data_dict["dD"][currentbegin:currentend])
            stepsizedD = (currentvaluedD-previousvaluedD) 
            valcosegnormdD = (valcosegdD-previousvaluedD)/stepsizedD
            
            badtransh2o = [x for x in data_dict["index"][Index1:Index2] if data_dict["flag1"][x]=="W"]
            if len(badtransh2o)<=200:
                if counter == 1:
                    valcoindex = valcosegindexnorm
                    valcod18o = valcosegnormd18o
                    valcodD = valcosegnormdD
                    counter = 2
#                    #### only for when first transitions buggered - start
#                    if counter == 2:
#                        valcoindex = valcosegindexnorm
#                        valcod18o = valcosegnormd18o
#                        valcodD = valcosegnormdD
#                        counter = 3
#                    #### only for when first transitions buggered - end
                if counter == 2:
                    valcoindex = np.append(valcoindex,valcosegindexnorm)
                    valcod18o = np.append(valcod18o,valcosegnormd18o)
                    valcodD = np.append(valcodD,valcosegnormdD)
                
                run_am_valco_transfer = PerformTransfer(type = 'AMValco', int = 1, TransferIndex1 = Index1, TransferIndex2 = Index2, StepIndex = i)
                # output is: extrapolated18o, extrapolatedD, sigma1_Transd18o, sigma2_Transd18o, sigma1_TransdD, sigma2_TransdD, time_n_Transd18o, cdf_Transd18o_norm, time_n_TransdD, cdf_TransdD_norm
                extrapolatedd18o.append(run_am_valco_transfer[0])
                extrapolatedD.append(run_am_valco_transfer[1])
                sigma1_Transd18o.append(run_am_valco_transfer[2])
                sigma2_Transd18o.append(run_am_valco_transfer[3])
                sigma1_TransdD.append(run_am_valco_transfer[4])
                sigma2_TransdD.append(run_am_valco_transfer[5])
                valco_skewsigma_d18o.append(run_am_valco_transfer[11])
                valco_normsigma_d18o.append(run_am_valco_transfer[12])
                valco_skewsigma_dD.append(run_am_valco_transfer[13])
                valco_normsigma_dD.append(run_am_valco_transfer[14])
                if count == 2:
                    amtimed18o = run_am_valco_transfer[6]
                    amcdfd18o = run_am_valco_transfer[7]
                    amtimedD = run_am_valco_transfer[8]
                    amcdfdD = run_am_valco_transfer[9]
            count = count + 1
            

        ## RUN THE TRANSFER FUNCTION  IN LOOP THROUGH ALL PM VALCO TRANSITIONS #########
        count = 1
        if filepath =="/Users/frio/GoogleDrive/WAIS06AData/raw_dictionaries/rawHIDS2038-20121009-113525Z-DataLog_User_A.dat" or \
            filepath == "/Users/frio/GoogleDrive/WAIS06AData/raw_dictionaries/rawHIDS2038-20120502-090905Z-DataLog_User_A.dat" or \
                filepath == "/Users/frio/GoogleDrive/WAIS06AData/raw_dictionaries/rawHIDS2038-20120619-091825Z-DataLog_User.dat" or \
                    filepath == "/Users/frio/GoogleDrive/WAIS06AData/raw_dictionaries/rawHIDS2038-20120720-095623Z-DataLog_User.dat":
            pmtransindexd18o = pmtransindexd18o[1:]
            extrapolatedd18o.append(extrapolatedd18o[-1])
            extrapolatedD.append(extrapolatedD[-1])
        for i in pmtransindexd18o:
            Index1 = i - 250
            Index2 = i + 250
            previousbegin = i-250
            previousend = i-150
            currentbegin = i+150
            currentend = i+250
            valcosegindex = data_dict["index"][Index1:Index2]
            valcosegindexnorm = valcosegindex - Index1
            valcosegd18o = data_dict["d18o"][Index1:Index2]
            previousvalued18o = np.mean(data_dict["d18o"][previousbegin:previousend])
            currentvalued18o = np.mean(data_dict["d18o"][currentbegin:currentend])
            stepsized18o = (currentvalued18o-previousvalued18o) 
            valcosegnormd18o = (valcosegd18o-previousvalued18o)/stepsized18o
            valcosegdD = data_dict["dD"][Index1:Index2]
            previousvaluedD = np.mean(data_dict["dD"][previousbegin:previousend])
            currentvaluedD = np.mean(data_dict["dD"][currentbegin:currentend])
            stepsizedD = (currentvaluedD-previousvaluedD) 
            valcosegnormdD = (valcosegdD-previousvaluedD)/stepsizedD
            
            badtransh2o = [x for x in data_dict["index"][Index1:Index2] if data_dict["flag1"][x]=="W"]
            counter  = 1 #### only for when first transitions buggered
            if len(badtransh2o)<=200:
                if counter == 1:
                    valcoindex = valcosegindexnorm
                    valcod18o = valcosegnormd18o
                    valcodD = valcosegnormdD
                    counter = 2
#                    #### only for when first transitions buggered - start
#                    if counter == 2:
#                        valcoindex = valcosegindexnorm
#                        valcod18o = valcosegnormd18o
#                        valcodD = valcosegnormdD
#                        counter = 3
#                    #### only for when first transitions buggered - end
                if counter == 2:
                    valcoindex = np.append(valcoindex,valcosegindexnorm)
                    valcod18o = np.append(valcod18o,valcosegnormd18o)
                    valcodD = np.append(valcodD,valcosegnormdD)
                
                run_pm_valco_transfer = PerformTransfer(type='PMValco', int = 3, TransferIndex1 = Index1, TransferIndex2 = Index2, StepIndex = i)   
                # output is: extrapolated18o, extrapolatedD, sigma1_Transd18o, sigma2_Transd18o, sigma1_TransdD, sigma2_TransdD, time_n_Transd18o, cdf_Transd18o_norm, time_n_TransdD, cdf_TransdD_norm
                extrapolatedd18o.append(run_pm_valco_transfer[0])
                extrapolatedD.append(run_pm_valco_transfer[1])
                sigma1_Transd18o.append(run_pm_valco_transfer[2])
                sigma2_Transd18o.append(run_pm_valco_transfer[3])
                sigma1_TransdD.append(run_pm_valco_transfer[4])
                sigma2_TransdD.append(run_pm_valco_transfer[5])
                valco_skewsigma_d18o.append(run_am_valco_transfer[11])
                valco_normsigma_d18o.append(run_am_valco_transfer[12])
                valco_skewsigma_dD.append(run_am_valco_transfer[13])
                valco_normsigma_dD.append(run_am_valco_transfer[14])
                if count == 2:
                    pmtimed18o = run_pm_valco_transfer[6]
                    pmcdfd18o = run_pm_valco_transfer[7]
                    pmtimedD = run_pm_valco_transfer[8]
                    pmcdfdD = run_pm_valco_transfer[9]
            count = count + 1

        sortindex = np.argsort(valcoindex)
        sortedvalcoindex = valcoindex[sortindex]
        sortedvalcod18o = valcod18o[sortindex]
        sortedvalcodD = valcodD[sortindex]   
        avevalcod18o = valcosegnormd18o.copy()
        avevalcodD = valcosegnormdD.copy()
        for p in valcosegindexnorm:
            aveindex = np.where(sortedvalcoindex==p)[0]
            avevalcod18o[p] = np.mean(sortedvalcod18o[aveindex])
            avevalcodD[p] = np.mean(sortedvalcodD[aveindex])
        smavevalcod18o = smooth(avevalcod18o)
        smavevalcodD = smooth(avevalcodD)
        valcosplined18o = UnivariateSpline(sortedvalcoindex,sortedvalcod18o,k=4, s=10.5)
        valcomomemcod18o = valcosplined18o(valcosegindexnorm)
        normvalcomemcod18o = (valcomomemcod18o-np.min(valcomomemcod18o))/(np.max(valcomomemcod18o)-np.min(valcomomemcod18o))
        valcoresd18o = valcomomemcod18o-avevalcod18o
        valcosplinedD = UnivariateSpline(sortedvalcoindex,sortedvalcodD,k=4, s=4.5)
        valcomomemcodD = valcosplinedD(valcosegindexnorm)
        normvalcomemcodD = (valcomomemcodD-np.min(valcomomemcodD))/(np.max(valcomomemcodD)-np.min(valcomomemcodD))
        valcoresdD = valcomomemcodD-avevalcodD
        
        fig420 = plt.figure(420)
        clear = plt.clf()
        fig420_ax1 = fig420.add_subplot(211)
        fig420_ax1.plot(sortedvalcoindex, sortedvalcod18o, "g-", valcosegindexnorm, avevalcod18o, "b-", valcosegindexnorm, smavevalcod18o, "k-") #valcosegindexnorm, valcosegnormd18o, "b-", valcosegindexnorm, valcosegnormneamemcod18o, "g-", 
        fig420_ax1.set_ylabel("d18o")
        fig420_ax2 = fig420.add_subplot(212)
        fig420_ax2.plot(sortedvalcoindex, sortedvalcodD, "m-", valcosegindexnorm, avevalcodD, "r-", valcosegindexnorm, smavevalcodD, "k-") #valcosegindexnorm, valcosegnormdD, "r-", valcosegindexnorm, valcosegnormneamemcodD, "m-", 
        fig420_ax2.set_ylabel("dD")
        fig420_ax2.set_xlabel("Index")
        fig420_ax1.set_title("%s" %(os.path.splitext(filepath)[0]))
        
        if verbose ==1:
            print extrapolatedd18o
            print extrapolatedD
            print sigma1_Transd18o
            print sigma2_Transd18o
            print sigma1_TransdD
            print sigma2_TransdD

        avesigma1_Transd18o = np.mean(sigma1_Transd18o)
        avesigma2_Transd18o = np.mean(sigma2_Transd18o)
        avesigma1_TransdD = np.mean(sigma1_TransdD)
        avesigma2_TransdD = np.mean(sigma2_TransdD)

        ##### CALCULATE RAW VALUES FOR STANDARDS IN VALCO
        rawd18o = []
        stdevrawd18o = []
        rawdD = []
        stdevrawdD = []

        for i in amtransbegin:
            begin = i-70
            end = i
            rawd18o.append(np.mean(data_dict["d18o"][begin:end]))
            stdevrawd18o.append(np.std(data_dict["d18o"][begin:end]))
            rawdD.append(np.mean(data_dict["dD"][begin:end]))
            stdevrawdD.append(np.std(data_dict["dD"][begin:end]))

        begin = trans7[0]-70
        end = trans7[0]
        rawd18o.append(np.mean(data_dict["d18o"][begin:end]))
        stdevrawd18o.append(np.std(data_dict["d18o"][begin:end]))
        rawdD.append(np.mean(data_dict["dD"][begin:end]))
        stdevrawdD.append(np.std(data_dict["dD"][begin:end]))

        for i in pmtransbegin:
            begin = i-70
            end = i
            rawd18o.append(np.mean(data_dict["d18o"][begin:end]))
            stdevrawd18o.append(np.std(data_dict["d18o"][begin:end]))
            rawdD.append(np.mean(data_dict["dD"][begin:end]))
            stdevrawdD.append(np.std(data_dict["dD"][begin:end]))

        begin = trans7[-1]-70
        end = trans7[-1]
        rawd18o.append(np.mean(data_dict["d18o"][begin:end]))
        stdevrawd18o.append(np.std(data_dict["d18o"][begin:end]))
        rawdD.append(np.mean(data_dict["dD"][begin:end]))
        stdevrawdD.append(np.std(data_dict["dD"][begin:end]))

        ## ASSIGN EXTRAPOLATED VALUES ############################################
        # Assign KBW measured/raw isotope values from extrapolation ###################                                     ### Need to put in error check, if no pm valco, don't creat 4 positions, only 2, OR NO AM VALCO IF DAY WAS RESTARTED OR SPLIT DUE TO SHIFT
        rawkbwd18o = [extrapolatedd18o[5],extrapolatedd18o[6],extrapolatedd18o[12]]
        rawkbwdD = [extrapolatedD[5],extrapolatedD[6],extrapolatedD[12]]
        
        if verbose ==1:
            print "KBW extrapolated d18o valco values ", rawkbwd18o
            print "KBW extrapolated dD valco values ", rawkbwdD

        ## Assign KAW measured isotope values #######################################                                         ### Need to put in error check, if no pm valco, don't creat 4 positions, only 2
        rawkawd18o = [extrapolatedd18o[0],extrapolatedd18o[4],extrapolatedd18o[7],extrapolatedd18o[11]]
        rawkawdD = [extrapolatedD[0],extrapolatedD[4],extrapolatedD[7],extrapolatedD[11]]
        if verbose ==1:
            print "KAW extrapolated d18o valco values ", rawkawd18o
            print "KAW extrapolated dD valco values ", rawkawdD 

        ## Assign KGW measured isotope values ##########################################                                         ### Need to put in error check, if no pm valco, don't creat 4 positions, only 2
        rawkgwd18o = [extrapolatedd18o[1],extrapolatedd18o[3],extrapolatedd18o[8],extrapolatedd18o[10]]
        rawkgwdD = [extrapolatedD[1],extrapolatedD[3],extrapolatedD[8],extrapolatedD[10]]
        if verbose ==1:
            print "KGW extrapolated d18o valco values ", rawkgwd18o
            print "KGW extrapolated dD valco values ", rawkgwdD

        ## Assign KPW measured isotope values #######################################                                         ### Need to put in error check, if no pm valco, don't creat 4 positions, only 2
        rawkpwd18o = [extrapolatedd18o[2],extrapolatedd18o[9]]
        rawkpwdD = [extrapolatedD[2],extrapolatedD[9]]
        if verbose ==1:
            print "KPW extrapolated d18o valco values ", rawkpwd18o
            print "KPW extrapolated dD valco values ", rawkpwdD

    if data_dict["epoch"][0] > 1354320001 and data_dict["epoch"][0] < 1420095599:  # after 20121201, WAIS06A, 20 min valco, and idle water as drift OR push waters inbetween cores
        for m in data_dict["index"]:
            data_dict["flag5"][m] = 'C'
        print "Data processing 2130 and 20 min valco data"
        
        ## RUN THE TRANSFER FUNCTION IN LOOP THROUGH ALL AM VALCO TRANSITIONS ##########
        for i in amtransindexd18o:
            Index1 = i - 500 
            Index2 = i + 500
            previousbegin = i-500
            previousend = i-400
            currentbegin = i+400
            currentend = i+500
            valcosegindex = data_dict["index"][Index1:Index2]
            valcosegindexnorm = valcosegindex - Index1
            valcosegd18o = data_dict["d18o"][Index1:Index2]
            previousvalued18o = np.mean(data_dict["d18o"][previousbegin:previousend])
            currentvalued18o = np.mean(data_dict["d18o"][currentbegin:currentend])
            stepsized18o = (currentvalued18o-previousvalued18o) 
            valcosegnormd18o = (valcosegd18o-previousvalued18o)/stepsized18o
            valcosegdD = data_dict["dD"][Index1:Index2]
            previousvaluedD = np.mean(data_dict["dD"][previousbegin:previousend])
            currentvaluedD = np.mean(data_dict["dD"][currentbegin:currentend])
            stepsizedD = (currentvaluedD-previousvaluedD) 
            valcosegnormdD = (valcosegdD-previousvaluedD)/stepsizedD
            
            badtransh2o = [x for x in data_dict["index"][Index1:Index2] if data_dict["flag1"][x]=="W"]
            if len(badtransh2o)<=200:
                if counter == 1:
                    valcoindex = valcosegindexnorm
                    valcod18o = valcosegnormd18o
                    valcodD = valcosegnormdD
                    counter = 2
                else:
                    valcoindex = np.append(valcoindex,valcosegindexnorm)
                    valcod18o = np.append(valcod18o,valcosegnormd18o)
                    valcodD = np.append(valcodD,valcosegnormdD)
                
                run_am_valco_transfer = PerformTransfer(type = 'AMValco', int = 1, TransferIndex1 = Index1, TransferIndex2 = Index2, StepIndex = i)
                # output is: extrapolated18o, extrapolatedD, sigma1_Transd18o, sigma2_Transd18o, sigma1_TransdD, sigma2_TransdD, time_n_Transd18o, cdf_Transd18o_norm, time_n_TransdD, cdf_TransdD_norm
                extrapolatedd18o.append(run_am_valco_transfer[0])
                extrapolatedD.append(run_am_valco_transfer[1])
                sigma1_Transd18o.append(run_am_valco_transfer[2])
                sigma2_Transd18o.append(run_am_valco_transfer[3])
                sigma1_TransdD.append(run_am_valco_transfer[4])
                sigma2_TransdD.append(run_am_valco_transfer[5])
                valco_skewsigma_d18o.append(run_am_valco_transfer[11])
                valco_normsigma_d18o.append(run_am_valco_transfer[12])
                valco_skewsigma_dD.append(run_am_valco_transfer[13])
                valco_normsigma_dD.append(run_am_valco_transfer[14])
                if count == 2:
                    amtimed18o = run_am_valco_transfer[6]
                    amcdfd18o = run_am_valco_transfer[7]
                    amtimedD = run_am_valco_transfer[8]
                    amcdfdD = run_am_valco_transfer[9]
            count = count + 1

        ## RUN THE TRANSFER FUNCTION  IN LOOP THROUGH ALL PM VALCO TRANSITIONS #########
        count = 1
        for i in pmtransindexd18o:
            Index1 = i - 500 
            Index2 = i + 500
            previousbegin = i-500
            previousend = i-400
            currentbegin = i+400
            currentend = i+500
            valcosegindex = data_dict["index"][Index1:Index2]
            valcosegindexnorm = valcosegindex - Index1
            valcosegd18o = data_dict["d18o"][Index1:Index2]
            previousvalued18o = np.mean(data_dict["d18o"][previousbegin:previousend])
            currentvalued18o = np.mean(data_dict["d18o"][currentbegin:currentend])
            stepsized18o = (currentvalued18o-previousvalued18o) 
            valcosegnormd18o = (valcosegd18o-previousvalued18o)/stepsized18o
            valcosegdD = data_dict["dD"][Index1:Index2]
            previousvaluedD = np.mean(data_dict["dD"][previousbegin:previousend])
            currentvaluedD = np.mean(data_dict["dD"][currentbegin:currentend])
            stepsizedD = (currentvaluedD-previousvaluedD) 
            valcosegnormdD = (valcosegdD-previousvaluedD)/stepsizedD
            
            badtransh2o = [x for x in data_dict["index"][Index1:Index2] if data_dict["flag1"][x]=="W"]
            if len(badtransh2o)<=200:
                if counter == 1:
                    valcoindex = valcosegindexnorm
                    valcod18o = valcosegnormd18o
                    valcodD = valcosegnormdD
                    counter = 2
                else:
                    valcoindex = np.append(valcoindex,valcosegindexnorm)
                    valcod18o = np.append(valcod18o,valcosegnormd18o)
                    valcodD = np.append(valcodD,valcosegnormdD)
                
                run_pm_valco_transfer = PerformTransfer(type='PMValco', int = 3, TransferIndex1 = Index1, TransferIndex2 = Index2, StepIndex = i)   
                # output is: extrapolated18o, extrapolatedD, sigma1_Transd18o, sigma2_Transd18o, sigma1_TransdD, sigma2_TransdD, time_n_Transd18o, cdf_Transd18o_norm, time_n_TransdD, cdf_TransdD_norm
                extrapolatedd18o.append(run_pm_valco_transfer[0])
                extrapolatedD.append(run_pm_valco_transfer[1])
                sigma1_Transd18o.append(run_pm_valco_transfer[2])
                sigma2_Transd18o.append(run_pm_valco_transfer[3])
                sigma1_TransdD.append(run_pm_valco_transfer[4])
                sigma2_TransdD.append(run_pm_valco_transfer[5])
                valco_skewsigma_d18o.append(run_am_valco_transfer[11])
                valco_normsigma_d18o.append(run_am_valco_transfer[12])
                valco_skewsigma_dD.append(run_am_valco_transfer[13])
                valco_normsigma_dD.append(run_am_valco_transfer[14])
                if count == 2:
                    pmtimed18o = run_pm_valco_transfer[6]
                    pmcdfd18o = run_pm_valco_transfer[7]
                    pmtimedD = run_pm_valco_transfer[8]
                    pmcdfdD = run_pm_valco_transfer[9]
            count = count + 1

        sortindex = np.argsort(valcoindex)
        sortedvalcoindex = valcoindex[sortindex]
        sortedvalcod18o = valcod18o[sortindex]
        sortedvalcodD = valcodD[sortindex]   
        avevalcod18o = valcosegnormd18o.copy()
        avevalcodD = valcosegnormdD.copy()
        for p in valcosegindexnorm:
            aveindex = np.where(sortedvalcoindex==p)[0]
            avevalcod18o[p] = np.mean(sortedvalcod18o[aveindex])
            avevalcodD[p] = np.mean(sortedvalcodD[aveindex])
        smavevalcod18o = smooth(avevalcod18o)
        smavevalcodD = smooth(avevalcodD)
        valcosplined18o = UnivariateSpline(sortedvalcoindex,sortedvalcod18o,k=4, s=10.5)
        valcomomemcod18o = valcosplined18o(valcosegindexnorm)
        normvalcomemcod18o = (valcomomemcod18o-np.min(valcomomemcod18o))/(np.max(valcomomemcod18o)-np.min(valcomomemcod18o))
        valcoresd18o = valcomomemcod18o-avevalcod18o
        valcosplinedD = UnivariateSpline(sortedvalcoindex,sortedvalcodD,k=4, s=4.5)
        valcomomemcodD = valcosplinedD(valcosegindexnorm)
        normvalcomemcodD = (valcomomemcodD-np.min(valcomomemcodD))/(np.max(valcomomemcodD)-np.min(valcomomemcodD))
        valcoresdD = valcomomemcodD-avevalcodD
        
        fig420 = plt.figure(420)
        clear = plt.clf()
        fig420_ax1 = fig420.add_subplot(211)
        fig420_ax1.plot(sortedvalcoindex, sortedvalcod18o, "g-", valcosegindexnorm, avevalcod18o, "b-", valcosegindexnorm, smavevalcod18o, "k-") #valcosegindexnorm, valcosegnormd18o, "b-", valcosegindexnorm, valcosegnormneamemcod18o, "g-", 
        fig420_ax1.set_ylabel("d18o")
        fig420_ax2 = fig420.add_subplot(212)
        fig420_ax2.plot(sortedvalcoindex, sortedvalcodD, "m-", valcosegindexnorm, avevalcodD, "r-", valcosegindexnorm, smavevalcodD, "k-") #valcosegindexnorm, valcosegnormdD, "r-", valcosegindexnorm, valcosegnormneamemcodD, "m-", 
        fig420_ax2.set_ylabel("dD")
        fig420_ax2.set_xlabel("Index")
        fig420_ax1.set_title("%s" %(os.path.splitext(filepath)[0]))
        
        if verbose ==1:
            print extrapolatedd18o
            print extrapolatedD
            print sigma1_Transd18o
            print sigma2_Transd18o
            print sigma1_TransdD
            print sigma2_TransdD

        avesigma1_Transd18o = np.mean(sigma1_Transd18o)
        avesigma2_Transd18o = np.mean(sigma2_Transd18o)
        avesigma1_TransdD = np.mean(sigma1_TransdD)
        avesigma2_TransdD = np.mean(sigma2_TransdD)

        ##### CALCULATE RAW VALUES FOR STANDARDS IN VALCO
        rawd18o = []
        stdevrawd18o = []
        rawdD = []
        stdevrawdD = []

        for i in amtransbegin:
            begin = i-352 
            end = i
            rawd18o.append(np.mean(data_dict["d18o"][begin:end]))
            stdevrawd18o.append(np.std(data_dict["d18o"][begin:end]))
            rawdD.append(np.mean(data_dict["dD"][begin:end]))
            stdevrawdD.append(np.std(data_dict["dD"][begin:end]))

        begin = trans7[0]-352 
        end = trans7[0]
        rawd18o.append(np.mean(data_dict["d18o"][begin:end]))
        stdevrawd18o.append(np.std(data_dict["d18o"][begin:end]))
        rawdD.append(np.mean(data_dict["dD"][begin:end]))
        stdevrawdD.append(np.std(data_dict["dD"][begin:end]))

        for i in pmtransbegin:
            begin = i-352 
            end = i
            rawd18o.append(np.mean(data_dict["d18o"][begin:end]))
            stdevrawd18o.append(np.std(data_dict["d18o"][begin:end]))
            rawdD.append(np.mean(data_dict["dD"][begin:end]))
            stdevrawdD.append(np.std(data_dict["dD"][begin:end]))

        begin = trans7[-1]-352 
        end = trans7[-1]
        rawd18o.append(np.mean(data_dict["d18o"][begin:end]))
        stdevrawd18o.append(np.std(data_dict["d18o"][begin:end]))
        rawdD.append(np.mean(data_dict["dD"][begin:end]))
        stdevrawdD.append(np.std(data_dict["dD"][begin:end]))

        ##### ASSIGN RAW VALUES ############################################
        ## Assign KBW measured/raw isotope values                               ### Need to put in error check, if no pm valco, don't creat 4 positions, only 2, OR NO AM VALCO IF DAY WAS RESTARTED OR SPLIT DUE TO SHIFT
        rawkbwd18o = [rawd18o[1],rawd18o[7],rawd18o[9],rawd18o[15]]
        averawkbwd18o = np.mean(rawkbwd18o)
        stdevrawkbwd18o = np.std(rawkbwd18o)
        rawkbwdD = [rawdD[1],rawdD[7],rawdD[9],rawdD[15]]
        averawkbwdD = np.mean(rawkbwdD)
        stdevrawkbwdD = np.std(rawkbwdD)
        if verbose ==1:
            print "KBW raw d18o valco values"
            print rawkbwd18o
            print averawkbwd18o, stdevrawkbwd18o
            print "KBW raw dD valco values"
            print rawkbwdD
            print averawkbwdD, stdevrawkbwdD

        ##### Assign KAW measured isotope values                                ### Need to put in error check, if no pm valco, don't creat 4 positions, only 2
        rawkawd18o = [rawd18o[2],rawd18o[6],rawd18o[10],rawd18o[14]]
        averawkawd18o = np.mean(rawkawd18o)
        stdevrawkawd18o = np.std(rawkawd18o)
        rawkawdD = [rawdD[2],rawdD[6],rawdD[10],rawdD[14]]
        averawkawdD = np.mean(rawkawdD)
        stdevrawkawdD = np.std(rawkawdD)
        if verbose ==1:
            print "KAW raw d18o valco values"
            print rawkawd18o
            print averawkawd18o, stdevrawkawd18o
            print "KAW raw dD valco values"
            print rawkawdD
            print averawkawdD, stdevrawkawdD

        ## Assign KGW measured isotope values                                   ### Need to put in error check, if no pm valco, don't creat 4 positions, only 2
        rawkgwd18o = [rawd18o[3],rawd18o[5],rawd18o[11],rawd18o[13]]
        averawkgwd18o = np.mean(rawkgwd18o)
        stdevrawkgwd18o = np.std(rawkgwd18o)
        rawkgwdD = [rawdD[3],rawdD[5],rawdD[11],rawdD[13]]
        averawkgwdD = np.mean(rawkgwdD)
        stdevrawkgwdD = np.std(rawkgwdD)
        if verbose ==1:
            print "KGW raw d18o valco values"
            print rawkgwd18o
            print averawkgwd18o, stdevrawkgwd18o
            print "KGW raw dD valco values"
            print rawkgwdD
            print averawkgwdD, stdevrawkgwdD

        ##### Assign KPW measured isotope values                                ### Need to put in error check, if no pm valco, don't creat 4 positions, only 2
        rawkpwd18o = [rawd18o[4],rawd18o[12]]
        averawkpwd18o = np.mean(rawkpwd18o)
        stdevrawkpwd18o = np.std(rawkpwd18o)
        rawkpwdD = [rawdD[4],rawdD[12]]
        averawkpwdD = np.mean(rawkpwdD)
        stdevrawkpwdD = np.std(rawkpwdD)
        if verbose ==1:
            print "KPW raw d18o valco values"
            print rawkpwd18o
            print averawkpwd18o, stdevrawkpwd18o
            print "KPW raw dD valco values"
            print rawkpwdD
            print averawkpwdD, stdevrawkpwdD

    if data_dict["epoch"][0] > 1420095600:  # after 20150101, SPIce Core, 20 min valco, and idle water as drift OR push waters inbetween cores
        for m in data_dict["index"]:
            data_dict["flag5"][m] = 'C'
        print "Data processing 2130 and 20 min valco data"

        ## RUN THE TRANSFER FUNCTION IN LOOP THROUGH ALL AM VALCO TRANSITIONS ##########
        for i in amtransindexd18o:
            Index1 = i - 500 
            Index2 = i + 500
            previousbegin = i-500
            previousend = i-400
            currentbegin = i+400
            currentend = i+500
            valcosegindex = data_dict["index"][Index1:Index2]
            valcosegindexnorm = valcosegindex - Index1
            valcosegd18o = data_dict["d18o"][Index1:Index2]
            previousvalued18o = np.mean(data_dict["d18o"][previousbegin:previousend])
            currentvalued18o = np.mean(data_dict["d18o"][currentbegin:currentend])
            stepsized18o = (currentvalued18o-previousvalued18o) 
            valcosegnormd18o = (valcosegd18o-previousvalued18o)/stepsized18o
            valcosegdD = data_dict["dD"][Index1:Index2]
            previousvaluedD = np.mean(data_dict["dD"][previousbegin:previousend])
            currentvaluedD = np.mean(data_dict["dD"][currentbegin:currentend])
            stepsizedD = (currentvaluedD-previousvaluedD) 
            valcosegnormdD = (valcosegdD-previousvaluedD)/stepsizedD
            
            badtransh2o = [x for x in data_dict["index"][Index1:Index2] if data_dict["flag1"][x]=="W"]
            if len(badtransh2o)<=200:
                if counter == 1:
                    valcoindex = valcosegindexnorm
                    valcod18o = valcosegnormd18o
                    valcodD = valcosegnormdD
                    counter = 2
                else:
                    valcoindex = np.append(valcoindex,valcosegindexnorm)
                    valcod18o = np.append(valcod18o,valcosegnormd18o)
                    valcodD = np.append(valcodD,valcosegnormdD)
                
                run_am_valco_transfer = PerformTransfer(type = 'AMValco', int = 1, TransferIndex1 = Index1, TransferIndex2 = Index2, StepIndex = i)
                # output is: extrapolated18o, extrapolatedD, sigma1_Transd18o, sigma2_Transd18o, sigma1_TransdD, sigma2_TransdD, time_n_Transd18o, cdf_Transd18o_norm, time_n_TransdD, cdf_TransdD_norm
                extrapolatedd18o.append(run_am_valco_transfer[0])
                extrapolatedD.append(run_am_valco_transfer[1])
                sigma1_Transd18o.append(run_am_valco_transfer[2])
                sigma2_Transd18o.append(run_am_valco_transfer[3])
                sigma1_TransdD.append(run_am_valco_transfer[4])
                sigma2_TransdD.append(run_am_valco_transfer[5])
                valco_skewsigma_d18o.append(run_am_valco_transfer[11])
                valco_normsigma_d18o.append(run_am_valco_transfer[12])
                valco_skewsigma_dD.append(run_am_valco_transfer[13])
                valco_normsigma_dD.append(run_am_valco_transfer[14])
                if count == 2:
                    amtimed18o = run_am_valco_transfer[6]
                    amcdfd18o = run_am_valco_transfer[7]
                    amtimedD = run_am_valco_transfer[8]
                    amcdfdD = run_am_valco_transfer[9]
            count = count + 1

        ## RUN THE TRANSFER FUNCTION  IN LOOP THROUGH ALL PM VALCO TRANSITIONS #########
        count = 1
        for i in pmtransindexd18o:
            Index1 = i - 500 
            Index2 = i + 500
            previousbegin = i-500
            previousend = i-400
            currentbegin = i+400
            currentend = i+500
            valcosegindex = data_dict["index"][Index1:Index2]
            valcosegindexnorm = valcosegindex - Index1
            valcosegd18o = data_dict["d18o"][Index1:Index2]
            previousvalued18o = np.mean(data_dict["d18o"][previousbegin:previousend])
            currentvalued18o = np.mean(data_dict["d18o"][currentbegin:currentend])
            stepsized18o = (currentvalued18o-previousvalued18o) 
            valcosegnormd18o = (valcosegd18o-previousvalued18o)/stepsized18o
            valcosegdD = data_dict["dD"][Index1:Index2]
            previousvaluedD = np.mean(data_dict["dD"][previousbegin:previousend])
            currentvaluedD = np.mean(data_dict["dD"][currentbegin:currentend])
            stepsizedD = (currentvaluedD-previousvaluedD) 
            valcosegnormdD = (valcosegdD-previousvaluedD)/stepsizedD
            
            badtransh2o = [x for x in data_dict["index"][Index1:Index2] if data_dict["flag1"][x]=="W"]
            if len(badtransh2o)<=200:
                if counter == 1:
                    valcoindex = valcosegindexnorm
                    valcod18o = valcosegnormd18o
                    valcodD = valcosegnormdD
                    counter = 2
                else:
                    valcoindex = np.append(valcoindex,valcosegindexnorm)
                    valcod18o = np.append(valcod18o,valcosegnormd18o)
                    valcodD = np.append(valcodD,valcosegnormdD)
                
                run_pm_valco_transfer = PerformTransfer(type='PMValco', int = 3, TransferIndex1 = Index1, TransferIndex2 = Index2, StepIndex = i)   
                # output is: extrapolated18o, extrapolatedD, sigma1_Transd18o, sigma2_Transd18o, sigma1_TransdD, sigma2_TransdD, time_n_Transd18o, cdf_Transd18o_norm, time_n_TransdD, cdf_TransdD_norm
                extrapolatedd18o.append(run_pm_valco_transfer[0])
                extrapolatedD.append(run_pm_valco_transfer[1])
                sigma1_Transd18o.append(run_pm_valco_transfer[2])
                sigma2_Transd18o.append(run_pm_valco_transfer[3])
                sigma1_TransdD.append(run_pm_valco_transfer[4])
                sigma2_TransdD.append(run_pm_valco_transfer[5])
                valco_skewsigma_d18o.append(run_am_valco_transfer[11])
                valco_normsigma_d18o.append(run_am_valco_transfer[12])
                valco_skewsigma_dD.append(run_am_valco_transfer[13])
                valco_normsigma_dD.append(run_am_valco_transfer[14])
                if count == 2:
                    pmtimed18o = run_pm_valco_transfer[6]
                    pmcdfd18o = run_pm_valco_transfer[7]
                    pmtimedD = run_pm_valco_transfer[8]
                    pmcdfdD = run_pm_valco_transfer[9]
            count = count + 1

        sortindex = np.argsort(valcoindex)
        sortedvalcoindex = valcoindex[sortindex]
        sortedvalcod18o = valcod18o[sortindex]
        sortedvalcodD = valcodD[sortindex]   
        avevalcod18o = valcosegnormd18o.copy()
        avevalcodD = valcosegnormdD.copy()
        for p in valcosegindexnorm:
            aveindex = np.where(sortedvalcoindex==p)[0]
            avevalcod18o[p] = np.mean(sortedvalcod18o[aveindex])
            avevalcodD[p] = np.mean(sortedvalcodD[aveindex])
        smavevalcod18o = smooth(avevalcod18o)
        smavevalcodD = smooth(avevalcodD)
        valcosplined18o = UnivariateSpline(sortedvalcoindex,sortedvalcod18o,k=4, s=10.5)
        valcomomemcod18o = valcosplined18o(valcosegindexnorm)
        normvalcomemcod18o = (valcomomemcod18o-np.min(valcomomemcod18o))/(np.max(valcomomemcod18o)-np.min(valcomomemcod18o))
        valcoresd18o = valcomomemcod18o-avevalcod18o
        valcosplinedD = UnivariateSpline(sortedvalcoindex,sortedvalcodD,k=4, s=4.5)
        valcomomemcodD = valcosplinedD(valcosegindexnorm)
        normvalcomemcodD = (valcomomemcodD-np.min(valcomomemcodD))/(np.max(valcomomemcodD)-np.min(valcomomemcodD))
        valcoresdD = valcomomemcodD-avevalcodD
        
        fig420 = plt.figure(420)
        clear = plt.clf()
        fig420_ax1 = fig420.add_subplot(211)
        fig420_ax1.plot(sortedvalcoindex, sortedvalcod18o, "g-", valcosegindexnorm, avevalcod18o, "b-", valcosegindexnorm, smavevalcod18o, "k-") #valcosegindexnorm, valcosegnormd18o, "b-", valcosegindexnorm, valcosegnormneamemcod18o, "g-", 
        fig420_ax1.set_ylabel("d18o")
        fig420_ax2 = fig420.add_subplot(212)
        fig420_ax2.plot(sortedvalcoindex, sortedvalcodD, "m-", valcosegindexnorm, avevalcodD, "r-", valcosegindexnorm, smavevalcodD, "k-") #valcosegindexnorm, valcosegnormdD, "r-", valcosegindexnorm, valcosegnormneamemcodD, "m-", 
        fig420_ax2.set_ylabel("dD")
        fig420_ax2.set_xlabel("Index")
        fig420_ax1.set_title("%s" %(os.path.splitext(filepath)[0]))
        
        if verbose ==1:
            print extrapolatedd18o
            print extrapolatedD
            print sigma1_Transd18o
            print sigma2_Transd18o
            print sigma1_TransdD
            print sigma2_TransdD

        avesigma1_Transd18o = np.mean(sigma1_Transd18o)
        avesigma2_Transd18o = np.mean(sigma2_Transd18o)
        avesigma1_TransdD = np.mean(sigma1_TransdD)
        avesigma2_TransdD = np.mean(sigma2_TransdD)

        ##### CALCULATE RAW VALUES FOR STANDARDS IN VALCO
        rawd18o = []
        stdevrawd18o = []
        rawdD = []
        stdevrawdD = []

        for i in amtransbegin:
            begin = i-352 
            end = i
            rawd18o.append(np.mean(data_dict["d18o"][begin:end]))
            stdevrawd18o.append(np.std(data_dict["d18o"][begin:end]))
            rawdD.append(np.mean(data_dict["dD"][begin:end]))
            stdevrawdD.append(np.std(data_dict["dD"][begin:end]))

        begin = trans7[0]-352 
        end = trans7[0]
        rawd18o.append(np.mean(data_dict["d18o"][begin:end]))
        stdevrawd18o.append(np.std(data_dict["d18o"][begin:end]))
        rawdD.append(np.mean(data_dict["dD"][begin:end]))
        stdevrawdD.append(np.std(data_dict["dD"][begin:end]))

        for i in pmtransbegin:
            begin = i-352 
            end = i
            rawd18o.append(np.mean(data_dict["d18o"][begin:end]))
            stdevrawd18o.append(np.std(data_dict["d18o"][begin:end]))
            rawdD.append(np.mean(data_dict["dD"][begin:end]))
            stdevrawdD.append(np.std(data_dict["dD"][begin:end]))

        begin = trans7[-1]-352 
        end = trans7[-1]
        rawd18o.append(np.mean(data_dict["d18o"][begin:end]))
        stdevrawd18o.append(np.std(data_dict["d18o"][begin:end]))
        rawdD.append(np.mean(data_dict["dD"][begin:end]))
        stdevrawdD.append(np.std(data_dict["dD"][begin:end]))

        ##### ASSIGN RAW VALUES ############################################
        ## Assign kaw measured/raw isotope values                               ### Need to put in error check, if no pm valco, don't create 4 positions, only 2, OR NO AM VALCO IF DAY WAS RESTARTED OR SPLIT DUE TO SHIFT
        rawkawd18o = [rawd18o[1],rawd18o[7],rawd18o[9],rawd18o[15]]
        averawkawd18o = np.mean(rawkawd18o)
        stdevrawkawd18o = np.std(rawkawd18o)
        rawkawdD = [rawdD[1],rawdD[7],rawdD[9],rawdD[15]]
        averawkawdD = np.mean(rawkawdD)
        stdevrawkawdD = np.std(rawkawdD)
        if verbose ==1:
            print "kaw raw d18o valco values"
            print rawkawd18o
            print averawkawd18o, stdevrawkawd18o
            print "kaw raw dD valco values"
            print rawkawdD
            print averawkawdD, stdevrawkawdD

        ##### Assign kgw measured isotope values                                ### Need to put in error check, if no pm valco, don't create 4 positions, only 2
        rawkgwd18o = [rawd18o[2],rawd18o[6],rawd18o[10],rawd18o[14]]
        averawkgwd18o = np.mean(rawkgwd18o)
        stdevrawkgwd18o = np.std(rawkgwd18o)
        rawkgwdD = [rawdD[2],rawdD[6],rawdD[10],rawdD[14]]
        averawkgwdD = np.mean(rawkgwdD)
        stdevrawkgwdD = np.std(rawkgwdD)
        if verbose ==1:
            print "kgw raw d18o valco values"
            print rawkgwd18o
            print averawkgwd18o, stdevrawkgwd18o
            print "kgw raw dD valco values"
            print rawkgwdD
            print averawkgwdD, stdevrawkgwdD

        ## Assign kpw measured isotope values                                   ### Need to put in error check, if no pm valco, don't create 4 positions, only 2
        rawkpwd18o = [rawd18o[3],rawd18o[5],rawd18o[11],rawd18o[13]]
        averawkpwd18o = np.mean(rawkpwd18o)
        stdevrawkpwd18o = np.std(rawkpwd18o)
        rawkpwdD = [rawdD[3],rawdD[5],rawdD[11],rawdD[13]]
        averawkpwdD = np.mean(rawkpwdD)
        stdevrawkpwdD = np.std(rawkpwdD)
        if verbose ==1:
            print "kpw raw d18o valco values"
            print rawkpwd18o
            print averawkpwd18o, stdevrawkpwd18o
            print "kpw raw dD valco values"
            print rawkpwdD
            print averawkpwdD, stdevrawkpwdD

        ##### Assign vw1f measured isotope values                                ### Need to put in error check, if no pm valco, don't create 4 positions, only 2
        rawvw1fd18o = [rawd18o[4],rawd18o[12]]
        averawvw1fd18o = np.mean(rawvw1fd18o)
        stdevrawvw1fd18o = np.std(rawvw1fd18o)
        rawvw1fdD = [rawdD[4],rawdD[12]]
        averawvw1fdD = np.mean(rawvw1fdD)
        stdevrawvw1fdD = np.std(rawvw1fdD)
        if verbose ==1:
            print "vw1f raw d18o valco values"
            print rawvw1fd18o
            print averawvw1fd18o, stdevrawvw1fd18o
            print "vw1f raw dD valco values"
            print rawvw1fdD
            print averawvw1fdD, stdevrawvw1fdD
    
    ave_valco_skewsigma_d18o = np.mean(valco_skewsigma_d18o)
    ave_valco_normsigma_d18o = np.mean(valco_normsigma_d18o)
    ave_valco_skewsigma_dD = np.mean(valco_skewsigma_dD)  
    ave_valco_normsigma_dD = np.mean(valco_normsigma_dD)

    ### MEMORY CORRECT ISOTOPE VALUES FOLLOWING each valco transition #####################
    ## USE SAME VALCO TRANSITIONS FROM ABS(DIFFD18O[:]) TYPE EQUATIONS

    valcochange = [x for x in data_dict["index"][amvalcobegin[0]:] if data_dict["valco_pos"][x-1]!=data_dict["valco_pos"][x]] ### ALL VALCO TRANSITIONS, VALCO RUNS, IDLE WATER, ICE CORES prior to push ice implementation
    numvalcochange = len(valcochange)
    if verbose ==1:
        print valcochange
        print numvalcochange

    for i in valcochange: # change to diff min or max?
        if data_dict["epoch"][0] < 1325376000:          #### 1102
            previousbegin = i-20
            previousend = i
            currentbegin = i+50
            currentend = i+100
        if data_dict["epoch"][0] > 1325376000:          #### 2130
            previousbegin = i-50
            previousend = i
            currentbegin = i+150
            currentend = i+250
        if currentend >= data_dict["index"][-1]:
            currentend = data_dict["index"][-1]
        previousvalue = np.mean(data_dict["d18o"][previousbegin:previousend])
        currentvalue = np.mean(data_dict["d18o"][currentbegin:currentend])
        stepsize = (currentvalue-previousvalue)
        middlevalue = (previousvalue+currentvalue)/2
        midpoints = [x for x in data_dict["index"][i:currentend] if data_dict["d18o"][x] >= middlevalue-1 and data_dict["d18o"][x] <= middlevalue+1]
        nummidpoints = len(midpoints)
        if nummidpoints>0:
            midpoint = np.ceil(np.mean(midpoints[:]))
        else:
            midvalue = np.max(np.abs(diffd18o[i:currentend]))
            midpoints = [x for x in data_dict["index"][i:currentend] if np.abs(diffd18o[x]) == midvalue]
            midpoint = np.ceil(np.mean(midpoints[:]))-10
        normalizedtimed18o = data_dict["j_days"][midpoint:currentend+600]-data_dict["j_days"][midpoint]
        
        if data_dict["epoch"][0] < 1325376000:                                                  #### 1102
            for z in data_dict["index"][midpoint:midpoint+40]:
                valcomemd18o[z] = (data_dict["d18o"][z]-previousvalue*(1-smavevalcod18o[z-midpoint+51]))/(smavevalcod18o[z-midpoint+51])
                data_dict["flag4"][z] = 'v'
        if data_dict["epoch"][0] < 1354320001 and data_dict["epoch"][0] > 1325376000:          #### 2130 5 min
            for z in data_dict["index"][midpoint:midpoint+240]:
                valcomemd18o[z] = (data_dict["d18o"][z]-previousvalue*(1-smavevalcod18o[z-midpoint+256]))/(smavevalcod18o[z-midpoint+256])
                data_dict["flag4"][z] = 'v'
        if data_dict["epoch"][0] > 1354320001:                                                  #### 2130 20 min valco
            for z in data_dict["index"][midpoint:midpoint+490]:
                valcomemd18o[z] = (data_dict["d18o"][z]-previousvalue*(1-smavevalcod18o[z-midpoint+506]))/(smavevalcod18o[z-midpoint+506]) 
                data_dict["flag4"][z] = 'v'
        # repeat for dD
        previousvalue = np.mean(data_dict["dD"][previousbegin:previousend])
        currentvalue = np.mean(data_dict["dD"][currentbegin:currentend])
        stepsize = (currentvalue-previousvalue)
        middlevalue = (previousvalue+currentvalue)/2
        midpoints = [x for x in data_dict["index"][i:currentend] if data_dict["dD"][x] >= middlevalue-4 and data_dict["dD"][x] <= middlevalue+4]
        nummidpoints = len(midpoints)
        if nummidpoints>0:
            midpoint = np.ceil(np.mean(midpoints[:]))
        else:
            midvalue = np.max(np.abs(diffdD[i:currentend]))
            midpoints = [x for x in data_dict["index"][i:currentend] if np.abs(diffdD[x]) == midvalue]
            midpoint = np.ceil(np.mean(midpoints[:]))-10
        normalizedtimedD = data_dict["j_days"][midpoint:currentend+600]-data_dict["j_days"][midpoint]

        if data_dict["epoch"][0] < 1325376000:                                                  #### 1102
            for z in data_dict["index"][midpoint:midpoint+40]:
                valcomemdD[z] = (data_dict["dD"][z]-previousvalue*(1-smavevalcodD[z-midpoint+52]))/(smavevalcodD[z-midpoint+52])
                data_dict["flag4"][z] = 'v'
        if data_dict["epoch"][0] < 1354320001 and data_dict["epoch"][0] > 1325376000:          #### 2130 5 min
            for z in data_dict["index"][midpoint:midpoint+240]:
                valcomemdD[z] = (data_dict["dD"][z]-previousvalue*(1-smavevalcodD[z-midpoint+257]))/(smavevalcodD[z-midpoint+257])
                data_dict["flag4"][z] = 'v'
        if data_dict["epoch"][0] > 1354320001:                                                  #### 2130 20 min valco
            for z in data_dict["index"][midpoint:midpoint+490]:
                valcomemdD[z] = (data_dict["dD"][z]-previousvalue*(1-smavevalcodD[z-midpoint+507]))/(smavevalcodD[z-midpoint+507])
                data_dict["flag4"][z] = 'v'
    
    valcomemdexcess = valcomemdD-8*valcomemd18o

    #### plot memory corrected values onto original graph
    fig21_ax1.plot(data_dict["index"], valcomemd18o, "g-")
    fig21_ax2.plot(data_dict["index"], valcomemdD, "m-")
    fig21_ax3.plot(data_dict["index"], valcomemdexcess, "k-")

    ##### NEA IDENTIFICATION #######################################################
    ## Look at comments to locate amnea and pmnea
    amneabegin = [x for x in data_dict["index"][1:] if data_dict["comments"][x-1]!=153 and data_dict["comments"][x]==153]
    pmneabegin = [x for x in data_dict["index"][1:] if data_dict["comments"][x-1]!=161 and data_dict["comments"][x]==161]

    if len(amvalcobegin) > 1:
        amneabegin = [amneabegin[-1]]
    if len(amneabegin) < 1:
        amneabegin = [pmneabegin[-1]]
    if len(pmneabegin) > 1:
        pmneabegin = [pmneabegin[-1]]
    if len(pmneabegin) < 1:
        pmneabegin = [amneabegin[-1]]
        
    if verbose ==1:
        print "AM neapolitan begin ", amneabegin
        print "PM neapolitan begin ", pmneabegin
        
    ## Stop and ask if need to edit?
        checkbegin = raw_input("Do you want to edit the beginning am neapolitan indices?")
        if checkbegin in ('y', 'ye', 'yes'):
            amneabegin = input("Please type new indices list in [ ]...")
            print "New AM neapolitan begin ", amneabegin
        checkbegin = raw_input("Do you want to edit the beginning pm neapolitan indices?")
        if checkbegin in ('y', 'ye', 'yes'):
            pmneabegin = input("Please type new indices list in [ ]...")
            print "New PM neapolitan begin ", pmneabegin

    ##### SMOOTHED CUBIC SPLINE FIT FUNCTION FOR AM NEA ################################################
    # only on low to high transition
    low2high = [x for x in data_dict["index"][amneabegin[-1]:] if data_dict["comments"][x-2]!=101 and data_dict["comments"][x]==101]
    tranbegin = low2high[0]
    tranend = tranbegin+350
    if data_dict["epoch"][0] < 1325376000:                                                  #### 1102
        tranend = tranbegin+100
    d18otransition = np.max(diffd18o[tranbegin:tranend])
    low2hightransd18o = [x for x in data_dict["index"][tranbegin:tranend] if diffd18o[x]==d18otransition]
    dDtransition = np.max(diffdD[tranbegin:tranend])
    low2hightransdD = [x for x in data_dict["index"][tranbegin:tranend] if diffdD[x]==dDtransition]
    previousbegin = low2hightransdD[0]-300
    previousend = low2hightransdD[0]-200
    currentbegin = low2hightransdD[0]+200
    currentend = low2hightransdD[0]+300
    if data_dict["epoch"][0] < 1325376000:                                                  #### 1102
        previousbegin = low2hightransdD[0]-100
        previousend = low2hightransdD[0]-50
        currentbegin = low2hightransdD[0]+50
        currentend = low2hightransdD[0]+100
    
    previousvalued18o = np.mean(data_dict["d18o"][previousbegin:previousend])
    currentvalued18o = np.mean(data_dict["d18o"][currentbegin:currentend])
    stepsized18o = (currentvalued18o-previousvalued18o)
    midvalued18o = (currentvalued18o+previousvalued18o)/2
    midpointsd18o = [x for x in data_dict["index"][tranbegin:tranend] if data_dict["d18o"][x] >= midvalued18o-2 and data_dict["d18o"][x] <= midvalued18o+2]
    nummidpointsd18o = len(midpointsd18o)
    if nummidpointsd18o>0:
        midpointd18o = np.ceil(np.mean(midpointsd18o[:]))
    else:
        midpointd18o = low2hightransd18o[0]
    Index1d18o = midpointd18o-250
    Index2d18o = midpointd18o+250  
    if data_dict["epoch"][0] < 1325376000:                                                  #### 1102
        Index1d18o = midpointd18o-100
        Index2d18o = midpointd18o+100
    amneaindexd18o = data_dict["index"][Index1d18o:Index2d18o]
    amneaindexnormd18o = amneaindexd18o - Index1d18o
    amnead18o = data_dict["d18o"][Index1d18o:Index2d18o]
    amneanormd18o = (amnead18o-previousvalued18o)/stepsized18o
    
    previousvaluedD = np.mean(data_dict["dD"][previousbegin:previousend])
    currentvaluedD = np.mean(data_dict["dD"][currentbegin:currentend])
    stepsizedD = (currentvaluedD-previousvaluedD)
    midvaluedD = (currentvaluedD+previousvaluedD)/2
    midpointsdD = [x for x in data_dict["index"][tranbegin:tranend] if data_dict["dD"][x] >= midvaluedD-5 and data_dict["dD"][x] <= midvaluedD+5]
    nummidpointsdD = len(midpointsdD)
    if nummidpointsdD>0:
        midpointdD = np.ceil(np.mean(midpointsdD[:]))
    else:
        midpointdD = low2hightransdD[0]
    Index1dD = midpointdD-250
    Index2dD = midpointdD+250 
    if data_dict["epoch"][0] < 1325376000:                                                  #### 1102   
        Index1dD = midpointdD-100
        Index2dD = midpointdD+100 
    amneaindexdD = data_dict["index"][Index1dD:Index2dD]
    amneaindexnormdD = amneaindexdD - Index1dD
    amneadD = data_dict["dD"][Index1dD:Index2dD]
    amneanormdD = (amneadD-previousvaluedD)/stepsizedD

    ##### SMOOTHED CUBIC SPLINE FIT FUNCTION FOR PM NEA ################################################
    low2high = [x for x in data_dict["index"][pmneabegin[-1]:] if data_dict["comments"][x-2]!=101 and data_dict["comments"][x]==101]
    tranbegin = low2high[0]
    tranend = tranbegin+350
    if data_dict["epoch"][0] < 1325376000:                                                  #### 1102 
        tranend = tranbegin+100
    d18otransition = np.max(diffd18o[tranbegin:tranend])
    low2hightransd18o = [x for x in data_dict["index"][tranbegin:tranend] if diffd18o[x]==d18otransition]
    dDtransition = np.max(diffdD[tranbegin:tranend])
    low2hightransdD = [x for x in data_dict["index"][tranbegin:tranend] if diffdD[x]==dDtransition]
    previousbegin = low2hightransdD[0]-300
    previousend = low2hightransdD[0]-200
    currentbegin = low2hightransdD[0]+200
    currentend = low2hightransdD[0]+300
    if data_dict["epoch"][0] < 1325376000:                                                  #### 1102 
        previousbegin = low2hightransdD[0]-100
        previousend = low2hightransdD[0]-50
        currentbegin = low2hightransdD[0]+50
        currentend = low2hightransdD[0]+100
    previousvalued18o = np.mean(data_dict["d18o"][previousbegin:previousend])
    currentvalued18o = np.mean(data_dict["d18o"][currentbegin:currentend])
    stepsized18o = (currentvalued18o-previousvalued18o)
    midvalued18o = (currentvalued18o+previousvalued18o)/2
    midpointsd18o = [x for x in data_dict["index"][tranbegin:tranend] if data_dict["d18o"][x] >= midvalued18o-2 and data_dict["d18o"][x] <= midvalued18o+2]
    nummidpointsd18o = len(midpointsd18o)
    if nummidpointsd18o>0:
        midpointd18o = np.ceil(np.mean(midpointsd18o[:]))
    else:
        midpointd18o = low2hightransd18o[0]
    Index1d18o = midpointd18o-250
    Index2d18o = midpointd18o+250  
    if data_dict["epoch"][0] < 1325376000:                                                  #### 1102 
        Index1d18o = midpointd18o-100
        Index2d18o = midpointd18o+100 
    pmneaindexd18o = data_dict["index"][Index1d18o:Index2d18o]
    pmneaindexnormd18o = pmneaindexd18o - Index1d18o
    pmnead18o = data_dict["d18o"][Index1d18o:Index2d18o]
    pmneanormd18o = (pmnead18o-previousvalued18o)/stepsized18o
    
    previousvaluedD = np.mean(data_dict["dD"][previousbegin:previousend])
    currentvaluedD = np.mean(data_dict["dD"][currentbegin:currentend])
    stepsizedD = (currentvaluedD-previousvaluedD)
    midvaluedD = (currentvaluedD+previousvaluedD)/2
    midpointsdD = [x for x in data_dict["index"][tranbegin:tranend] if data_dict["dD"][x] >= midvaluedD-5 and data_dict["dD"][x] <= midvaluedD+5]
    nummidpointsdD = len(midpointsdD)
    if nummidpointsdD>0:
        midpointdD = np.ceil(np.mean(midpointsdD[:]))
    else:
        midpointdD = low2hightransdD[0]
    Index1dD = midpointdD-250
    Index2dD = midpointdD+250   
    if data_dict["epoch"][0] < 1325376000:                                                  #### 1102
        Index1dD = midpointdD-100
        Index2dD = midpointdD+100
    pmneaindexdD = data_dict["index"][Index1dD:Index2dD]
    pmneaindexnormdD = pmneaindexdD - Index1dD
    pmneadD = data_dict["dD"][Index1dD:Index2dD]
    pmneanormdD = (pmneadD-previousvaluedD)/stepsizedD
    
    #### combine am and pm neas to get average
    neaindex = np.append(amneaindexnormd18o,pmneaindexnormd18o)
    nead18o = np.append(amneanormd18o,pmneanormd18o)
    neadD = np.append(amneanormdD,pmneanormdD)
    sortindex = np.argsort(neaindex)
    sortedneaindex = neaindex[sortindex]
    sortednead18o = nead18o[sortindex]
    sortedneadD = neadD[sortindex]
    avenead18o = amneanormd18o.copy()
    aveneadD = amneanormdD.copy()
    for p in amneaindexnormd18o:
        aveindex = np.where(sortedneaindex==p)[0]
        avenead18o[p] = np.mean(sortednead18o[aveindex])
        aveneadD[p] = np.mean(sortedneadD[aveindex])
    smavenead18o = smooth(avenead18o)
    smaveneadD = smooth(aveneadD)
    
    fig421 = plt.figure(421)
    clear = plt.clf()
    fig421_ax1 = fig421.add_subplot(211)
    fig421_ax1.plot(amneaindexnormd18o, amneanormd18o, "b-", amneaindexnormd18o, pmneanormd18o, "g-",  \
        sortedneaindex, sortednead18o, "k-",  amneaindexnormd18o, smavenead18o, "b-")
    fig421_ax1.set_ylabel("d18o")
    fig421_ax2 = fig421.add_subplot(212)
    fig421_ax2.plot(amneaindexnormd18o, amneanormdD, "r-",  amneaindexnormd18o, pmneanormdD, "m-",  \
        sortedneaindex, sortedneadD, "k-",  amneaindexnormd18o, smaveneadD, "r-")
    fig421_ax2.set_ylabel("dD")
    fig421_ax2.set_xlabel("Index")
    fig421_ax1.set_title("%s" %(os.path.splitext(filepath)[0]))
    
    ##### RUN THE TRANSFER FUNCTION ################################################
    nea_skewsigma_d18o = []
    nea_normsigma_d18o = []
    nea_skewsigma_dD = []
    nea_normsigma_dD = []
    
    # only on low to high transition
    low2high = [x for x in data_dict["index"][amneabegin[-1]:] if data_dict["comments"][x-2]!=101 and data_dict["comments"][x]==101]
    tranbegin = low2high[0]
    tranend = tranbegin+150
    d18otransition = np.max(abs(diffd18o[tranbegin:tranend]))
    low2hightransd18o = [x for x in data_dict["index"][tranbegin:tranend] if abs(diffd18o[x])==d18otransition]
    dDtransition = np.max(abs(diffdD[tranbegin:tranend]))
    low2hightransdD = [x for x in data_dict["index"][tranbegin:tranend] if abs(diffdD[x])==dDtransition]
    Index1 = low2hightransdD[0]-200
    Index2 = low2hightransdD[0]+200
    if data_dict["epoch"][0] < 1325376000:                                                  #### 1102
        Index1 = low2hightransdD[0]-100
        Index2 = low2hightransdD[0]+100
    step = low2hightransdD[0]
    run_am_nea_transfer = PerformTransfer(type='AMNea', int = 5, TransferIndex1 = Index1, TransferIndex2 = Index2, StepIndex = step)
    nea_skewsigma_d18o.append(run_am_nea_transfer[11])
    nea_normsigma_d18o.append(run_am_nea_transfer[12])
    nea_skewsigma_dD.append(run_am_nea_transfer[13])
    nea_normsigma_dD.append(run_am_nea_transfer[14])

    ##### RUN THE TRANSFER FUNCTION ################################################
    low2high = [x for x in data_dict["index"][pmneabegin[-1]:] if data_dict["comments"][x-2]!=101 and data_dict["comments"][x]==101]
    tranbegin = low2high[0]
    tranend = tranbegin+150
    d18otransition = np.max(abs(diffd18o[tranbegin:tranend]))
    low2hightransd18o = [x for x in data_dict["index"][tranbegin:tranend] if abs(diffd18o[x])==d18otransition]
    dDtransition = np.max(abs(diffdD[tranbegin:tranend]))
    low2hightransdD = [x for x in data_dict["index"][tranbegin:tranend] if abs(diffdD[x])==dDtransition]
    Index1 = low2hightransdD[0]-200
    Index2 = low2hightransdD[0]+200
    if data_dict["epoch"][0] < 1325376000:                                                  #### 1102
        Index1 = low2hightransdD[0]-100
        Index2 = low2hightransdD[0]+100
    step = low2hightransdD[0]
    run_pm_nea_transfer = PerformTransfer(type='PMNea', int = 7, TransferIndex1 = Index1, TransferIndex2 = Index2, StepIndex = step)
    nea_skewsigma_d18o.append(run_pm_nea_transfer[11])
    nea_normsigma_d18o.append(run_pm_nea_transfer[12])
    nea_skewsigma_dD.append(run_pm_nea_transfer[13])
    nea_normsigma_dD.append(run_pm_nea_transfer[14])
    
    ave_nea_skewsigma_d18o = np.mean(nea_skewsigma_d18o)
    ave_nea_normsigma_d18o = np.mean(nea_normsigma_d18o)
    ave_nea_skewsigma_dD = np.mean(nea_skewsigma_dD)
    ave_nea_normsigma_dD = np.mean(nea_normsigma_dD)
    
    ###### MEMORY CORRECTION APPLIED TO NEAS TO CHECK CORRECTION
    # if analysis date after 4/16/13, then apply this melt to melt correction, otherwise valco memory already applied
    amneachange = [x for x in data_dict["index"][amneabegin[0]:amneabegin[0]+1000] if (data_dict["comments"][x-1]!=101 and \
        data_dict["comments"][x]==101) or (data_dict["comments"][x-1]!=104 and data_dict["comments"][x]==104)] ### low to high and high to low
    pmneachange = [x for x in data_dict["index"][pmneabegin[0]:pmneabegin[0]+1000] if (data_dict["comments"][x-1]!=101 and \
        data_dict["comments"][x]==101) or (data_dict["comments"][x-1]!=104 and data_dict["comments"][x]==104)] ### low to high and high to low
    meltchange = np.append(amneachange,pmneachange)
    nummeltchange = len(meltchange)
    if verbose == 1:
        print meltchange
        print nummeltchange
    
    neamemd18o = valcomemd18o.copy()
    neamemdD = valcomemdD.copy()

    if data_dict["epoch"][0] < 1325376000:                                           #### 1102
        for i in meltchange: # change to diff min or max?
            previousbegin = i-500
            previousend = i
            currentbegin = i+50
            currentend = i+100
            previousvalued18o = np.mean(data_dict["d18o"][previousbegin:previousend])
            previousvaluedD = np.mean(data_dict["dD"][previousbegin:previousend])
            currentvalued18o = np.mean(data_dict["d18o"][currentbegin:currentend])
            stepsize = (currentvalued18o-previousvalued18o)
            middlevalue = (previousvalued18o+currentvalued18o)/2
            midpoints = [x for x in data_dict["index"][i:currentend] if data_dict["d18o"][x] >= middlevalue-2 and data_dict["d18o"][x] <= middlevalue+2]
            nummidpoints = len(midpoints)
            if nummidpoints>0:
                midpoint = np.ceil(np.mean(midpoints[:]))
            else:
                midvalue = np.max(np.abs(diffd18o[i:currentend]))
                midpoints = [x for x in data_dict["index"][i:currentend] if np.abs(diffd18o[x]) == midvalue]
                midpoint = np.ceil(np.mean(midpoints[:]))
            for z in data_dict["index"][midpoint:midpoint+100]:
                neamemd18o[z] = (valcomemd18o[z]-previousvalued18o*(1-smavenead18o[z-midpoint+100]))/(smavenead18o[z-midpoint+100])
                data_dict["flag4"][z] = 'n'
            for z in data_dict["index"][midpoint:midpoint+100]:
                neamemdD[z] = (valcomemdD[z]-previousvaluedD*(1-smaveneadD[z-midpoint+100]))/(smaveneadD[z-midpoint+100])
                data_dict["flag4"][z] = 'n'
        neamemdexcess = neamemdD-8*neamemd18o
        
    if data_dict["epoch"][0] > 1325376000:                                           ### 2130       
        for i in meltchange: # change to diff min or max?
            previousbegin = i-100
            previousend = i
            currentbegin = i+150
            currentend = i+250
            previousvalued18o = np.mean(data_dict["d18o"][previousbegin:previousend])
            previousvaluedD = np.mean(data_dict["dD"][previousbegin:previousend])
            currentvalued18o = np.mean(data_dict["d18o"][currentbegin:currentend])
            stepsize = (currentvalued18o-previousvalued18o)
            middlevalue = (previousvalued18o+currentvalued18o)/2
            midpoints = [x for x in data_dict["index"][i:currentend] if data_dict["d18o"][x] >= middlevalue-2 and data_dict["d18o"][x] <= middlevalue+2]
            nummidpoints = len(midpoints)
            if nummidpoints>0:
                midpoint = np.ceil(np.mean(midpoints[:]))
            else:
                midvalue = np.max(np.abs(diffd18o[i:currentend]))
                midpoints = [x for x in data_dict["index"][i:currentend] if np.abs(diffd18o[x]) == midvalue]
                midpoint = np.ceil(np.mean(midpoints[:]))
            for z in data_dict["index"][midpoint:midpoint+250]:
                neamemd18o[z] = (valcomemd18o[z]-previousvalued18o*(1-smavenead18o[z-midpoint+250]))/(smavenead18o[z-midpoint+250])
                data_dict["flag4"][z] = 'n'
            for z in data_dict["index"][midpoint:midpoint+250]:
                neamemdD[z] = (valcomemdD[z]-previousvaluedD*(1-smaveneadD[z-midpoint+250]))/(smaveneadD[z-midpoint+250])
                data_dict["flag4"][z] = 'n'
        neamemdexcess = neamemdD-8*neamemd18o
        
    #### plot memory corrected values onto original graph
    fig21_ax1.plot(data_dict["index"], neamemd18o, "c-")
    fig21_ax2.plot(data_dict["index"], neamemdD, "k-")
    fig21_ax3.plot(data_dict["index"], neamemdexcess, "y-")


    ##### ISOTOPE CALIBRATION - linear fit, with slope intercept and appy slope intercept to data
    def linearfunc (m, x, b):
        return m*x + b
    
    corrd18o = neamemd18o.copy()
    corrdD = neamemdD.copy()
    
    driftcorstdd18o = [0,0,0]
    stdevdriftcorstdd18o = [0,0,0]
    driftcorstddD = [0,0,0]
    stdevdriftcorstddD = [0,0,0]
    
    #   STANDARDS  KBW     KAW     (KGW)     KPW    for WAIS06A
    #   position   0       1       (2   )    3
    # knownd18o = [-14.19, -30.35, (-38.09), -45.43]
    # knowndD   = [-111.8, -239.3, (-298.7), -355.6]
    
    if corename == "WAIS06AData":
        driftcorstdd18o[0] = np.mean(rawkbwd18o)
        stdevdriftcorstdd18o[0] = np.std(rawkbwd18o) 
        driftcorstdd18o[1] = np.mean(rawkawd18o)
        stdevdriftcorstdd18o[1] = np.std(rawkawd18o)
        driftcorstdd18o[2] = np.mean(rawkpwd18o)
        stdevdriftcorstdd18o[2] = np.std(rawkpwd18o)
        
        driftcorstddD[0] = rawkbwdD[1] 
        stdevdriftcorstddD[0] = np.std(rawkbwdD) 
        driftcorstddD[1] = rawkawdD[0]
        stdevdriftcorstddD[1] = np.std(rawkawdD)
        driftcorstddD[2] = rawkpwdD[0]
        stdevdriftcorstddD[2] = np.std(rawkpwdD)
        
    #   STANDARDS  kaw     kgw     (kpw)     vw1f   for SPIceCore
    #   position   0       1       (2  )     3
    # knownd18o = [-30.35, -38.09, (-45.43),  -56]
    # knowndD   = [-239.3, -298.7, (-355.6), -438]

    if corename == "SPIceCoreData":
        driftcorstdd18o[0] = np.mean(rawkawd18o)
        stdevdriftcorstdd18o[0] = np.std(rawkawd18o) 
        driftcorstdd18o[1] = np.mean(rawkgwd18o)
        stdevdriftcorstdd18o[1] = np.std(rawkgwd18o)
        driftcorstdd18o[2] = np.mean(rawvw1fd18o)
        stdevdriftcorstdd18o[2] = np.std(rawvw1fd18o)

        driftcorstddD[0] = rawkawdD[1] 
        stdevdriftcorstddD[0] = np.std(rawkawdD) 
        driftcorstddD[1] = rawkgwdD[0]
        stdevdriftcorstddD[1] = np.std(rawkgwdD)
        driftcorstddD[2] = rawvw1fdD[0]
        stdevdriftcorstddD[2] = np.std(rawvw1fdD)
    
    d18oslope, d18ointercept, d18or_value, d18op_value, d18ostd_err = stats.linregress(driftcorstdd18o,knownd18o)
    dDslope, dDintercept, dDr_value, dDp_value, dDstd_err = stats.linregress(driftcorstddD,knowndD)

    if verbose ==1:
        print "d18O Stats"
        print "knownd18o", knownd18o
        print "riftcorstdd18o", driftcorstdd18o
        print "stdevdriftcorstdd18o", stdevdriftcorstdd18o
        print "d18oslope", d18oslope
        print "d18ointercept", d18ointercept
        print "dD Stats"
        print "knowndD", knowndD
        print "driftcorstddD", driftcorstddD
        print "stdevdriftcorstddD", stdevdriftcorstddD
        print "dDslope", dDslope
        print "dDintercept", dDintercept

    corrd18o = neamemd18o * d18oslope + d18ointercept
    corrdD = neamemdD * dDslope + dDintercept

    #### plot slope corrected values onto original graph
    fig21_ax1.plot(data_dict["index"], corrd18o, "b-")
    fig21_ax2.plot(data_dict["index"], corrdD, "r-") 

    ##### CALCULATE corrected VALUES FOR STANDARDS IN VALCO
    corrstdd18o = []
    stdevcorrstdd18o = []
    corrstddD = []
    stdevcorrstddD = []

    for i in amtransbegin:
        begin = i-70
        end = i
        meand18o = np.mean(corrd18o[begin:end])
        if np.mean(data_dict["water_ppm"][begin:end]) < 10000:
             meand18o = 9999
        corrstdd18o.append(meand18o)                            
        stdevcorrstdd18o.append(np.std(corrd18o[begin:end]))
        corrstddD.append(np.mean(corrdD[begin:end]))
        stdevcorrstddD.append(np.std(corrdD[begin:end]))

    begin = trans7[0]-70
    end = trans7[0]
    meand18o = np.mean(corrd18o[begin:end])
    if np.mean(data_dict["water_ppm"][begin:end]) < 10000:
        meand18o = 9999
    corrstdd18o.append(meand18o)                            
    stdevcorrstdd18o.append(np.std(corrd18o[begin:end]))                          
    corrstddD.append(np.mean(corrdD[begin:end]))                           
    stdevcorrstddD.append(np.std(corrdD[begin:end]))                            

    for i in pmtransbegin:
        begin = i-70
        end = i
        meand18o = np.mean(corrd18o[begin:end])
        if np.mean(data_dict["water_ppm"][begin:end]) < 10000:
             meand18o = 9999
        corrstdd18o.append(meand18o)                            
        stdevcorrstdd18o.append(np.std(corrd18o[begin:end]))                            
        corrstddD.append(np.mean(corrdD[begin:end]))                            
        stdevcorrstddD.append(np.std(corrdD[begin:end]))                            

    begin = trans7[-1]-70
    end = trans7[-1]
    meand18o = np.mean(corrd18o[begin:end])
    if np.mean(data_dict["water_ppm"][begin:end]) < 10000:
        meand18o = 9999
    corrstdd18o.append(meand18o)                            
    stdevcorrstdd18o.append(np.std(corrd18o[begin:end]))                            
    corrstddD.append(np.mean(corrdD[begin:end]))                            
    stdevcorrstddD.append(np.std(corrdD[begin:end]))                            

    ##### ASSIGN corrstd VALUES ####################################
    fourstd = np.arange(4)
    twostd = np.arange(2)
    diffam2pmd18o = np.arange(4)
    diffam2pmdD = np.arange(4)

    ##### Assign KBW measured isotope values #######################################    
    if corename == "WAIS06AData":
        corrstdkbwd18o = [corrstdd18o[1],corrstdd18o[7],corrstdd18o[9],corrstdd18o[15]]
        corrstdkbwdD = [corrstddD[1],corrstddD[7],corrstddD[9],corrstddD[15]]
        if filepath == "/Users/frio/GoogleDrive/WAIS06AData/raw_dictionaries/rawHIDS2038-20120305-091844Z-DataLog_User.dat":
            corrstdkbwd18o = [corrstdd18o[7],corrstdd18o[7],corrstdd18o[9],corrstdd18o[15]]
            corrstdkbwdD = [corrstddD[7],corrstddD[7],corrstddD[9],corrstddD[15]]
            print "in 20120305 loop"
        if filepath == "/Users/frio/GoogleDrive/WAIS06AData/raw_dictionaries/rawHIDS2038-20121013-085350Z-DataLog_User_B.dat":
            corrstdkbwd18o = [corrstdd18o[1],corrstdd18o[1],corrstdd18o[1],corrstdd18o[1]]
            corrstdkbwdD = [corrstddD[1],corrstddD[1],corrstddD[1],corrstddD[1]]
        if filepath == "/Users/frio/GoogleDrive/WAIS06AData/raw_dictionaries/rawHIDS2038-20121017-101908Z-DataLog_User.dat":
            corrstdkbwd18o = [corrstdd18o[1],corrstdd18o[7],corrstdd18o[9],corrstdd18o[9]]
            corrstdkbwdD = [corrstddD[1],corrstddD[7],corrstddD[9],corrstddD[9]]                                           

        meankbwd18o = np.mean(corrstdkbwd18o)
        stdkbwd18o = np.std(corrstdkbwd18o)
        diffkbwd18o = kbwd18o - meankbwd18o
        diffam2pmd18o[0] = np.mean(corrstdkbwd18o[0:1])-np.mean(corrstdkbwd18o[2:3])  

        meankbwdD = np.mean(corrstdkbwdD)
        stdkbwdD = np.std(corrstdkbwdD)
        diffkbwdD = kbwdD - meankbwdD
        diffam2pmdD[0] = np.mean(corrstdkbwdD[0:1])-np.mean(corrstdkbwdD[2:3])

        if verbose ==1:
            print "KBW corrstd d18o valco values"
            print corrstdkbwd18o
            print meankbwd18o, stdkbwd18o, diffkbwd18o
            print "KBW corrstd dD valco values"
            print corrstdkbwdD
            print meankbwdD, stdkbwdD, diffkbwdD

    ##### Assign kaw measured isotope values #######################################    
    if corename == "WAIS06AData":
        corrstdkawd18o = [corrstdd18o[2],corrstdd18o[6],corrstdd18o[10],corrstdd18o[14]]
        corrstdkawdD = [corrstddD[2],corrstddD[6],corrstddD[10],corrstddD[14]]
    if corename == "SPIceCoreData":
        corrstdkawd18o = [corrstdd18o[1],corrstdd18o[7],corrstdd18o[9],corrstdd18o[15]]
        corrstdkawdD = [corrstddD[1],corrstddD[7],corrstddD[9],corrstddD[15]]                                           

    meankawd18o = np.mean(corrstdkawd18o)
    stdkawd18o = np.std(corrstdkawd18o)
    diffkawd18o = kawd18o - meankawd18o
    diffam2pmd18o[0] = np.mean(corrstdkawd18o[0:1])-np.mean(corrstdkawd18o[2:3])

    meankawdD = np.mean(corrstdkawdD)
    stdkawdD = np.std(corrstdkawdD)
    diffkawdD = kawdD - meankawdD
    diffam2pmdD[0] = np.mean(corrstdkawdD[0:1])-np.mean(corrstdkawdD[2:3])
    
    if verbose ==1:
        print "kaw corrstd d18o valco values"
        print corrstdkawd18o
        print meankawd18o, stdkawd18o, diffkawd18o
        print "kaw corrstd dD valco values"
        print corrstdkawdD
        print meankawdD, stdkawdD, diffkawdD

    ##### Assign kgw measured isotope values #######################################    
    if corename == "WAIS06AData":
        corrstdkgwd18o = [corrstdd18o[3],corrstdd18o[5],corrstdd18o[11],corrstdd18o[13]]
        corrstdkgwdD = [corrstddD[3],corrstddD[5],corrstddD[11],corrstddD[13]]
    if corename == "SPIceCoreData":
        corrstdkgwd18o = [corrstdd18o[2],corrstdd18o[6],corrstdd18o[10],corrstdd18o[14]]
        corrstdkgwdD = [corrstddD[2],corrstddD[6],corrstddD[10],corrstddD[14]]

    meankgwd18o = np.mean(corrstdkgwd18o)
    stdkgwd18o = np.std(corrstdkgwd18o)
    diffkgwd18o = kgwd18o - meankgwd18o
    diffam2pmd18o[1] = np.mean(corrstdkgwd18o[0:1])-np.mean(corrstdkgwd18o[2:3])

    meankgwdD = np.mean(corrstdkgwdD)
    stdkgwdD = np.std(corrstdkgwdD)
    diffkgwdD = kgwdD - meankgwdD
    diffam2pmdD[1] = np.mean(corrstdkgwdD[0:1])-np.mean(corrstdkgwdD[2:3])
    
    if verbose ==1:
        print "kgw corrstd d18o valco values"
        print corrstdkgwd18o
        print meankgwd18o, stdkgwd18o, diffkgwd18o
        print "kgw corrstd dD valco values"
        print corrstdkgwdD
        print meankgwdD, stdkgwdD, diffkgwdD

    ## Assign kpw measured isotope values ########################################## 
    if corename == "WAIS06AData":
        corrstdkpwd18o = [corrstdd18o[4],corrstdd18o[12]]
        corrstdkpwdD = [corrstddD[4],corrstddD[12]]
        
        meankpwd18o = np.mean(corrstdkpwd18o)
        stdkpwd18o = np.std(corrstdkpwd18o)
        diffkpwd18o = kpwd18o - meankpwd18o
        diffam2pmd18o[2] = np.mean(corrstdkpwd18o[0])-np.mean(corrstdkpwd18o[1])
        meankpwdD = np.mean(corrstdkpwdD)
        stdkpwdD = np.std(corrstdkpwdD)
        diffkpwdD = kpwdD - meankpwdD
        diffam2pmdD[2] = np.mean(corrstdkpwdD[0])-np.mean(corrstdkpwdD[1])
        
    if corename == "SPIceCoreData":
        corrstdkpwd18o = [corrstdd18o[3],corrstdd18o[5],corrstdd18o[11],corrstdd18o[13]]
        corrstdkpwdD = [corrstddD[3],corrstddD[5],corrstddD[11],corrstddD[13]]

        meankpwd18o = np.mean(corrstdkpwd18o)
        stdkpwd18o = np.std(corrstdkpwd18o)
        diffkpwd18o = kpwd18o - meankpwd18o
        diffam2pmd18o[2] = np.mean(corrstdkpwd18o[0:1])-np.mean(corrstdkpwd18o[2:3])
        meankpwdD = np.mean(corrstdkpwdD)
        stdkpwdD = np.std(corrstdkpwdD)
        diffkpwdD = kpwdD - meankpwdD
        diffam2pmdD[2] = np.mean(corrstdkpwdD[0:1])-np.mean(corrstdkpwdD[2:3])

    if verbose ==1:
        print "kpw corrstd d18o valco values"
        print corrstdkpwd18o
        print meankpwd18o, stdkpwd18o, diffkpwd18o        
        print "kpw corrstd dD valco values"
        print corrstdkpwdD
        print meankpwdD, stdkpwdD, diffkpwdD

    ##### Assign vw1f measured isotope values ####################################### 
    if corename == "SPIceCoreData":
        corrstdvw1fd18o = [corrstdd18o[4],corrstdd18o[12]]
        corrstdvw1fdD = [corrstddD[4],corrstddD[12]]

        meanvw1fd18o = np.mean(corrstdvw1fd18o)
        stdvw1fd18o = np.std(corrstdvw1fd18o)
        diffvw1fd18o = vw1fd18o - meanvw1fd18o
        diffam2pmd18o[3] = corrstdvw1fd18o[0]-corrstdvw1fd18o[1]

        meanvw1fdD = np.mean(corrstdvw1fdD)
        stdvw1fdD = np.std(corrstdvw1fdD)
        diffvw1fdD = vw1fdD - meanvw1fdD
        diffam2pmdD[3] = corrstdvw1fdD[0]-corrstdvw1fdD[1]

        if verbose ==1:
            print "vw1f corrstd d18o valco values"
            print corrstdvw1fd18o
            print meanvw1fd18o, stdvw1fd18o, diffvw1fd18o
            print "vw1f corrstd dD valco values"
            print corrstdvw1fdD
            print meanvw1fdD, stdvw1fdD, diffvw1fdD

    #### Collect drift values from comparing am to pm valcos
    avedriftstdd18o = np.mean(diffam2pmd18o)
    stdevdriftstdd18o = np.std(diffam2pmd18o)
    avedriftstddD = np.mean(diffam2pmdD)
    stdevdriftstddD = np.std(diffam2pmdD)


    ##### ICE CORE IDENTIFICATION ##################################################
    ## Look at comments to decided on number of cores, location of cores, length of cores
    beginmelt = [x for x in data_dict["index"][1:] if data_dict["comments"][x-1]!=175 and data_dict["comments"][x]==175]
    begincores = [x for x in data_dict["index"][1:-20] if data_dict["comments"][x+20]==175 and \
        data_dict["carousel_pos"][x-1]!=data_dict["carousel_pos"][x] and (data_dict["carousel_pos"][x]-np.ceil(data_dict["carousel_pos"][x]))==0] #comment out last conditional for 20120215
    if len(begincores) == 0 or \
        filepath == "/Users/frio/GoogleDrive/WAIS06AData/raw_dictionaries/rawHIDS2038-20130322-000007Z-DataLog_User.dat" or \
            filepath == "/Users/frio/GoogleDrive/WAIS06AData/raw_dictionaries/rawHIDS2038-20140312-000007Z-DataLog_User.dat" or \
                filepath == "/Users/frio/GoogleDrive/WAIS06AData/raw_dictionaries/rawHIDS2038-20120215-All-DataLog_User":
        begincores = beginmelt
    coreindex = np.arange(len(begincores))
    for x in coreindex:
        begincores[x] = begincores[x] + 5
    startdepth = data_dict["start_depth"][begincores]
    enddepth = data_dict["end_depth"][begincores]
    coredatalength = np.arange(len(begincores))
    for i in coreindex:
        begincores[i] = begincores[i] - 7
        coredataindex = [x for x in data_dict["index"][1:] if data_dict["start_depth"][x]==startdepth[i]]
        coredatalength[i] = len(coredataindex)
    startepoch = data_dict["epoch"][begincores]
    numbeginmelt = len(beginmelt)
    endmelt = [x for x in data_dict["index"][1:] if data_dict["comments"][x-1]==175 and data_dict["comments"][x]!=175]
    meltend = []
    for i in endmelt: meltend.append(i-10)
    numendmelt = len(endmelt)
    if verbose ==1:
        print "Beginning of melts indices ", beginmelt
        print "Start depths ", startdepth
        print "Start time in epoch ", startepoch
        print "Number of cores begun ", numbeginmelt
        print "Ending of melts indices ", endmelt
        print "End depths ", enddepth
        print "Number of cores ended ", numendmelt
        
    ##### Stop and ask if need to edit?
    if verbose == 1:
        checkbegin = raw_input("Do you want to edit the beginning core indices?")
        if checkbegin in ('y', 'ye', 'yes'):
            beginmelt = input("Please type new indices list in [ ]...")
            numbeginmelt = len(beginmelt)
            print "New Beginning of melts ", beginmelt
            print "New Number of cores melted ", numbeginmelt
        checkstartdepth = raw_input("Do you want to edit the beginning core depths?")
        if checkstartdepth in ('y', 'ye', 'yes'):
            wrong_depth = input("Please type in wrong depth...")
            right_depth = input("Please type in right depth...")
            fixcarousel = input("Please type in carousel number for correction...")
            fixtime = input("Please type in epoch time just prior to correction...")
            fixdepth = [x for x in data_dict["index"][:] if data_dict["start_depth"][x]==wrong_depth and \
                data_dict["carousel_pos"][x]==fixcarousel and data_dict["epoch"][x]>=fixtime]
            for x in fixdepth:
                data_dict["true_depth"][x] = data_dict["true_depth"][x] - wrong_depth + right_depth
        checkend = raw_input("Do you want to edit the ending core indices?")
        if checkend in ('y', 'ye', 'yes'):
            endmelt = input("Please type new indices list in [ ]...")
            numendmelt = len(endmelt)
            print "New Ending of melts ", endmelt
            print "New Number of cores melted ". numendmelt
        checkcomments = raw_input("Do you want to edit any of the comment?")
        if checkcomments in ('y', 'ye', 'yes'):
            commentstartindex = input("Please type in start index...")
            commentendindex = input("Please type in end index...")
            newcomment = input("Please type in new comment number...")
            data_dict["comments"][commentstartindex:commentendindex] = newcomment
        
    meltlength = map(lambda x,y: x-y, endmelt, beginmelt)
    meltlengthplus = []
    for i in meltlength: meltlengthplus.append(i+500)

    if verbose ==1:
        print "index length of each melt ", meltlength
        
    #### WRITE TO SEPARATE FILE TO RECORD START AND END DEPTH, START AND END TIME, AVERAGE MELT RATE AND FILENAME
    dataout_file = "/Users/frio/GoogleDrive/"+corename+"/AveMeltrateFile20160112"
    file = open(dataout_file, "a")
    for i in coreindex:
        starttime = data_dict["j_days"][begincores[i]] # in seconds
        endtime = data_dict["j_days"][begincores[i]+coredatalength[i]]
        avemeltrate = ((enddepth[i]-startdepth[i])*100)/((endtime-starttime)/60) # in cm/min
        data = np.transpose(np.vstack((filename, starttime, endtime, startdepth[i], enddepth[i], avemeltrate, crunchversion)))
        np.savetxt(file, data, delimiter = "\t", fmt = ("%s", "%s", "%s", "%s", "%s", "%s", "%s"))
    file.close()

    ## Write raw data dictionary to file for future reprocessing
    dataout_file = "/Users/frio/GoogleDrive/"+corename+"/raw_dictionaries/raw" + filename
    file = open(dataout_file, "w")   
    pickle.dump(data_dict, file)
    file.close()  

    ##### ASSIGN DEPTH, EC TO ISOTOPES AND SAVE FILES #######################    

    ##### Cut out and assign isotopes, ec, and depth to each core ###########
    meltindex = np.arange(len(beginmelt))

    ice_dict ={}
    ice_dict["filepath"] = np.array(()).astype("S")
    ice_dict["time"] = np.array(())
    ice_dict["rawd18o"] = np.array(())
    ice_dict["rawdD"] = np.array(())
    ice_dict["d18o"] = np.array(())
    ice_dict["dD"] = np.array(())
    ice_dict["d_excess"] =np.array(())
    ice_dict["water"] = np.array(())
    ice_dict["ec"] = np.array(())
    ice_dict["depth"] = np.array(())
    ice_dict["vial"] = np.array(())
    ice_dict["meltrate"] = np.array(())
    ice_dict["flag1"] = np.array(()).astype("S")
    ice_dict["flag2"] = np.array(()).astype("S")
    ice_dict["flag3"] = np.array(()).astype("S")
    ice_dict["flag4"] = np.array(()).astype("S")
    ice_dict["flag5"] = np.array(()).astype("S")
    ice_dict["flag6"] = np.array(()).astype("S")
    ice_dict["ave_valco_normsigma_d18o"] = np.array(())
    ice_dict["ave_valco_normsigma_dD"] = np.array(())
    ice_dict["ave_valco_skewsigma_d18o"] = np.array(())
    ice_dict["ave_valco_skewsigma_dD"] = np.array(())
    ice_dict["ave_nea_normsigma_d18o"] = np.array(())
    ice_dict["ave_nea_normsigma_dD"] = np.array(())
    ice_dict["ave_nea_skewsigma_d18o"] = np.array(())
    ice_dict["ave_nea_skewsigma_dD"] = np.array(())
    ice_dict["prodate"] = np.array(())
    ice_dict["crunchversion"] = np.array(())
    
    memcorrd18o = corrd18o.copy()
    memcorrdD = corrdD.copy()

    for i in meltindex:
        startmelt = beginmelt[i]+5
        endmelt = startmelt + meltlength[i]-10
        if endmelt >= data_dict["index"][-1]:
            endmelt = data_dict["index"][-1]
        endmeltplus = startmelt + meltlengthplus[i]
        if endmeltplus >= data_dict["index"][-1]:
            endmeltplus = data_dict["index"][-1]  #put in for cut files that had binary shifts half way through the day
        core = data_dict["index"][startmelt:endmelt]
        ##### FIND THE MINIUMS, AND ASSIGN BEGINNING AND END OF CORES ##############
        startiso = np.min(diffdD[startmelt:endmelt])
        endiso = np.max(diffdD[endmelt:endmeltplus]) #    endiso = np.max(diffdD[startmelt:endmeltplus])
        startisoindex = [x for x in data_dict["index"][startmelt:endmelt] if diffdD[x]==startiso] # by first derivative, could be from mid point if was saved in an array...
        startisoindex = startisoindex[0]
        endisoindex = [x for x in data_dict["index"][startmelt:endmeltplus] if diffdD[x]==endiso]
        endisoindex = endisoindex[0]
        print startisoindex
        print endisoindex
        
        #Special cases where the isotopes need to be identified manually
        #### For WAIS06A
        if filepath == "/Users/frio/GoogleDrive/"+corename+"/raw_dictionaries/rawHBDS92-20110831-0814-Data.dat":
            startiso20110831 = [2816,5057,7128,9171,11440,13741]
            endiso20110831 = [4597,6653,8666,10763,13004,15745]
            startisoindex = startiso20110831[i]
            endisoindex = endiso20110831[i]
        if filepath == "/Users/frio/GoogleDrive/"+corename+"/raw_dictionaries/rawHBDS92-20110912-0856-Data.dat":
            startiso20110912 = [3833,5532,7354]
            endiso20110912 = [5112,6931,9010]
            startisoindex = startiso20110912[i]
            endisoindex = endiso20110912[i]
        if filepath == "/Users/frio/GoogleDrive/"+corename+"/raw_dictionaries/rawHBDS92-20110914-0820-Data.dat":
            startiso20110914 = [2640, 4583, 7685, 9794, 12031, 14293, 16180, 18145]
            endiso20110914 = [4206, 6315, 9287, 11400, 13742, 15620, 17738, 19666]
            startisoindex = startiso20110914[i]
            endisoindex = endiso20110914[i]
        if filepath == "/Users/frio/GoogleDrive/"+corename+"/raw_dictionaries/rawHBDS92-20110926-0835-Data.dat":
            startiso20110926 = [2179,4151,6257,8410,16080]
            endiso20110926 = [3701,5762,7972,9696,17687]
            startisoindex = startiso20110926[i]
            endisoindex = endiso20110926[i] 
        if filepath == "/Users/frio/GoogleDrive/"+corename+"/raw_dictionaries/rawHBDS92-20110928-0822-Data.dat":
            startiso20110928 = [2681,5775,7282,9155,11541,13583,15516,17572]
            endiso20110928 = [2896,6828,8710,10670,13215,15126,17165,20868]
            startisoindex = startiso20110928[i]
            endisoindex = endiso20110928[i]
        if filepath == "/Users/frio/GoogleDrive/"+corename+"/raw_dictionaries/rawHBDS92-20110929-1155-Data.dat":
            startiso20110929 = [2777,4782,6349]
            endiso20110929 = [4055,5943,7882]
            startisoindex = startiso20110929[i]
            endisoindex = endiso20110929[i]
        if filepath == "/Users/frio/GoogleDrive/"+corename+"/raw_dictionaries/rawHBDS92-20111006-1124-Data.dat":
            startiso20111006 = [2266,3969,5729,7232,9510,11568,12761,14545]
            endiso20111006 = [3556,4489,6725,8852,10052,12403,14147,15807]
            startisoindex = startiso20111006[i]
            endisoindex = endiso20111006[i]
        if filepath == "/Users/frio/GoogleDrive/"+corename+"/raw_dictionaries/rawHIDS2038-20120410-085352Z-DataLog_User.dat":
            startiso20120410 = [6227,9554,12991,16311,19951,24105,28638,32606,35884,39266]
            endiso20120410 = [8827,12046,15504,18906,22523,26721,31451,35133,38476,41755]
            startisoindex = startiso20120410[i]
            endisoindex = endiso20120410[i]
        if filepath == "/Users/frio/GoogleDrive/"+corename+"/raw_dictionaries/rawHIDS2038-20120615-084804Z-DataLog_User.dat":
            startiso20120615 = [5281,8668,12098,15566,18946,22535,26380]
            endiso20120615 = [8020,11376,14878,18261,21871,25427,29230]
            startisoindex = startiso20120615[i]
            endisoindex = endiso20120615[i]
        if filepath == "/Users/frio/GoogleDrive/"+corename+"/raw_dictionaries/rawHIDS2038-20120619-091825Z-DataLog_User.dat":
            startiso20120619 = [5148,8677,12070,15565,20263,23588,27291,30995,34613,38209,41761,45201,48822]
            endiso20120619 = [8018,11410,14932,18344,22941,26345,29946,33728,37317,40994,44460,48048,51378]
            startisoindex = startiso20120619[i]
            endisoindex = endiso20120619[i]
        if filepath == "/Users/frio/GoogleDrive/"+corename+"/raw_dictionaries/rawHIDS2038-20120820-091333Z-DataLog_User.dat":
            startiso20120820 = [5050,8665,12201,15687,19862,23351,26754,30945,34653]
            endiso20120820 = [7971,11408,14987,19041,22659,26009,29916,33875,37516]
            startisoindex = startiso20120820[i]
            endisoindex = endiso20120820[i]
        if filepath == "/Users/frio/GoogleDrive/"+corename+"/raw_dictionaries/rawHIDS2038-20120905-095650Z-DataLog_User.dat":
            startiso20120905 = [5595,9031,12415,17256,20700,22518,25685,29350,33171,36495,38572]
            endiso20120905 = [8321,11632,16308,20009,21308,24767,28597,32450,35692,37774,40061]
            startisoindex = startiso20120905[i]
            endisoindex = endiso20120905[i]
        if filepath == "/Users/frio/GoogleDrive/"+corename+"/raw_dictionaries/rawHIDS2038-20120918-091028Z-DataLog_User.dat":
            startiso20120918 = [5105,8530,11986,15832,19488,23230,26662,30514,34104,38539,42988]
            endiso20120918 = [7934,11356,15187,18792,22513,26038,29597,33215,37543,41623,45403]
            startisoindex = startiso20120918[i]
            endisoindex = endiso20120918[i]  
        if filepath == "/Users/frio/GoogleDrive/"+corename+"/raw_dictionaries/rawHIDS2038-20120919-093631Z-DataLog_User.dat":
            startiso20120919 = [13600,17070,20402,23797,27106,30890,34447,37796]
            endiso20120919 = [16395,19763,23179,26461,30163,33786,37173,40635]
            startisoindex = startiso20120919[i]
            endisoindex = endiso20120919[i] 
        if filepath == "/Users/frio/GoogleDrive/"+corename+"/raw_dictionaries/rawHIDS2038-20120922-092103Z-DataLog_User.dat":
            startiso20120922 = [12425,15965,19494,23365,27118,30802,34331,38507]
            endiso20120922 = [15132,18755,22466,26390,30069,33639,37091,41116]
            startisoindex = startiso20120922[i]
            endisoindex = endiso20120922[i] 
        if filepath == "/Users/frio/GoogleDrive/"+corename+"/raw_dictionaries/rawHIDS2038-20121013-085350Z-DataLog_User_A.dat":
            startiso20121013 = [8271,10976,14260,17787,21030,24867,28331]
            endiso20121013 = [8644,13447,16972,20158,24086,27618,30182]
            startisoindex = startiso20121013[i]
            endisoindex = endiso20121013[i] 
        if filepath == "/Users/frio/GoogleDrive/"+corename+"/raw_dictionaries/rawHIDS2038-20130125-000005Z-DataLog_User.dat":
            startiso20130125 = [52069,55656,59285,63451,67082,71126,74721,78067,81699]
            endiso20130125 = [54802,58468,62572,66229,70131,72519,76148,80877,84469]
            startisoindex = startiso20130125[i]
            endisoindex = endiso20130125[i]
        if filepath == "/Users/frio/GoogleDrive/"+corename+"/raw_dictionaries/rawHIDS2038-20130128-000014Z-DataLog_User.dat":
            startiso20130128 = [54202,57939,62693,66709,72964,81273]
            endiso20130128 = [56970,61628,65740,69786,77040,81551]
            startisoindex = startiso20130128[i]
            endisoindex = endiso20130128[i]         
        if filepath == "/Users/frio/GoogleDrive/"+corename+"/raw_dictionaries/rawHIDS2038-20130517-000006Z-DataLog_User.dat":
            startiso20130517 = [54993,63269,74466,85458]
            endiso20130517 = [62768,73956,84997,88265]
            startisoindex = startiso20130517[i]
            endisoindex = endiso20130517[i]
        if filepath == "/Users/frio/GoogleDrive/"+corename+"/raw_dictionaries/rawHIDS2038-20130711-000009Z-DataLog_User.dat":
            startiso20130711 = [50242, 61549, 73024]
            endiso20130711 = [61059, 72248, 83115]
            startisoindex = startiso20130711[i]
            endisoindex = endiso20130711[i]
        if filepath == "/Users/frio/GoogleDrive/"+corename+"/raw_dictionaries/rawHIDS2038-20130712-000008Z-DataLog_User.dat":
            startiso20130712 = [54800, 59500, 67560, 78178]
            endiso20130712 = [57466, 67098, 77700, 82847]
            startisoindex = startiso20130712[i]
            endisoindex = endiso20130712[i]
        if filepath == "/Users/frio/GoogleDrive/"+corename+"/raw_dictionaries/rawHIDS2038-20130802-000006Z-DataLog_User.dat":
            startiso20130802 = [49476,59145,71148,80083]
            endiso20130802 = [58545,70659,79327,88307]
            startisoindex = startiso20130802[i]
            endisoindex = endiso20130802[i]
        if filepath == "/Users/frio/GoogleDrive/"+corename+"/raw_dictionaries/rawHIDS2038-20130904-000007Z-DataLog_User.dat":
            startiso20130904 = [53938,62352,68484,73899,81172]
            endiso20130904 = [61849,65034,73327,79204,86448]
            startisoindex = startiso20130904[i]
            endisoindex = endiso20130904[i]
        if filepath == "/Users/frio/GoogleDrive/"+corename+"/raw_dictionaries/rawHIDS2038-20130920-000018Z-DataLog_User.dat":
            startiso20130920 = [64343,73338,78942,85336]
            endiso20130920 = [72736,76129,84728,93772]
            startisoindex = startiso20130920[i]
            endisoindex = endiso20130920[i]
        if filepath == "/Users/frio/GoogleDrive/"+corename+"/raw_dictionaries/rawHIDS2038-20131017-000028Z-DataLog_User.dat":
            startiso20131017 = [53169,56030,66811,69521,72684,85408,87108]
            endiso20131017 = [55536,60386,67346,72177,83312,86501,92266]
            startisoindex = startiso20131017[i]
            endisoindex = endiso20131017[i]
        if filepath == "/Users/frio/GoogleDrive/"+corename+"/raw_dictionaries/rawHIDS2038-20131210-000008Z-DataLog_User.dat":
            startiso20131210 = [53359,64552,75765]
            endiso20131210 = [63712,75249,79957]
            startisoindex = startiso20131210[i]
            endisoindex = endiso20131210[i]
        if filepath == "/Users/frio/GoogleDrive/"+corename+"/raw_dictionaries/rawHIDS2038-20140128-000008Z-DataLog_User.dat":
            startiso20140128 = [47718,55946,63385]
            endiso20140128 = [55378,62799,70956]
            startisoindex = startiso20140128[i]
            endisoindex = endiso20140128[i]
        if filepath == "/Users/frio/GoogleDrive/"+corename+"/raw_dictionaries/rawHIDS2038-20140206-000008Z-DataLog_User.dat":
            startiso20140206 = [53979,63914,72355,81820,88003]
            endiso20140206 = [63377,71831,81001,86533,90479]
            startisoindex = startiso20140206[i]
            endisoindex = endiso20140206[i]
        if filepath == "/Users/frio/GoogleDrive/"+corename+"/raw_dictionaries/rawHIDS2038-20140331-000029Z-DataLog_User.dat":
            startiso20140331 = [55885,63629,76673]
            endiso20140331 = [63034,75959,85506]
            startisoindex = startiso20140331[i]
            endisoindex = endiso20140331[i]
        if filepath == "/Users/frio/GoogleDrive/"+corename+"/raw_dictionaries/rawHIDS2038-20140401-000012Z-DataLog_User.dat":
            startiso20140401 = [46162,50536,62863,77638]
            endiso20140401 = [49936,62255,75369,83455]
            startisoindex = startiso20140401[i]
            endisoindex = endiso20140401[i]
        if filepath == "/Users/frio/GoogleDrive/"+corename+"/raw_dictionaries/rawHIDS2038-20140415-000009Z-DataLog_User_rep.dat":
            startiso20140415 = [56230,63757,73773,78166,85071]
            endiso20140415 = [63114,72519,77601,84501,88017]
            startisoindex = startiso20140415[i]
            endisoindex = endiso20140415[i]
        if filepath == "/Users/frio/GoogleDrive/"+corename+"/raw_dictionaries/rawHIDS2038-20140514-000007Z-DataLog_User_rep.dat":
            startiso20140514 = [43918,54686]
            endiso20140514 = [54170,65004]
            startisoindex = startiso20140514[i]
            endisoindex = endiso20140514[i]
            
        #### Special Cases for SPIceCore        
        if filepath == "/Users/frio/GoogleDrive/SPIceCoreData/raw_dictionaries/rawHIDS2148-20150626-000006Z-DataLog_User.dat":
            startiso = [51125,65935,78287]
            endiso = [65308,76724,82495]
            startisoindex = startiso[i]
            endisoindex = endiso[i]
        if filepath == "/Users/frio/GoogleDrive/SPIceCoreData/raw_dictionaries/rawHIDS2148-20150727-031939Z-DataLog_User.dat":
            startiso = [62324,73070,82228,95138,97879]
            endiso = [70178,81598,94545,96016,107993]
            startisoindex = startiso[i]
            endisoindex = endiso[i]
        if filepath == "/Users/frio/GoogleDrive/SPIceCoreData/raw_dictionaries/rawHIDS2148-20150813-000007Z-DataLog_User.dat":
            print "IN EXCEPTION LOOP!"
            startiso = [57320,71527,85220]
            endiso = [70418,84378,99257]
            startisoindex = startiso[i]
            endisoindex = endiso[i]
        if filepath == "/Users/frio/GoogleDrive/SPIceCoreData/raw_dictionaries/rawHIDS2148-20150901-000005Z-DataLog_User.dat":
            print "IN EXCEPTION LOOP!"
            startiso = [78501,87508,99971]
            endiso = [86888,99309,111863]
            startisoindex = startiso[i]
            endisoindex = endiso[i]
        if filepath == "/Users/frio/GoogleDrive/SPIceCoreData/raw_dictionaries/rawHIDS2148-20150910-000006Z-DataLog_User.dat":
            print "IN EXCEPTION LOOP!"
            startiso = [77170,95287]
            endiso = [94633,111918]
            startisoindex = startiso[i]
            endisoindex = endiso[i]
        if filepath == "/Users/frio/GoogleDrive/SPIceCoreData/raw_dictionaries/rawHIDS2148-20150915-000005Z-DataLog_User.dat":
            startiso = [78168,95655]
            endiso = [95067,112898]
            startisoindex = startiso[i]
            endisoindex = endiso[i]
        if filepath == "/Users/frio/GoogleDrive/SPIceCoreData/raw_dictionaries/rawHIDS2148-20150917-000006Z-DataLog_User.dat":
            print "IN EXCEPTION LOOP!"
            startiso = [49190,63467]
            endiso = [62736,80803]
            startisoindex = startiso[i]
            endisoindex = endiso[i]
        if filepath == "/Users/frio/GoogleDrive/SPIceCoreData/raw_dictionaries/rawHIDS2148-20150923-000006Z-DataLog_User.dat":
            startiso = [50219,67115]
            endiso = [66449,80613]
            startisoindex = startiso[i]
            endisoindex = endiso[i]
        if filepath == "/Users/frio/GoogleDrive/SPIceCoreData/raw_dictionaries/rawHIDS2148-20150926-011312Z-DataLog_User.dat":
            startiso = [67138,81885]
            endiso = [81064,98138]
            startisoindex = startiso[i]
            endisoindex = endiso[i]
        
        #### Memory application of nea curve to each ice core only when push ice was used inbetween ice cores, valco correction already applied
        if data_dict["epoch"][0]>=1364947200:
            previousvalued18o = np.mean(corrd18o[startisoindex-350:startisoindex-250])
            previousvaluedD = np.mean(corrdD[startisoindex-350:startisoindex-250])
            for z in data_dict["index"][startisoindex:startisoindex+250]:
                memcorrd18o[z] = (corrd18o[z]-previousvalued18o*(1-smavenead18o[z-startisoindex+250]))/(smavenead18o[z-startisoindex+250])
                data_dict["flag4"][z] = 'n'
            for z in data_dict["index"][startisoindex:startisoindex+250]:
                memcorrdD[z] = (corrdD[z]-previousvaluedD*(1-smaveneadD[z-startisoindex+250]))/(smaveneadD[z-startisoindex+250])
                data_dict["flag4"][z] = 'n'
        memcorrdexcess = memcorrdD-8*memcorrd18o
            
        ##### DEPTH, FILTER OUT OUTLIERS AND LASER ERRORS, STILL MAY NEED SOME MANUAL EDITING OF RAW FILE TO MAKE WORK DEPENDING ON ERRORS
        laserep = data_dict["epoch"][startmelt:endmelt]               #epoch time of melt
        isoep = data_dict["epoch"][startisoindex:endisoindex]         #epoch time of isotopes
        coreindex = data_dict["index"][startmelt:endmelt]             #index of core depth
        meltindex = np.arange(len(coreindex))
        coredepth = data_dict["true_depth"][startmelt:endmelt]          #core depth
        coreflag1 = data_dict["flag1"][startmelt:endmelt]
        coreflag2 = data_dict["flag2"][startmelt:endmelt]
        coreflag3 = data_dict["flag3"][startmelt:endmelt]
        coreflag4 = data_dict["flag4"][startmelt:endmelt]

        ##### PASS One OF FILTER 0.04M below fitted line
        if verbose ==1:
            print "4th order polynomial"
        fpolyfit1 = np.polyfit(coreindex, coredepth, 4)
        newpolydepth = np.polyval(fpolyfit1, coreindex)
        depthresiduals = coredepth-newpolydepth                           #residuals of fit 
        depthkeepers = np.where(depthresiduals>=-0.04)[0]            #keep values where residuals are great than -0.02m
        depthkeeperindex = np.arange(len(depthkeepers))
        for n in depthkeeperindex[1:]:
            diff = depthkeepers[n]-depthkeepers[n-1]
            if (diff)>1:
                startfixindex = depthkeepers[n-1]
                endfixindex = depthkeepers[n]
                fixerindex = np.arange(startfixindex,endfixindex)
                startfixdepth = coredepth[startfixindex]
                endfixdepth = coredepth[endfixindex]
                x = [startfixindex,endfixindex]
                y = [startfixdepth,endfixdepth]
                interpdepth = interp1d(x, y)
                fixdepth = interpdepth(fixerindex)
                loopindex = np.arange(len(fixdepth))
                for l in loopindex:
                    coredepth[depthkeepers[n-1]+l] = fixdepth[l]
                    coreflag4[depthkeepers[n-1]+l] = coreflag4[depthkeepers[n-1]+l]+'d'
        
        ##### PASS One OF FILTER 0.025M below fitted line
        if verbose ==1:
            print "5th order polynomial"
        fpolyfit1 = np.polyfit(coreindex, coredepth, 5)
        newpolydepth = np.polyval(fpolyfit1, coreindex)
        depthresiduals = coredepth-newpolydepth                           #residuals of fit 
        depthkeepers = np.where(depthresiduals>=-0.025)[0]            #keep values where residuals are great than -0.02m
        depthkeeperindex = np.arange(len(depthkeepers))
        for n in depthkeeperindex[1:]:
            diff = depthkeepers[n]-depthkeepers[n-1]
            if (diff)>1:
                startfixindex = depthkeepers[n-1]
                endfixindex = depthkeepers[n]
                fixerindex = np.arange(startfixindex,endfixindex)
                startfixdepth = coredepth[startfixindex]
                endfixdepth = coredepth[endfixindex]
                x = [startfixindex,endfixindex]
                y = [startfixdepth,endfixdepth]
                interpdepth = interp1d(x, y)
                fixdepth = interpdepth(fixerindex)
                loopindex = np.arange(len(fixdepth))
                for l in loopindex:
                    coredepth[depthkeepers[n-1]+l] = fixdepth[l]
                    coreflag4[depthkeepers[n-1]+l] = coreflag4[depthkeepers[n-1]+l]+'d'

        ##### PASS One OF FILTER 0.015M below fitted line
        if verbose ==1:
            print "6th order polynomial"
        fpolyfit1 = np.polyfit(coreindex, coredepth, 6)
        newpolydepth = np.polyval(fpolyfit1, coreindex)
        depthresiduals = coredepth-newpolydepth                           #residuals of fit 
        depthkeepers = np.where(depthresiduals>=-0.015)[0]            #keep values where residuals are great than -0.02m
        depthkeeperindex = np.arange(len(depthkeepers))
        for n in depthkeeperindex[1:]:
            diff = depthkeepers[n]-depthkeepers[n-1]
            if (diff)>1:
                startfixindex = depthkeepers[n-1]
                endfixindex = depthkeepers[n]
                fixerindex = np.arange(startfixindex,endfixindex)
                startfixdepth = coredepth[startfixindex]
                endfixdepth = coredepth[endfixindex]
                x = [startfixindex,endfixindex]
                y = [startfixdepth,endfixdepth]
                interpdepth = interp1d(x, y)
                fixdepth = interpdepth(fixerindex)
                loopindex = np.arange(len(fixdepth))
                for l in loopindex:
                    coredepth[depthkeepers[n-1]+l] = fixdepth[l]
                    coreflag4[depthkeepers[n-1]+l] = coreflag4[depthkeepers[n-1]+l]+'d'

        ##### PASS One OF FILTER 0.005M below fitted line
        if verbose ==1:
            print "6th order polynomial"
        fpolyfit1 = np.polyfit(coreindex, coredepth, 6)
        newpolydepth = np.polyval(fpolyfit1, coreindex)
        depthresiduals = coredepth-newpolydepth                           #residuals of fit 
        depthkeepers = np.where(depthresiduals>=-0.005)[0]            #keep values where residuals are great than -0.02m
        depthkeeperindex = np.arange(len(depthkeepers))
        for n in depthkeeperindex[1:]:
            diff = depthkeepers[n]-depthkeepers[n-1]
            if (diff)>1:
                startfixindex = depthkeepers[n-1]
                endfixindex = depthkeepers[n]
                fixerindex = np.arange(startfixindex,endfixindex)
                startfixdepth = coredepth[startfixindex]
                endfixdepth = coredepth[endfixindex]
                x = [startfixindex,endfixindex]
                y = [startfixdepth,endfixdepth]
                interpdepth = interp1d(x, y)
                fixdepth = interpdepth(fixerindex)
                loopindex = np.arange(len(fixdepth))
                for l in loopindex:
                    coredepth[depthkeepers[n-1]+l] = fixdepth[l]
                    coreflag4[depthkeepers[n-1]+l] = coreflag4[depthkeepers[n-1]+l]+'d'
        
        ##### PASS Two OF FILTER 0.015M above fitted line
        fpolyfit1 = np.polyfit(coreindex, coredepth, 6)
        newpolydepth = np.polyval(fpolyfit1, coreindex)
        depthresiduals = coredepth-newpolydepth                          
        depthkeepers = np.where(depthresiduals<=0.015)[0]           
        depthkeeperindex = np.arange(len(depthkeepers))
        for n in depthkeeperindex[1:]:
            diff = depthkeepers[n]-depthkeepers[n-1]
            if (diff)>1:
                startfixindex = depthkeepers[n-1]
                endfixindex = depthkeepers[n]
                fixerindex = np.arange(startfixindex,endfixindex)
                startfixdepth = coredepth[startfixindex]
                endfixdepth = coredepth[endfixindex]
                x = [startfixindex,endfixindex]
                y = [startfixdepth,endfixdepth]
                interpdepth = interp1d(x, y)
                fixdepth = interpdepth(fixerindex)
                loopindex = np.arange(len(fixdepth))
                for l in loopindex:
                    coredepth[depthkeepers[n-1]+l] = fixdepth[l]
                    coreflag4[depthkeepers[n-1]+l] = coreflag4[depthkeepers[n-1]+l]+'d'

        
        fig22_ax2.plot(coreindex, coredepth, "k-")
        
        ##### EC
        startec = np.max(diff_ec[startmelt:endmelt])
        startecindex = [x for x in data_dict["index"][startmelt:endmelt] if diff_ec[x]==startec]
        startecindex = startecindex[0]
        
        ##### VIAL
        startvial = np.floor(data_dict["vial_num"][beginmelt[i]])                     #NOT APPLICABLE FOR AFTER STARTING CONTINUOUS MELTING... NEED TO REFIGURE OUT VIAL ASSIGNMENT WITH NEA AND PUSH WATERS INCLUDED
        if endisoindex+200 >= data_dict["index"][-1]:
            endvial = np.floor(data_dict["vial_num"][data_dict["index"][-1]]) #put in for cut files that had binary shifts half way through the day
        else:
             endvial = np.floor(data_dict["vial_num"][endisoindex+200])
        vialslope = (endvial-startvial)/(endisoindex-startisoindex)
        
        ##### COLLECT AND WRITE DATA TO MELER DATA FILE ############################
        coreindex = np.arange(len(core))
        if data_dict["epoch"][0] < 1325376000:                                                #### 1102
            for j in coreindex[:]:                                                        ### AUTOTRIM - was first 10 and last 5 of each melt, now first 30 and last 5
                ice_dict["filepath"] = np.hstack([ice_dict["filepath"],filepath])
                ice_dict["time"] = np.hstack([ice_dict["time"],data_dict["j_days"][startisoindex + j]])
                ice_dict["d18o"] = np.hstack([ice_dict["d18o"],memcorrd18o[startisoindex + j]])
                ice_dict["rawd18o"] = np.hstack([ice_dict["rawd18o"],data_dict["d18o"][startisoindex + j]])
                ice_dict["dD"] = np.hstack([ice_dict["dD"],memcorrdD[startisoindex + j]])
                ice_dict["rawdD"] = np.hstack([ice_dict["rawdD"],data_dict["dD"][startisoindex + j]])
                ice_dict["d_excess"] = np.hstack([ice_dict["d_excess"],memcorrdD[startisoindex + j]-8*memcorrd18o[startisoindex + j]])     
                ice_dict["water"] = np.hstack([ice_dict["water"],data_dict["water_ppm"][startisoindex + j]])
                if startecindex+coreindex[-1] >= data_dict["index"][-1]:
                    ice_dict["ec"] = np.hstack([ice_dict["ec"],data_dict["ec_value"][startecindex]]) #put in for cut files that had binary shifts half way through the day
                else:    
                    ice_dict["ec"] = np.hstack([ice_dict["ec"],data_dict["ec_value"][startecindex + j]])
                if filepath == "/Users/frio/GoogleDrive/"+corename+"/raw_dictionaries/rawHBDS92-20111130-0940-Data.dat" or \
                        filepath == "/Users/frio/GoogleDrive/"+corename+"/raw_dictionaries/rawHBDS92-20111201-1256-Data.dat" or \
                            filepath == "/Users/frio/GoogleDrive/"+corename+"/raw_dictionaries/rawHBDS92-20111202-0914-Data.dat" or \
                                filepath == "/Users/frio/GoogleDrive/"+corename+"/raw_dictionaries/rawHBDS92-20111206-0918-Data.dat" or \
                                    filepath == "/Users/frio/GoogleDrive/"+corename+"/raw_dictionaries/rawHBDS92-20111207-0941-Data.dat" or \
                                        filepath == "/Users/frio/GoogleDrive/"+corename+"/raw_dictionaries/rawHBDS92-20111208-0907-Data.dat":
                    startdepthdata = startdepth[i]
                    enddepthdata = enddepth[i]
                    depthslope = (enddepthdata-startdepthdata)/(endmelt-startmelt)
                    if j == 35:
                        print "INTERPOLATED DEPTH, INDEX, START, END, SLOPE:", i, startdepthdata, enddepthdata, depthslope
                    ice_dict["depth"] = np.hstack([ice_dict["depth"],startdepthdata + depthslope*j])
                    coreflag4[j] = coreflag4[j]+'D'
                else:
                    ice_dict["depth"] = np.hstack([ice_dict["depth"],coredepth[j]])                       ###laserdepth[j]])                  
                ice_dict["meltrate"] = np.hstack([ice_dict["meltrate"],meltrate[startisoindex + j]])
                ice_dict["vial"] = np.hstack([ice_dict["vial"],startvial + np.floor(j*vialslope) - 1]) 
                ice_dict["flag1"] = np.hstack([ice_dict["flag1"],coreflag1[j]])
                ice_dict["flag2"] = np.hstack([ice_dict["flag2"],coreflag2[j]])
                ice_dict["flag3"] = np.hstack([ice_dict["flag3"],coreflag3[j]])
                ice_dict["flag4"] = np.hstack([ice_dict["flag4"],coreflag4[j]])
                ice_dict["flag5"] = np.hstack([ice_dict["flag5"],data_dict["flag5"][0]])
                ice_dict["flag6"] = np.hstack([ice_dict["flag6"],data_dict["flag6"][0]])
                if j <= 3:
                    ice_dict["flag2"][-1] = ice_dict["flag2"][-1]+'p1'
                if j <= 6:
                    ice_dict["flag2"][-1] = ice_dict["flag2"][-1]+'p2'
                if j <= 9:
                    ice_dict["flag2"][-1] = ice_dict["flag2"][-1]+'p3'
                if j <= 12:
                    ice_dict["flag2"][-1] = ice_dict["flag2"][-1]+'p4'
                if j <= 15:
                    ice_dict["flag2"][-1] = ice_dict["flag2"][-1]+'p5'
                if j <= 18:
                    ice_dict["flag2"][-1] = ice_dict["flag2"][-1]+'p6'
                if j <= 21:
                    ice_dict["flag2"][-1] = ice_dict["flag2"][-1]+'p7'
                if j <= 24:
                    ice_dict["flag2"][-1] = ice_dict["flag2"][-1]+'p8'
                if j <= 27:
                    ice_dict["flag2"][-1] = ice_dict["flag2"][-1]+'p9'
                if j <= 30:
                    ice_dict["flag2"][-1] = ice_dict["flag2"][-1]+'p0'
                if j >= coreindex[-1]-5:
                    ice_dict["flag2"][-1] = ice_dict["flag2"][-1]+'p'
                now = datetime.date.today()
                ice_dict["ave_valco_normsigma_d18o"] = np.hstack([ice_dict["ave_valco_normsigma_d18o"],ave_valco_normsigma_d18o])
                ice_dict["ave_valco_normsigma_dD"] = np.hstack([ice_dict["ave_valco_normsigma_dD"],ave_valco_normsigma_dD])
                ice_dict["ave_valco_skewsigma_d18o"] = np.hstack([ice_dict["ave_valco_skewsigma_d18o"],ave_valco_skewsigma_d18o])
                ice_dict["ave_valco_skewsigma_dD"] = np.hstack([ice_dict["ave_valco_skewsigma_dD"],ave_valco_skewsigma_dD])
                ice_dict["ave_nea_normsigma_d18o"] = np.hstack([ice_dict["ave_nea_normsigma_d18o"],ave_nea_normsigma_d18o])
                ice_dict["ave_nea_normsigma_dD"] = np.hstack([ice_dict["ave_nea_normsigma_dD"],ave_nea_normsigma_dD])
                ice_dict["ave_nea_skewsigma_d18o"] = np.hstack([ice_dict["ave_nea_skewsigma_d18o"],ave_nea_skewsigma_d18o])
                ice_dict["ave_nea_skewsigma_dD"] = np.hstack([ice_dict["ave_nea_skewsigma_dD"],ave_nea_skewsigma_dD])
                ice_dict["prodate"] = np.hstack([ice_dict["prodate"],now.strftime("%Y%m%d")])
                ice_dict["crunchversion"] = np.hstack([ice_dict["crunchversion"],crunchversion])
                
        if data_dict["epoch"][0] > 1325376000:                                                  #### 2130       
            for j in coreindex[:]:                                                        ### AUTOTRIM - was first 35 and last 25 of each melt, now first 100 and last 25
                ice_dict["filepath"] = np.hstack([ice_dict["filepath"],filepath])
                ice_dict["time"] = np.hstack([ice_dict["time"],data_dict["j_days"][startisoindex + j]])
                ice_dict["d18o"] = np.hstack([ice_dict["d18o"],memcorrd18o[startisoindex + j]])
                ice_dict["rawd18o"] = np.hstack([ice_dict["rawd18o"],data_dict["d18o"][startisoindex + j]])
                ice_dict["dD"] = np.hstack([ice_dict["dD"],memcorrdD[startisoindex + j]])
                ice_dict["rawdD"] = np.hstack([ice_dict["rawdD"],data_dict["dD"][startisoindex + j]])
                ice_dict["d_excess"] = np.hstack([ice_dict["d_excess"],memcorrdD[startisoindex + j]-8*memcorrd18o[startisoindex + j]])   
                ice_dict["water"] = np.hstack([ice_dict["water"],data_dict["water_ppm"][startisoindex + j]])
                if startecindex+coreindex[-1] >= data_dict["index"][-1]:
                    ice_dict["ec"] = np.hstack([ice_dict["ec"],data_dict["ec_value"][startecindex]]) #put in for cut files that had binary shifts half way through the day
                else:    
                    ice_dict["ec"] = np.hstack([ice_dict["ec"],data_dict["ec_value"][startecindex + j]])
                if filepath == "/Users/frio/GoogleDrive/"+corename+"/raw_dictionaries/rawHIDS2038-20120213-175121Z-DataLog_User.dat" or \
                    filepath == "/Users/frio/GoogleDrive/"+corename+"/raw_dictionaries/rawHIDS2038-20120215-All-DataLog_User" or \
                        filepath == "/Users/frio/GoogleDrive/"+corename+"/raw_dictionaries/rawHIDS2038-20120217-All-DataLog_User" or \
                            filepath == "/Users/frio/GoogleDrive/WAIS06AData/raw_dictionaries/rawHIDS2038-20120718-093352Z-DataLog_User.dat" or \
                                filepath == "/Users/frio/GoogleDrive/"+corename+"/raw_dictionaries/rawHIDS2038-20120720-095623Z-DataLog_User.dat" or \
                                    filepath == "/Users/frio/GoogleDrive/"+corename+"/raw_dictionaries/rawHIDS2038-20120723-101021Z-DataLog_User.dat" or \
                                        filepath == "/Users/frio/GoogleDrive/"+corename+"/raw_dictionaries/rawHIDS2038-20120724-104457Z-DataLog_User.dat" or \
                                            filepath == "/Users/frio/GoogleDrive/"+corename+"/raw_dictionaries/rawHIDS2038-20120726-115605Z-DataLog_User.dat" or \
                                                filepath == "/Users/frio/GoogleDrive/"+corename+"/raw_dictionaries/rawHIDS2038-20120727-100805Z-DataLog_User.dat" or \
                                                    filepath == "/Users/frio/GoogleDrive/"+corename+"/raw_dictionaries/rawHIDS2038-20121219-000007Z-DataLog_User.dat" or \
                                                        filepath == "/Users/frio/GoogleDrive/"+corename+"/raw_dictionaries/rawHIDS2038-20121220-000008Z-DataLog_User.dat" or \
                                                            filepath == "/Users/frio/GoogleDrive/"+corename+"/raw_dictionaries/rawHIDS2038-20121221-032412Z-DataLog_User.dat":
                    startdepthdata = startdepth[i]
                    enddepthdata = enddepth[i]
                    depthslope = (enddepthdata-startdepthdata)/(endmelt-startmelt)
                    if j == 35:
                        print "INTERPOLATED DEPTH, INDEX, START, END, SLOPE:", i, startdepthdata, enddepthdata, depthslope
                    ice_dict["depth"] = np.hstack([ice_dict["depth"],startdepthdata + depthslope*j])
                    coreflag4[j] = coreflag4[j]+'D'
                else:
                    ice_dict["depth"] = np.hstack([ice_dict["depth"],coredepth[j]])                       ###laserdepth[j]])                  
                ice_dict["meltrate"] = np.hstack([ice_dict["meltrate"],meltrate[startisoindex + j]])
                ice_dict["vial"] = np.hstack([ice_dict["vial"],startvial + np.floor(j*vialslope) - 1])
                ice_dict["flag1"] = np.hstack([ice_dict["flag1"],coreflag1[j]])
                ice_dict["flag2"] = np.hstack([ice_dict["flag2"],coreflag2[j]])
                ice_dict["flag3"] = np.hstack([ice_dict["flag3"],coreflag3[j]])
                ice_dict["flag4"] = np.hstack([ice_dict["flag4"],coreflag4[j]])
                ice_dict["flag5"] = np.hstack([ice_dict["flag5"],data_dict["flag5"][0]])
                ice_dict["flag6"] = np.hstack([ice_dict["flag6"],data_dict["flag6"][0]])
                if j <= 10:
                    ice_dict["flag2"][-1] = ice_dict["flag2"][-1]+'p1'
                if j <= 20:
                    ice_dict["flag2"][-1] = ice_dict["flag2"][-1]+'p2'
                if j <= 30:
                    ice_dict["flag2"][-1] = ice_dict["flag2"][-1]+'p3'
                if j <= 40:
                    ice_dict["flag2"][-1] = ice_dict["flag2"][-1]+'p4'
                if j <= 50:
                    ice_dict["flag2"][-1] = ice_dict["flag2"][-1]+'p5'
                if j <= 60:
                    ice_dict["flag2"][-1] = ice_dict["flag2"][-1]+'p6'
                if j <= 70:
                    ice_dict["flag2"][-1] = ice_dict["flag2"][-1]+'p7'
                if j <= 80:
                    ice_dict["flag2"][-1] = ice_dict["flag2"][-1]+'p8'
                if j <= 90:
                    ice_dict["flag2"][-1] = ice_dict["flag2"][-1]+'p9'
                if j <= 100:
                    ice_dict["flag2"][-1] = ice_dict["flag2"][-1]+'p0'
                if j >= coreindex[-1]-25:
                    ice_dict["flag2"][-1] = ice_dict["flag2"][-1]+'p'
                now = datetime.date.today()
                ice_dict["ave_valco_normsigma_d18o"] = np.hstack([ice_dict["ave_valco_normsigma_d18o"],ave_valco_normsigma_d18o])
                ice_dict["ave_valco_normsigma_dD"] = np.hstack([ice_dict["ave_valco_normsigma_dD"],ave_valco_normsigma_dD])
                ice_dict["ave_valco_skewsigma_d18o"] = np.hstack([ice_dict["ave_valco_skewsigma_d18o"],ave_valco_skewsigma_d18o])
                ice_dict["ave_valco_skewsigma_dD"] = np.hstack([ice_dict["ave_valco_skewsigma_dD"],ave_valco_skewsigma_dD])
                ice_dict["ave_nea_normsigma_d18o"] = np.hstack([ice_dict["ave_nea_normsigma_d18o"],ave_nea_normsigma_d18o])
                ice_dict["ave_nea_normsigma_dD"] = np.hstack([ice_dict["ave_nea_normsigma_dD"],ave_nea_normsigma_dD])
                ice_dict["ave_nea_skewsigma_d18o"] = np.hstack([ice_dict["ave_nea_skewsigma_d18o"],ave_nea_skewsigma_d18o])
                ice_dict["ave_nea_skewsigma_dD"] = np.hstack([ice_dict["ave_nea_skewsigma_dD"],ave_nea_skewsigma_dD])
                ice_dict["prodate"] = np.hstack([ice_dict["prodate"],now.strftime("%Y%m%d")])
                ice_dict["crunchversion"] = np.hstack([ice_dict["crunchversion"],crunchversion])
        
        # get melt rate from smoothed time and depth data, and put smoothed data into end file
        depth_cm = ice_dict["depth"]*100  # depth in meters*100 = depth in cm
        smooth_depth = smooth(depth_cm)
        minutes = ice_dict["time"]/60  # time in sec/60 = time in minutes
        smooth_time =smooth(minutes)
        diff_depth = np.diff(smooth_depth)
        diff_time = np.diff(smooth_time)
        ice_dict["meltrate"] = diff_depth/diff_time
        smooth_meltrate = smooth(meltrate)
        diffdepthindex = nonzero_index_true_depth[:-1]    
            
        ##### Save data step #######################################################
        
        ## Write ice data dictionary to file for storage and prunning
        icedataout_file = "/Users/frio/GoogleDrive/"+corename+"/ice_dictionaries/ice" + filename
        file = open(icedataout_file, "w")                                                    # create bininary file to write to
        pickle.dump(ice_dict, file)                                                      # write dictionary (a) to file (f)
        file.close()
    
    #### plot memory corrected values onto original graph
    fig21_ax1.plot(data_dict["index"], memcorrd18o, "y-")
    fig21_ax2.plot(data_dict["index"], memcorrdD, "y-")
    fig21_ax3.plot(data_dict["index"], memcorrdexcess, "m-")  
            
    ##### READ IN ICE DATA FILE FROM MELTER FOR QA/QC AND PRUNNING #######################################

    icedata = open(icedataout_file, "r")                                   # open bininary file to read
    icedata_dict = pickle.load(icedata) 
    icedata_dict["index"] = np.arange(len(icedata_dict["d18o"]))
    flagfilter = [x for x in icedata_dict["index"] if icedata_dict["flag1"][x]=="." and icedata_dict["flag2"][x]=="."]

    fig321 = plt.figure(321)
    clear = plt.clf()
    fig321_ax1 = fig321.add_subplot(411)
    fig321_ax1.plot(icedata_dict["index"], icedata_dict["d18o"], "g-",icedata_dict["index"][flagfilter], icedata_dict["d18o"][flagfilter], "b-")
    fig321_ax1.axis([0,icedata_dict["index"][-1],-50,-25])
    fig321_ax1.set_ylabel("d18o")
    fig321_ax2 = fig321.add_subplot(412)
    fig321_ax2.plot(icedata_dict["index"], icedata_dict["dD"], "m-", icedata_dict["index"][flagfilter], icedata_dict["dD"][flagfilter], "r-")
    fig321_ax2.axis([0,icedata_dict["index"][-1],-400,-150])
    fig321_ax2.set_ylabel("dD")
    fig321_ax3 = fig321.add_subplot(413)
    fig321_ax3.plot(icedata_dict["index"], icedata_dict["depth"], "k-", icedata_dict["index"][flagfilter], icedata_dict["depth"][flagfilter], "g-")
    fig321_ax3.set_ylabel("depth")
    fig321_ax4 = fig321.add_subplot(414)
    fig321_ax4.plot(icedata_dict["index"], icedata_dict["d_excess"], "g-", icedata_dict["index"][flagfilter], icedata_dict["d_excess"][flagfilter], "k-")
    fig321_ax4.axis([0,icedata_dict["index"][-1],-15,15])
    fig321_ax4.set_ylabel("d-excess")
    fig321_ax4.set_xlabel("Index")
    fig321_ax1.set_title("%s" %(os.path.splitext(filepath)[0]))

    smoothicedD = smooth(icedata_dict["dD"])
    difficedD = np.diff(smoothicedD)
    maxdifficedD = np.where(difficedD>=5)[0]
    corenum = np.arange(len(maxdifficedD))
    
#    #### Manual Flags, to be applied to WAIS as a concatenated file, left here for SPIce    
#    if verbose == 0:     #For crunching individual files and pruning by indices #### Can change to 0 FOR PROBLEM FILES through batch crunch
#        startpflag = input("Please input start indices for data to be flagged for TAILS IN OR OUT of unknown reasons, in [ ], for p flag") 
#        endpflag = input("Please input end indices for data to be flagged for TAILS IN OR OUT of unknown reasons, in [ ], for p flag") 
#        if len(startpflag) >= 1:
#            flagindex = np.arange(len(startpflag))
#            for f in flagindex:
#                findex = np.arange(startpflag[f],endpflag[f])
#                for l in findex:
#                    icedata_dict["flag3"][l] = icedata_dict["flag3"][l]+'p'
#        startsflag = input("Please input start indices for data to be flagged for SPIKES of unknown reasons, in [ ], for s flag") 
#        endsflag = input("Please input end indices for data to be flagged for SPIKES of unknown reasons, in [ ], for s flag") 
#        if len(startsflag) >= 1:
#            flagindex = np.arange(len(startsflag))
#            for f in flagindex:
#                findex = np.arange(startsflag[f],endsflag[f])
#                for l in findex:
#                    icedata_dict["flag3"][l] = icedata_dict["flag3"][l]+'s'
#        startnflag = input("Please input start indices for data to be flagged for NOISE of unknown reasons, in [ ], for n flag") 
#        endnflag = input("Please input end indices for data to be flagged for NOISE of unknown reasons, in [ ], for n flag") 
#        if len(startnflag) >= 1:
#            flagindex = np.arange(len(startnflag))
#            for f in flagindex:
#                findex = np.arange(startnflag[f],endnflag[f])
#                for l in findex:
#                    icedata_dict["flag3"][l] = icedata_dict["flag3"][l]+'n'
#        startoflag = input("Please input start indices for data to be flagged for OUTLIERS of unknown reasons, in [ ], for o flag") 
#        endoflag = input("Please input end indices for data to be flagged for OUTLIERS of unknown reasons, in [ ], for o flag") 
#        if len(startoflag) >= 1:
#            flagindex = np.arange(len(startoflag))
#            for f in flagindex:
#                findex = np.arange(startoflag[f],endoflag[f])
#                for l in findex:
#                    icedata_dict["flag3"][l] = icedata_dict["flag3"][l]+'o'
#        startvflag = input("Please input start indices for data to be flagged for VALCO reasons, in [ ], for v flag") 
#        endvflag = input("Please input end indices for data to be flagged for VALCO reasons, in [ ], for v flag") 
#        if len(startvflag) >= 1:
#            flagindex = np.arange(len(startvflag))
#            for f in flagindex:
#                findex = np.arange(startvflag[f],endvflag[f])
#                for l in findex:
#                    icedata_dict["flag3"][l] = icedata_dict["flag3"][l]+'v'
#        startfflag = input("Please input start indices for data to be flagged for FILTER CHANGE reasons, in [ ], for f flag") 
#        endfflag = input("Please input end indices for data to be flagged for FILTER CHANGE reasons, in [ ], for f flag") 
#        if len(startfflag) >= 1:
#            flagindex = np.arange(len(startfflag))
#            for f in flagindex:
#                findex = np.arange(startfflag[f],endfflag[f])
#                for l in findex:
#                    icedata_dict["flag3"][l] = icedata_dict["flag3"][l]+'f'
#    for a in icedata_dict["flag3"][:]:
#        print a
        
    
    ##### WRITE ALL STATS TO PERFORMANCE FILE AND SET All Analytical Flags ######################################
    #Allan - 10, 600, 3600 of d18o and dD
    #Valco - Memory?, raw std values
    #Drift - mean and stddev of d18o and dD
    #Scaling - slope and intercept, mean, stdev, and diff of each standard
    #Nea - ?? from transfer, Delays 
    iceindex = np.arange(len(ice_dict["d18o"]))
    dataout_file = "/Users/frio/GoogleDrive/"+corename+"/MelterPerformanceFile20160419"
    file = open(dataout_file, "a")
    if corename =="WAIS06AData":
        data = np.transpose(np.vstack((filename, amallanaved18o, amallanstdevd18o, amallan10secd18o, amallan60secd18o, \
            amallan600secd18o, amallan3600secd18o, amallanavedD, amallanstdevdD, amallan10secdD, \
                amallan60secdD, amallan600secdD, amallan3600secdD, amallanh2o, pmallanaved18o, \
                    pmallanstdevd18o, pmallan10secd18o, pmallan60secd18o, pmallan600secd18o, pmallan3600secd18o, \
                        pmallanavedD, pmallanstdevdD, pmallan10secdD, pmallan60secdD, pmallan600secdD, \
                            pmallan36000secdD, pmallanh2o, avedriftstdd18o, stdevdriftstdd18o, avedriftstddD, \
                                stdevdriftstddD, fullmelttime, d18oslope, d18ointercept, dDslope, \
                                    dDintercept, meankbwd18o, stdkbwd18o, diffkbwd18o, meankbwdD, \
                                        stdkbwdD, diffkbwdD, meankawd18o, stdkawd18o, diffkawd18o, \
                                            meankawdD, stdkawdD, diffkawdD, meankgwd18o, stdkgwd18o, \
                                                diffkgwd18o, meankgwdD, stdkgwdD, diffkgwdD, meankpwd18o, \
                                                    stdkpwd18o, diffkpwd18o, meankpwdD, stdkpwdD, diffkpwdD, \
                                                        ave_valco_skewsigma_d18o, ave_valco_normsigma_d18o, ave_valco_skewsigma_dD, ave_valco_normsigma_dD, ave_nea_skewsigma_d18o, \
                                                            ave_nea_normsigma_d18o, ave_nea_skewsigma_dD, ave_nea_normsigma_dD, ice_dict["prodate"][0], crunchversion)))
        # A flag - 1st position, if standards have a collective standard deviation or difference from know greater than 0.3 for or 3.0 for dD 
        # a flag - 4th position, if standards have a collective standard deviation or difference from know greater than 0.1 for d18O or 1.0 for dD (a1), or 0.2 and 2.0 (a2), 0.3 and 3.0 (a3)
        if stdkbwd18o > 0.1 or diffkbwd18o > 0.1 or stdkbwdD > 1.0 or diffkbwdD > 1.0 or \
            stdkawd18o > 0.1 or diffkawd18o > 0.1 or stdkawdD > 1.0 or diffkawdD > 1.0 or \
                stdkpwd18o > 0.1 or diffkpwd18o > 0.1 or stdkpwdD > 1.0 or diffkpwdD > 1.0:
                for i in iceindex:
                    ice_dict["flag4"][i] = ice_dict["flag4"][i] + 'a1'
        if stdkbwd18o > 0.2 or diffkbwd18o > 0.2 or stdkbwdD > 2.0 or diffkbwdD > 2.0 or \
            stdkawd18o > 0.2 or diffkawd18o > 0.2 or stdkawdD > 2.0 or diffkawdD > 2.0 or \
                stdkpwd18o > 0.2 or diffkpwd18o > 0.2 or stdkpwdD > 2.0 or diffkpwdD > 2.0:
                for i in iceindex:
                    ice_dict["flag4"][i] = ice_dict["flag4"][i] + 'a2'
        if stdkbwd18o > 0.3 or diffkbwd18o > 0.3 or stdkbwdD > 3.0 or diffkbwdD > 3.0 or \
            stdkawd18o > 0.3 or diffkawd18o > 0.3 or stdkawdD > 3.0 or diffkawdD > 3.0 or \
                stdkpwd18o > 0.3 or diffkpwd18o > 0.3 or stdkpwdD > 3.0 or diffkpwdD > 3.0:
                for i in iceindex:
                    ice_dict["flag4"][i] = ice_dict["flag4"][i] + 'a3'
                    ice_dict["flag1"][i] = ice_dict["flag1"][i] + 'A'
        # T flag - 1st position, if trap standard has a collective standard deviation or difference from know greater than 0.3 for or 3.0 for dD
        # t flag - 4th position, if trap standard have a collective standard deviation or difference from know greater than 0.1 for d18O or 1.0 for dD (t1), or 0.2 and 2.0 (t2), 0.3 and 3.0 (t3)
        if stdkgwd18o > 0.1 or diffkgwd18o > 0.1 or stdkgwdD > 1.0 or diffkgwdD > 1.0:
            for i in iceindex:
                ice_dict["flag4"][i] = ice_dict["flag4"][i] + 't1'
        if stdkgwd18o > 0.2 or diffkgwd18o > 0.2 or stdkgwdD > 2.0 or diffkgwdD > 2.0:
            for i in iceindex:
                ice_dict["flag4"][i] = ice_dict["flag4"][i] + 't2'
        if stdkgwd18o > 0.3 or diffkgwd18o > 0.3 or stdkgwdD > 3.0 or diffkgwdD > 3.0:
            for i in iceindex:
                ice_dict["flag4"][i] = ice_dict["flag4"][i] + 't3'
                ice_dict["flag1"][i] = ice_dict["flag1"][i] + 'T'
            
    if corename == "SPIceCoreData":
        data = np.transpose(np.vstack((filename, amallanaved18o, amallanstdevd18o, amallan10secd18o, amallan60secd18o, \
            amallan600secd18o, amallan3600secd18o, amallanavedD, amallanstdevdD, amallan10secdD, \
                amallan60secdD, amallan600secdD, amallan3600secdD, amallanh2o, pmallanaved18o, \
                    pmallanstdevd18o, pmallan10secd18o, pmallan60secd18o, pmallan600secd18o, pmallan3600secd18o, \
                        pmallanavedD, pmallanstdevdD, pmallan10secdD, pmallan60secdD, pmallan600secdD, \
                            pmallan36000secdD, pmallanh2o, avedriftstdd18o, stdevdriftstdd18o, avedriftstddD, \
                                stdevdriftstddD, fullmelttime, d18oslope, d18ointercept, dDslope, \
                                    dDintercept, meankawd18o, stdkawd18o, diffkawd18o, meankawdD, \
                                        stdkawdD, diffkawdD, meankgwd18o, stdkgwd18o, diffkgwd18o, \
                                            meankgwdD, stdkgwdD, diffkgwdD, meankpwd18o, stdkpwd18o, \
                                                diffkpwd18o, meankpwdD, stdkpwdD, diffkpwdD, meanvw1fd18o, \
                                                    stdvw1fd18o, diffvw1fd18o, meanvw1fdD, stdvw1fdD, diffvw1fdD, \
                                                        ave_valco_skewsigma_d18o, ave_valco_normsigma_d18o, ave_valco_skewsigma_dD, ave_valco_normsigma_dD, ave_nea_skewsigma_d18o, \
                                                            ave_nea_normsigma_d18o, ave_nea_skewsigma_dD, ave_nea_normsigma_dD, ice_dict["prodate"][0], crunchversion)))
        # A flag - 1st position, if standards have a collective standard deviation or difference from know greater than 0.3 for or 3.0 for dD 
        # a flag - 4th position, if standards have a collective standard deviation or difference from know greater than 0.1 for d18O or 1.0 for dD (a1), or 0.2 and 2.0 (a2), 0.3 and 3.0 (a3)
        if stdkawd18o > 0.1 or diffkawd18o > 0.1 or stdkawdD > 1.0 or diffkawdD > 1.0 or \
            stdkgwd18o > 0.1 or diffkgwd18o > 0.1 or stdkgwdD > 1.0 or diffkgwdD > 1.0 or \
                stdvw1fd18o > 0.1 or diffvw1fd18o > 0.1 or stdvw1fdD > 1.0 or diffvw1fdD > 1.0:
                for i in iceindex:
                    ice_dict["flag4"][i] = ice_dict["flag4"][i] + 'a1'
        if stdkawd18o > 0.2 or diffkawd18o > 0.2 or stdkawdD > 2.0 or diffkawdD > 2.0 or \
            stdkgwd18o > 0.2 or diffkgwd18o > 0.2 or stdkgwdD > 2.0 or diffkgwdD > 2.0 or \
                stdvw1fd18o > 0.2 or diffvw1fd18o > 0.2 or stdvw1fdD > 2.0 or diffvw1fdD > 2.0:
                for i in iceindex:
                    ice_dict["flag4"][i] = ice_dict["flag4"][i] + 'a2'
        if stdkawd18o > 0.3 or diffkawd18o > 0.3 or stdkawdD > 3.0 or diffkawdD > 3.0 or \
            stdkgwd18o > 0.3 or diffkgwd18o > 0.3 or stdkgwdD > 3.0 or diffkgwdD > 3.0 or \
                stdvw1fd18o > 0.3 or diffvw1fd18o > 0.3 or stdvw1fdD > 3.0 or diffvw1fdD > 3.0:
                for i in iceindex:
                    ice_dict["flag4"][i] = ice_dict["flag4"][i] + 'a3'
        if stdkawd18o > 0.4 or diffkawd18o > 0.4 or stdkawdD > 4.0 or diffkawdD > 4.0 or \
            stdkgwd18o > 0.4 or diffkgwd18o > 0.4 or stdkgwdD > 4.0 or diffkgwdD > 4.0 or \
                stdvw1fd18o > 0.4 or diffvw1fd18o > 0.4 or stdvw1fdD > 4.0 or diffvw1fdD > 4.0:
                for i in iceindex:
                    ice_dict["flag1"][i] = ice_dict["flag1"][i] + 'A'
                
        # T flag - 1st position, if trap standard has a collective standard deviation or difference from know greater than 0.3 for or 3.0 for dD
        # t flag - 4th position, if trap standard have a collective standard deviation or difference from know greater than 0.1 for d18O or 1.0 for dD (t1), or 0.2 and 2.0 (t2), 0.3 and 3.0 (t3)
        if stdkpwd18o > 0.1 or diffkpwd18o > 0.1 or stdkpwdD > 1.0 or diffkpwdD > 1.0:
            for i in iceindex:
                ice_dict["flag4"][i] = ice_dict["flag4"][i] + 't1'
        if stdkpwd18o > 0.2 or diffkpwd18o > 0.2 or stdkpwdD > 2.0 or diffkpwdD > 2.0:
            for i in iceindex:
                ice_dict["flag4"][i] = ice_dict["flag4"][i] + 't2'
        if stdkpwd18o > 0.3 or diffkpwd18o > 0.3 or stdkpwdD > 3.0 or diffkpwdD > 3.0:
            for i in iceindex:
                ice_dict["flag4"][i] = ice_dict["flag4"][i] + 't3'
        if stdkpwd18o > 0.4 or diffkpwd18o > 0.4 or stdkpwdD > 4.0 or diffkpwdD > 4.0:
            for i in iceindex:
                ice_dict["flag1"][i] = ice_dict["flag1"][i] + 'T'
            
    np.savetxt(file, data, delimiter = "\t", fmt = ("%s", "%s", "%s", "%s", "%s", "%s", "%s", "%s", "%s", "%s", \
                "%s", "%s", "%s", "%s", "%s", "%s", "%s", "%s", "%s", "%s", \
                    "%s", "%s", "%s", "%s", "%s", "%s", "%s", "%s", "%s", "%s", \
                        "%s", "%s", "%s", "%s", "%s", "%s", "%s", "%s", "%s", "%s", \
                            "%s", "%s", "%s", "%s", "%s", "%s", "%s", "%s", "%s", "%s", \
                                "%s", "%s", "%s", "%s", "%s", "%s", "%s", "%s", "%s", "%s", \
                                    "%s", "%s", "%s", "%s", "%s", "%s", "%s", "%s", "%s", "%s"))
    file.close()
    
    # p flag - 4th position, if allan varience at __ seconds is greater than 0.1 for d18O or 1.0 for dD (p1), or 0.2 and 2.0 (p2), 0.3 and 3.0 (p3) 
    if amallanstdevd18o > 0.1 or amallan10secd18o > 0.1 or amallan60secd18o > 0.1 or amallan600secd18o > 0.1 or  amallan3600secd18o > 0.1 or \
        amallanstdevdD > 1.0 or amallan10secdD > 1.0 or amallan60secdD > 1.0 or amallan600secdD > 1.0 or amallan3600secdD > 1.0 or \
            pmallanstdevd18o > 0.1 or pmallan10secd18o > 0.1 or pmallan60secd18o > 0.1 or pmallan600secd18o > 0.1 or pmallan3600secd18o > 0.1 or \
                pmallanstdevdD > 1.0 or pmallan10secdD > 1.0 or pmallan60secdD > 1.0 or pmallan600secdD > 1.0 or pmallan36000secdD > 1.0:
                    for i in iceindex:
                        ice_dict["flag4"][i] = ice_dict["flag4"][i] +'p1'
    if amallanstdevd18o > 0.2 or amallan10secd18o > 0.2 or amallan60secd18o > 0.2 or amallan600secd18o > 0.2 or  amallan3600secd18o > 0.2 or \
        amallanstdevdD > 2.0 or amallan10secdD > 2.0 or amallan60secdD > 2.0 or amallan600secdD > 2.0 or amallan3600secdD > 2.0 or \
            pmallanstdevd18o > 0.2 or pmallan10secd18o > 0.2 or pmallan60secd18o > 0.2 or pmallan600secd18o > 0.2 or pmallan3600secd18o > 0.2 or \
                pmallanstdevdD > 2.0 or pmallan10secdD > 2.0 or pmallan60secdD > 2.0 or pmallan600secdD > 1.0 or pmallan36000secdD > 2.0:
                    for i in iceindex:
                        ice_dict["flag4"][i] = ice_dict["flag4"][i] + 'p2'
    if amallanstdevd18o > 0.3 or amallan10secd18o > 0.3 or amallan60secd18o > 0.3 or amallan600secd18o > 0.3 or  amallan3600secd18o > 0.3 or \
        amallanstdevdD > 3.0 or amallan10secdD > 3.0 or amallan60secdD > 3.0 or amallan600secdD > 3.0 or amallan3600secdD > 3.0 or \
            pmallanstdevd18o > 0.3 or pmallan10secd18o > 0.3 or pmallan60secd18o > 0.3 or pmallan600secd18o > 0.3 or pmallan3600secd18o > 0.3 or \
                pmallanstdevdD > 3.0 or pmallan10secdD > 3.0 or pmallan60secdD > 3.0 or pmallan600secdD > 3.0 or pmallan36000secdD > 3.0:
                    for i in iceindex:
                        ice_dict["flag4"][i] = ice_dict["flag4"][i] + 'p3'
#                        ice_dict["flag1"][i] = ice_dict["flag1"][i] + 'P'

    #### Write file with all Flags
    dataout_file = "/Users/frio/GoogleDrive/"+corename+"/trimmed_dictionaries/trimmed" + filename
    file = open(dataout_file, "w")                                                    # create bininary file to write to
    pickle.dump(ice_dict, file)                                                         # write dictionary (trimmed_data_dict) to file (file)
    file.close()
    
    if verbose == 0:     #For crunching individual files and pruning by indices #### Can change to 0 FOR PROBLEM FILES through batch crunch
        print filename
        print ice_dict["flag1"]
        print ice_dict["flag2"]
        print ice_dict["flag3"]
        print ice_dict["flag4"]
        print ice_dict["flag5"]
        print ice_dict["flag6"]
#        checkflag = input("Check flags and graphs. Continue?  ") 
    
#### Read in to Plot All Trimmed Data
trimmed_dict_long = {}
trimmed_dict_long["index"] = np.array(())
trimmed_dict_long["filepath"] = np.array(()).astype("S")
trimmed_dict_long["time"] = np.array(())
trimmed_dict_long["rawd18o"] = np.array(())
trimmed_dict_long["d18o"] = np.array(())
trimmed_dict_long["d18oerror"] = np.array(())
trimmed_dict_long["rawdD"] = np.array(())
trimmed_dict_long["dD"] = np.array(())
trimmed_dict_long["dDerror"] = np.array(())
trimmed_dict_long["d_excess"] = np.array(())
trimmed_dict_long["water"] = np.array(())
trimmed_dict_long["ec"] = np.array(())
trimmed_dict_long["depth"] = np.array(())
trimmed_dict_long["vial"] = np.array(())
trimmed_dict_long["meltrate"] = np.array(())
trimmed_dict_long["flag1"] = np.array(())
trimmed_dict_long["flag2"] = np.array(())
trimmed_dict_long["flag3"] = np.array(())
trimmed_dict_long["flag4"] = np.array(())
trimmed_dict_long["flag5"] = np.array(())
trimmed_dict_long["flag6"] = np.array(())
trimmed_dict_long["ave_valco_normsigma_d18o"] = np.array(())
trimmed_dict_long["ave_valco_normsigma_dD"] = np.array(())
trimmed_dict_long["ave_valco_skewsigma_d18o"] = np.array(())
trimmed_dict_long["ave_valco_skewsigma_dD"] = np.array(())
trimmed_dict_long["ave_nea_normsigma_d18o"] = np.array(())
trimmed_dict_long["ave_nea_normsigma_dD"] = np.array(())
trimmed_dict_long["ave_nea_skewsigma_d18o"] = np.array(())
trimmed_dict_long["ave_nea_skewsigma_dD"] = np.array(())
trimmed_dict_long["prodate"] = np.array(())
trimmed_dict_long["rundate"] = np.array(())
trimmed_dict_long["crunchversion"] = np.array(())

for root, dirs, files in os.walk('/Users/frio/GoogleDrive/'+corename+'/trimmed_dictionaries'):
    if verbose ==1:
        print files
    plt.ion()

if files[0] == '.DS_Store':
    files = files[1:]
    
if files[0] == 'Icon\r':
    files = files[1:]

for file in files[:]:   
    filepath = "/Users/frio/GoogleDrive/"+corename+"/trimmed_dictionaries/" + file
    trimdata = open(filepath, "r")                                   # open bininary file to read
    trimmed_data_dict = pickle.load(trimdata)  
    for i in trimmed_data_dict.keys():
        trimmed_dict_long[i] = np.concatenate([trimmed_dict_long[i], trimmed_data_dict[i][1:]])

trimmed_dict_long["d_excess"] = trimmed_dict_long["dD"]-8*trimmed_dict_long["d18o"]

##### Water filter
trimindex = np.arange(len(trimmed_dict_long["flag1"]))
datafilter = [x for x in trimindex if trimmed_dict_long["flag1"][x] == '.' and trimmed_dict_long["flag2"][x] == '.' and trimmed_dict_long["flag3"][x] == '.']
filteredd18o = trimmed_dict_long["d18o"][datafilter]
filtereddD = trimmed_dict_long["dD"][datafilter]
filtereddexcess = trimmed_dict_long["d_excess"][datafilter]
filteredec = trimmed_dict_long["ec"][datafilter]
filtereddepth = trimmed_dict_long["depth"][datafilter]

##### Read in All WAIS06A Replicate Trimmed Data
#reptrimmed_dict_long = {}
#reptrimmed_dict_long["index"] = np.array(())
#reptrimmed_dict_long["filepath"] = np.array(()).astype("S")
#reptrimmed_dict_long["time"] = np.array(())
#reptrimmed_dict_long["d18o"] = np.array(())
#reptrimmed_dict_long["dD"] = np.array(())
#reptrimmed_dict_long["d_excess"] = np.array(())
#reptrimmed_dict_long["water"] = np.array(())
#reptrimmed_dict_long["ec"] = np.array(())
#reptrimmed_dict_long["depth"] = np.array(())
#reptrimmed_dict_long["cordepth"] = np.array(())
#reptrimmed_dict_long["vial"] = np.array(())
#reptrimmed_dict_long["flag1"] = np.array(())
#reptrimmed_dict_long["flag2"] = np.array(())
#reptrimmed_dict_long["flag3"] = np.array(())
#reptrimmed_dict_long["flag4"] = np.array(())
#reptrimmed_dict_long["flag5"] = np.array(())
#reptrimmed_dict_long["flag6"] = np.array(())
#reptrimmed_dict_long["prodate"] = np.array(())

#for reproot, repdirs, repfiles in os.walk('/Users/frio/GoogleDrive/'+corename+'/rep_trimmed_dictionaries'):
#    if verbose ==1:
#        print repfiles
#    plt.ion()

#if repfiles[0] == '.DS_Store':
#    repfiles = repfiles[1:]

#for repfile in repfiles:   
#    repfilepath = "/Users/frio/GoogleDrive/"+corename+"/rep_trimmed_dictionaries/" + repfile
#    reptrimdata = open(repfilepath, "r")                                   # open bininary file to read
#    reptrimmed_data_dict = pickle.load(reptrimdata)  
#    for i in reptrimmed_data_dict.keys():
#        reptrimmed_dict_long[i] = np.concatenate([reptrimmed_dict_long[i], reptrimmed_data_dict[i][1:]])

#reptrimmed_dict_long["d_excess"] = reptrimmed_dict_long["dD"]-8*reptrimmed_dict_long["d18o"]
#reptrimmed_dict_long["index"] = np.arange(len(reptrimmed_dict_long["d18o"]))
#reptrimmed_dict_long["cordepth"] = reptrimmed_dict_long["depth"].copy()

##### OFFSET FROM RESETTING DRILL LAST FEILD SEASON NEEDS TO BE DIFFERENT FOR EACH REPLICATE CORE, from TJ Fudge at University of Washington
#r1slope = 0.999846291002
#r1intercept = -0.268410034128
#r2aslope = 0.997374701671
#r2aintercept = 7.086593078793
#r2bslope = 0.997869481137
#r2bintercept = 5.980225507232
#r3slope = 0.998692430626
#r3intercept = 4.040540752584
#r4slope = 0.997657630800
#r4intercept = 6.124672813607
#r5slope = 0.994953416149
#r5intercept = 12.633131987588
#for p in reptrimmed_dict_long["index"]:
#    if reptrimmed_dict_long["depth"][p]<=3200 and reptrimmed_dict_long["depth"][p]>=3000 and reptrimmed_dict_long["time"][p]>=8000000 and reptrimmed_dict_long["time"][p]<=11000000: # for some reason the dates are all shifted to 1970?? but day and month are correct?
#        reptrimmed_dict_long["cordepth"][p] = (r1slope*reptrimmed_dict_long["depth"][p])+r1intercept    
#        print p, "replicate core 1"
#    if reptrimmed_dict_long["depth"][p]<= 2438.425 and reptrimmed_dict_long["depth"][p]>=2410 and reptrimmed_dict_long["time"][p]>=9000000 and reptrimmed_dict_long["time"][p]<=12000000:
#        reptrimmed_dict_long["cordepth"][p] = (r2aslope*reptrimmed_dict_long["depth"][p])+r2aintercept
#        print p, "replicate core 2a"
#    if reptrimmed_dict_long["depth"][p]<= 2470 and reptrimmed_dict_long["depth"][p]>=2438.479 and reptrimmed_dict_long["time"][p]>=9000000 and reptrimmed_dict_long["time"][p]<=12000000:
#        reptrimmed_dict_long["cordepth"][p] = (r2bslope*reptrimmed_dict_long["depth"][p])+r2bintercept
#        print p, "replicate core 2b"
#    if reptrimmed_dict_long["depth"][p]<= 2300 and reptrimmed_dict_long["depth"][p]>=2220 and reptrimmed_dict_long["time"][p]>=11000000 and reptrimmed_dict_long["time"][p]<=13000000:
#        reptrimmed_dict_long["cordepth"][p] = (r3slope*reptrimmed_dict_long["depth"][p])+r3intercept
#        print p, "replicate core 3"
#    if reptrimmed_dict_long["depth"][p]<=2010 and reptrimmed_dict_long["depth"][p]>=1950 and reptrimmed_dict_long["time"][p]>=12000000 and reptrimmed_dict_long["time"][p]<=14000000:
#        reptrimmed_dict_long["cordepth"][p] = (r4slope*reptrimmed_dict_long["depth"][p])+r4intercept
#        print p, "replicate core 4"
#    if reptrimmed_dict_long["depth"][p]<=2430 and reptrimmed_dict_long["depth"][p]>=2410 and reptrimmed_dict_long["time"][p]>=13000000 and reptrimmed_dict_long["time"][p]<=14000000:
#        reptrimmed_dict_long["cordepth"][p] = (r5slope*reptrimmed_dict_long["depth"][p])+r5intercept
#        print p, "replicate core 5"

### Read in Mass Spec WAIS06A discrete data to plot with ours...
#msfilepath = "/Users/frio/GoogleDrive/"+corename+"/MassSpecDiscrete.txt"
#msdata = np.loadtxt(msfilepath, skiprows = 1, dtype = "S")
#msdepth = msdata[:,0].astype("float") 
#msd18o = msdata[:,1].astype("float") 
#msdD = msdata[:,2].astype("float") 
#msdexcess = msdata[:,3].astype("float")
#msindex = np.arange(len(msdepth))

### Read in Picarro WAIS06A discrete data to plot with ours...
#pfilepath = "/Users/frio/GoogleDrive/"+corename+"/PicarroDiscrete.txt"
#pdata = np.loadtxt(pfilepath, skiprows = 1, dtype = "S")
#pdepth = pdata[:,0].astype("float") 
#pd18o = pdata[:,1].astype("float") 
#pdD = pdata[:,2].astype("float") 
#pdexcess = pdata[:,3].astype("float")
#pindex = np.arange(len(pdepth))

### Read in UW WAIS06A half meter data to plot with ours...
#uwfilepath = "/Users/frio/Ice/UWdataWAIS06A_2.txt"
#uwdata = np.loadtxt(uwfilepath, skiprows = 1, dtype = "S")
#uwdepth = uwdata[:,0].astype("float") 
#uwd18o = uwdata[:,1].astype("float") 
#uwdD = uwdata[:,2].astype("float") 
#uwdexcess = uwdata[:,3].astype("float")
#uwindex = np.arange(len(uwdepth))

#beginzoom = np.min(nonzero_true_depth)-100
#endzoom = np.max(nonzero_true_depth)+100

fig441 = plt.figure(441)                    
fig441_ax1 = fig441.add_subplot(311)
fig441_ax1.plot(trimmed_dict_long["depth"], trimmed_dict_long["d18o"], "g.", filtereddepth, filteredd18o, "b.")#, uwdepth, uwd18o, "g.", msdepth, msd18o, "y.", \
#    pdepth, pd18o, "c.") #,reptrimmed_dict_long["cordepth"], reptrimmed_dict_long["d18o"], "w."
fig441_ax1.axis([0,600,-45,-20])
fig441_ax1.set_ylabel("d18o")
fig441_ax2 = fig441.add_subplot(312)
fig441_ax2.plot(trimmed_dict_long["depth"], trimmed_dict_long["dD"], "m.", filtereddepth, filtereddD, "r.")#, uwdepth, uwdD, "g.", msdepth, msdD, "y.", \
#    pdepth, pdD, "c.") #, reptrimmed_dict_long["cordepth"], reptrimmed_dict_long["dD"], "w."
fig441_ax2.axis([0,600,-400,-200])
fig441_ax2.set_ylabel("dD")
fig441_ax3 = fig441.add_subplot(313)
fig441_ax3.plot(trimmed_dict_long["depth"], trimmed_dict_long["d_excess"], "k.", filtereddepth, filtereddexcess, "y.")#, uwdepth, uwdexcess, "g.", msdepth, msdexcess, "y.", \
#    pdepth, pdexcess, "c.") #, reptrimmed_dict_long["cordepth"], reptrimmed_dict_long["d_excess"], "w."
fig441_ax3.axis([0,600,-10,20])
fig441_ax3.set_ylabel("d-excess")
fig441_ax3.set_xlabel("Depth")
fig441_ax1.set_title("%s" %(os.path.splitext(filepath)[0]))

print len(trimmed_dict_long["depth"])
print len(filtereddepth)

################################################################################
# END OF FULL PROGRAM ##########################################################
